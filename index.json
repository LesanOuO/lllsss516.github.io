[{"categories":["实践笔记"],"content":"在使用docker时，常常需要对已启动的容器进行相应的配置修改，其中最常见的就是挂载目录或端口映射。其实配置也并不是非常复杂，可以通过修改docker中的json配置文件即可。 以下为详细修改步骤 ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:0:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"1. 先查看需要修改的容器的id号 首先通过 docker ps -a 查看 CONTAINER ID 再通过 docker inspect \u003ccontainer_id\u003e 查看 Id （一般在最开始的位置） ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:1:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"2. 关闭docker服务 在做相应配置前，一定要先停止docker服务，否则会修改不成功。 systemctl stop docker ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:2:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"3. 前往docker配置文件目录 通过以下命令即可进入到配置文件目录： cd /var/lib/docker/containers/\u003ccontainer_id\u003e ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:3:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"4. 修改hostconfig.json文件 通过 vim hostconfig.json 即可修改配置文件。 vim中可以通过 /字符串 快速定位字符串位置 修改以下内容配置端口映射 { ... \"PortBindings\": { \"80/tcp\": [ { \"HostIp\": \"\", \"HostPort\": \"8080\" } ] } ... } 修改以下内容配置挂载目录 { ... \"Binds\": [ \"/home/docker/www:/var/www\" ] ... // 其中 `/home/docker/www` 为宿主机目录，`/var/www` 为容器目录 } ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:4:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"4. 修改config.v2.json文件 通过 vim config.v2.json 即可修改配置文件。 修改以下内容配置端口映射 { ... \"ExposedPorts\": { \"80/tcp\": {}, } ... } 修改以下内容配置挂载目录 { ... \"MountPoints\": { \"/var/www\": { \"Source\": \"/home/docker/www\", \"Destination\": \"/var/www\", \"RW\": true, \"Name\": \"\", \"Driver\": \"\", \"Type\": \"bind\", \"Propagation\": \"rprivate\", \"Spec\": { \"Type\": \"bind\", \"Source\": \"/home/docker/www\", \"Target\": \"/var/www\", } \"SkipMountpointCreation\": false, } } ... // 其中 `/home/docker/www` 为宿主机目录，`/var/www` 为容器目录 } ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:5:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"5. 重启docker服务 `systemctl start docker` ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:6:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["学习笔记"],"content":"索引 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:0:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"MySQL 索引 MySQL 的索引有两种分类方式：逻辑分类和物理分类 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"逻辑分类 主键索引：一张表只能有一个主键索引，不允许重复、不允许为 NULL 唯一索引：数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一 普通索引：一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插入 全文索引：它查找的是文本中的关键词，主要用于全文检索 单例索引：一个索引只包含一个列，一个表可以有多个单例索引 组合索引：一个组合索引包含两个或两个以上的列。查询的时候遵循 mysql 组合索引的 “最左前缀”原则，即使用 where 时条件要按照建立索引的时候字段的排列方式放置索引才会生效 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"物理分类 聚簇索引：不是单独的一种索引类型，而是一种数据存储方式。这种存储方式是依靠B+树来实现的，根据表的主键构造一棵B+树且B+树叶子节点存放的都是表的行记录数据时，方可称该主键索引为聚簇索引。聚簇索引也可理解为将数据存储与索引放到了一块，找到索引也就找到了数据。 非聚簇索引：数据和索引是分开的，B+树叶子节点存放的不是数据表的行记录 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"EXPLAIN 使用格式：EXPLAIN SQL...; 返回结果包含： id:选择标识符 select_type:表示查询的类型。 table:输出结果集的表 partitions:匹配的分区 type:表示表的连接类型 possible_keys:表示查询时，可能使用的索引 key:表示实际使用的索引 key_len:索引字段的长度 ref:列与索引的比较 rows:扫描出的行数(估算的行数) filtered:按表条件过滤的行百分比 Extra:执行情况的描述和说明 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"SQL Server 索引 唯一索引（UNIQUE）：唯一索引不允许两行具有相同的索引值 主键索引：为表定义一个主键将自动创建主键索引，主键索引是唯一索引的特殊类型。主键索引要求主键中的每个值是唯一的，并且不能为空 聚集索引(Clustered)：表中各行的物理顺序与键值的逻辑（索引）顺序相同，每个表最多只能有一个，设置某列为主键，该列就默认为聚集索引 非聚集索引(NonClustered)：非聚集索引指定表的逻辑顺序。数据存储在一个位置，索引存储在另一个位置，索引中包含指向数据存储位置的指针。可以有多个，小于249个 SQL 优化 总结SQL优化中，就三点: 最大化利用索引； 尽可能避免全表扫描； 减少无效数据的查询； ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:2:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"避免不走索引的场景 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫码 例如： SELECT * FROM user WHERE name LIKE '%李%' 优化方式：尽量在字段后面使用模糊查询，例如： SELECT * FROM user WHERE name LIKE '李%' 如果需要在前面使用模糊查询，可以使用以下方式： 使用MySQL内置函数INSTR(str, substr)，返回匹配子串的位置,类似Java中的str.indexOf(substr) 使用FullText全文索引，用match against检索 数据量较大的情况，使用ElasticSearch、solr，亿级数据量检索速度秒级 当数据量较少时（几千条），直接用LIKE '%李%' ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 尽量避免使用in和not in，会导致全表扫描 SELECT * FROM table WHERE id IN (2,3) 优化方式：如果是连续数值，可以使用between代替，例如: SELECT * FROM table WHERE id BETWEEN 2 AND 3 如果是子查询，可以使用EXISTS或NOT EXISTS代替，例如: SELECT * FROM table WHERE EXISTS (SELECT id FROM table2 WHERE table.id = table2.id) ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3. 尽量避免使用OR，会导致全表扫描 SELECT * FROM table WHERE id = 1 OR id = 2 优化方式：可以使用Union，例如: SELECT * FROM table WHERE id = 1 UNION SELECT * FROM table WHERE id = 2 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4. 尽量避免null值的判断 SELECT * FROM table WHERE id IS NULL 优化方式：可以给字段添加默认值，对默认值进行判断，例如： SELECT * FROM table WHERE id = 默认值 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"5. 尽量避免在where条件中等号左侧进行表达式、函数操作 可以将表达式、函数操作移动到等号右侧，例如： -- 全表扫码 SELECT*FROMtableWHEREscore/10=9-- 走索引 SELECT*FROMtableWHEREscore=10*9 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:5","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"6. 当数据量大时，避免使用where 1=1的条件 通常为了方便拼接查询条件，会使用它来作为条件 优化方式：用代码拼接sql时进行判断，没where条件就去掉where，有where条件就加and ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:6","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"7. 查询条件不能用\u003c\u003e或者!= 使用索引列作为条件进行查询时，需要避免使用\u003c\u003e或者!=等判断条件。如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:7","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"8. where条件仅包含复合索引非前置列 如下：复合（联合）索引包含key_part1，key_part2，key_part3三列，但SQL语句没有包含索引前置列\"key_part1\"，按照MySQL联合索引的最左匹配原则，不会走联合索引 select col1 from table where key_part2=1 and key_part3=2 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:8","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"9. 隐式类型转换造成不使用索引 如下SQL语句由于索引对列类型为varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引 select col1 from table where col_varchar=123; ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:9","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"10. order by 条件要与where中条件一致，否则order by不会利用索引进行排序 -- 不走age索引 SELECT*FROMtorderbyage;-- 走age索引 SELECT*FROMtwhereage\u003e0orderbyage; 当order by 中的字段出现在where条件中时，才会利用索引而不再二次排序，更准确的说，order by 中的字段在执行计划中利用了索引时，不用排序操作 这个结论不仅对order by有效，对其他需要排序的操作也有效。比如group by 、union 、distinct等 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:10","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"11. 正确使用hint优化语句 MySQL中可以使用hint指定优化器在执行时选择或忽略特定的索引。一般而言，处于版本变更带来的表结构索引变化，更建议避免使用hint，而是通过Analyze table多收集统计信息。但在特定场合下，指定hint可以排除其他索引干扰而指定更优的执行计划。 USE INDEX 在你查询语句中表名的后面，添加 USE INDEX 来提供希望 MySQL 去参考的索引列表，就可以让 MySQL 不再考虑其他可用的索引。例子: SELECT col1 FROM table USE INDEX (mod_time, name)… IGNORE INDEX 如果只是单纯的想让 MySQL 忽略一个或者多个索引，可以使用 IGNORE INDEX 作为 Hint。例子: SELECT col1 FROM table IGNORE INDEX (priority) … FORCE INDEX 为强制 MySQL 使用一个特定的索引，可在查询中使用FORCE INDEX 作为Hint。例子: SELECT col1 FROM table FORCE INDEX (mod_time) … 在查询的时候，数据库系统会自动分析查询语句，并选择一个最合适的索引。但是很多时候，数据库系统的查询优化器并不一定总是能使用最优索引。如果我们知道如何选择索引，可以使用FORCE INDEX强制查询使用指定的索引。 例如：SELECT * FROM students FORCE INDEX (idx_class_id) WHERE class_id = 1 ORDER BY id DESC; ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:11","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"SELECT语句其他优化 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 避免出现select * 首先，select * 操作在任何类型数据库中都不是一个好的SQL编写习惯。 使用select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的I/O,内存和CPU消耗。 建议提出业务实际需要的列数，将指定列名以取代select *。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 避免出现不确定结果的函数 特定针对主从复制这类业务场景。由于原理上从库复制的是主库执行的语句，使用如now()、rand()、sysdate()、current_user()等不确定结果的函数很容易导致主库与从库相应的数据不一致。另外不确定值的函数,产生的SQL语句无法利用query cache。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3.多表关联查询时，小表在前，大表在后。 在MySQL中，执行 from 后的表关联查询是从左往右执行的（Oracle相反），第一张表会涉及到全表扫描，所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前100行就符合返回条件并return了。 例如：表1有50条数据，表2有30亿条数据；如果全表扫描表2，你品，那就先去吃个饭再说吧是吧。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4. 使用表的别名 当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"5. 用where字句替换HAVING字句 避免使用HAVING字句，因为HAVING只会在检索出所有记录之后才对结果集进行过滤，而where则是在聚合前刷选记录，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在where字句中。 where和having的区别：where后面不能使用组函数 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:5","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"6.调整Where字句中的连接顺序 MySQL采用从左往右，自上而下的顺序解析where子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:6","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"增删改 DML 语句优化 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 大批量插入数据 如果同时执行大量的插入，建议使用多个值的INSERT语句(方法二)。这比使用分开INSERT语句快（方法一），一般情况下批量插入效率有几倍的差别。 方法一： insertintoTvalues(1,2);insertintoTvalues(1,3);insertintoTvalues(1,4); 方法二： InsertintoTvalues(1,2),(1,3),(1,4); 选择后一种方法的原因有三。 减少SQL语句解析的操作，MySQL没有类似Oracle的share pool，采用方法二，只需要解析一次就能进行数据的插入操作； 在特定场景可以减少对DB连接次数 SQL语句较短，可以减少网络传输的IO。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 适当使用commit 适当使用commit可以释放事务占用的资源而减少消耗，commit后能释放的资源如下： 事务占用的undo数据块； 事务在redo log中记录的数据块； 释放事务施加的，减少锁争用影响性能。特别是在需要使用delete删除大量数据的时候，必须分解删除量并定期commit。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3. 避免重复查询更新的数据 针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL并不支持PostgreSQL那样的UPDATE RETURNING语法，在MySQL中可以通过变量实现。 例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么，简单方法实现： Updatet1settime=now()wherecol1=1;Selecttimefromt1whereid=1; 使用变量，可以重写为以下方式： Updatet1settime=now()wherecol1=1and@now:=now();Select@now; 前后二者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当t1表数据量较大时，后者比前者快很多。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4.查询优先还是更新（insert、update、delete）优先 MySQL 还允许改变语句调度的优先级，它可以使来自多个客户端的查询更好地协作，这样单个客户端就不会由于锁定而等待很长时间。改变优先级还可以确保特定类型的查询被处理得更快。我们首先应该确定应用的类型，判断应用是以查询为主还是以更新为主的，是确保查询效率还是确保更新的效率，决定是查询优先还是更新优先。下面我们提到的改变调度策略的方法主要是针对只存在表锁的存储引擎，比如 MyISAM 、MEMROY、MERGE，对于Innodb 存储引擎，语句的执行是由获得行锁的顺序决定的。MySQL 的默认的调度策略可用总结如下： 1）写入操作优先于读取操作。 2）对某张数据表的写入操作某一时刻只能发生一次，写入请求按照它们到达的次序来处理。 3）对某张数据表的多个读取操作可以同时地进行。MySQL 提供了几个语句调节符，允许你修改它的调度策略： LOW_PRIORITY关键字应用于DELETE、INSERT、LOAD DATA、REPLACE和UPDATE； HIGH_PRIORITY关键字应用于SELECT和INSERT语句； DELAYED关键字应用于INSERT和REPLACE语句。 如果写入操作是一个 LOW_PRIORITY（低优先级）请求，那么系统就不会认为它的优先级高于读取操作。在这种情况下，如果写入者在等待的时候，第二个读取者到达了，那么就允许第二个读取者插到写入者之前。只有在没有其它的读取者的时候，才允许写入者开始操作。这种调度修改可能存在 LOW_PRIORITY写入操作永远被阻塞的情况。 SELECT 查询的HIGH_PRIORITY（高优先级）关键字也类似。它允许SELECT 插入正在等待的写入操作之前，即使在正常情况下写入操作的优先级更高。另外一种影响是，高优先级的 SELECT 在正常的 SELECT 语句之前执行，因为这些语句会被写入操作阻塞。如果希望所有支持LOW_PRIORITY 选项的语句都默认地按照低优先级来处理，那么 请使用–low-priority-updates 选项来启动服务器。通过使用 INSERTHIGH_PRIORITY 来把 INSERT 语句提高到正常的写入优先级，可以消除该选项对单个INSERT语句的影响。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"查询条件优化 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 对于复杂的查询，可以使用中间临时表暂存数据 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 优化group by语句 默认情况下，MySQL 会对GROUP BY分组的所有值进行排序，如 “GROUP BY col1，col2，….;” 查询的方法如同在查询中指定 “ORDER BY col1，col2，…;” 如果显式包括一个包含相同的列的 ORDER BY子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。 因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL禁止排序。例如： SELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3. 优化join语句 MySQL中可以通过子查询来使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接(JOIN)..替代。 例子：假设要将所有没有订单记录的用户取出来，可以用下面这个查询完成： SELECT col1 FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo ) 如果使用连接(JOIN).. 来完成这个查询工作，速度将会有所提升。尤其是当 salesinfo表中对 CustomerID 建有索引的话，性能将会更好，查询如下： SELECTcol1FROMcustomerinfoLEFTJOINsalesinfoONcustomerinfo.CustomerID=salesinfo.CustomerIDWHEREsalesinfo.CustomerIDISNULL ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4. 优化union查询 MySQL通过创建并填充临时表的方式来执行union查询。除非确实要消除重复的行，否则建议使用union all。原因在于如果没有all这个关键词，MySQL会给临时表加上distinct选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高。 高效： SELECTCOL1,COL2,COL3FROMTABLEWHERECOL1=10UNIONALLSELECTCOL1,COL2,COL3FROMTABLEWHERECOL3='TEST'; 低效： SELECTCOL1,COL2,COL3FROMTABLEWHERECOL1=10UNIONSELECTCOL1,COL2,COL3FROMTABLEWHERECOL3='TEST'; ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"5. 拆分复杂SQL为多个小SQL，避免大事务 简单的SQL容易使用到MySQL的QUERY CACHE； 减少锁表时间特别是使用MyISAM存储引擎的表； 可以使用多核CPU。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:5","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"6. 使用truncate代替delete 当删除全表中记录时，使用delete语句的操作会被记录到undo块中，删除记录也记录binlog，当确认需要删除全表时，会产生很大量的binlog并占用大量的undo数据块，此时既没有很好的效率也占用了大量的资源。 使用truncate替代，不会记录可恢复的信息，数据不能被恢复。也因此使用truncate操作有其极少的资源占用与极快的时间。另外，使用truncate可以回收表的水位，使自增字段值归零。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:6","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"7. 使用合理的分页方式以提高分页效率 使用合理的分页方式以提高分页效率 针对展现等分页需求，合适的分页方式能够提高分页的效率。 案例1： select*fromtwherethread_id=10000anddeleted=0orderbygmt_createasclimit0,15; 上述例子通过一次性根据过滤条件取出所有字段进行排序返回。数据访问开销=索引IO+索引全部记录结果对应的表数据IO。因此，该种写法越翻到后面执行效率越差，时间越长，尤其表数据量很大的时候。 适用场景：当中间结果集很小（10000行以下）或者查询条件复杂（指涉及多个不同查询字段或者多表连接）时适用。 案例2： selectt.*from(selectidfromtwherethread_id=10000anddeleted=0orderbygmt_createasclimit0,15)a,twherea.id=t.id; 上述例子必须满足t表主键是id列，且有覆盖索引secondary key:(thread_id, deleted, gmt_create)。通过先根据过滤条件利用覆盖索引取出主键id进行排序，再进行join操作取出其他字段。数据访问开销=索引IO+索引分页后结果（例子中是15行）对应的表数据IO。因此，该写法每次翻页消耗的资源和时间都基本相同，就像翻第一页一样。 适用场景：当查询和排序字段（即where子句和order by子句涉及的字段）有对应覆盖索引时，且中间结果集很大的情况时适用。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:7","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"建表优化 在表中建立索引，优先考虑where、order by使用到的字段 尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了 查询数据量大的表会造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段分页进行查询，循环遍历，将结果合并处理进行展示。要查询100000到100050的数据: SELECT * FROM (SELECT ROW_NUMBER() OVER(ORDER BY ID ASC) AS rowid,* FROM infoTab)t WHERE t.rowid \u003e 100000 AND t.rowid \u003c= 100050 用varchar/nvarchar 代替 char/nchar 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:7:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["收藏分享"],"content":"简介 在大型企业中，服务器网络一般都会有各种各样的限制，常见的就会有堡垒机或者运维网关，以达到操作审计等目的。但对于开发者来讲，这些限制大大降低了效率，所以我们需要一个方便的方式来解决这个问题。 本篇文章主要通过为Linux增加SSH端口的方式来解决这个问题，通过增加SSH访问端口来绕开22端口的限制。 ","date":"2022-05-21","objectID":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/:1:0","tags":["Linux"],"title":"Linux增加SSH端口","uri":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/"},{"categories":["收藏分享"],"content":"实现 SSH配置文件 通过 vi /etc/ssh/sshd_config 来配置SSH端口，在Port 22后添加一行Port XX即可 配置SELinux 通过 semanage port -l | grep ssh 可以看到： ssh_port_t tcp 22 可以看到并没有我们添加的端口 可以执行semanage port -a -tssh_port_t -p tcp XX来添加 再次检查： ssh_port_t tcp XX, 22 重启SSH systemctl restart sshd.service 通过telnet可以验证 telnet IP地址 XX 通过以上操作后，就可以通过新开放的端口来实现对SHH服务的访问了 ","date":"2022-05-21","objectID":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/:2:0","tags":["Linux"],"title":"Linux增加SSH端口","uri":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/"},{"categories":["学习笔记"],"content":"Redis简介 Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis数据结构 String（字符串） string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。 string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。 string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。 127.0.0.1:6379\u003e set name Lesan OK 127.0.0.1:6379\u003e get name \"Lesan\" Hash（哈希） Redis hash 是一个键值(key=\u003evalue)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 127.0.0.1:6379\u003e hmset lesan field1 \"Hello\" field2 \"World\" OK 127.0.0.1:6379\u003e hget lesan field1 \"Hello\" 127.0.0.1:6379\u003e hget lesan field2 \"World\" List（列表） Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 127.0.0.1:6379\u003e del lesan (integer) 1 127.0.0.1:6379\u003e lpush lesan redis (integer) 1 127.0.0.1:6379\u003e lpush lesan mongodb (integer) 2 127.0.0.1:6379\u003e lpush lesan mysql (integer) 3 127.0.0.1:6379\u003e lrange lesan 0 10 1) \"mysql\" 2) \"mongodb\" 3) \"redis\" Set（集合） Redis 的 Set 是 string 类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 127.0.0.1:6379\u003e sadd lesan redis (integer) 1 127.0.0.1:6379\u003e sadd lesan redis (integer) 0 127.0.0.1:6379\u003e sadd lesan mongodb (integer) 1 127.0.0.1:6379\u003e sadd lesan mysql (integer) 1 127.0.0.1:6379\u003e smembers lesan 1) \"redis\" 2) \"mysql\" 3) \"mongodb\" zset（有序集合） Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 127.0.0.1:6379\u003e zadd lesan 0 redis (integer) 1 127.0.0.1:6379\u003e zadd lesan 0 mongodb (integer) 1 127.0.0.1:6379\u003e zadd lesan 0 mysql (integer) 1 127.0.0.1:6379\u003e zadd lesan 0 mysql (integer) 0 127.0.0.1:6379\u003e zrangebyscore lesan 0 100 1) \"mongodb\" 2) \"mysql\" 3) \"redis\" Stream Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。 而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:1","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis 命令 key Redis 键命令用于管理 redis 的键。 DEL KEY_NAME 用于删除已存在的键。不存在的 key 会被忽略 DUMP KEY_NAME 用于序列化给定 key ，并返回被序列化的值 EXISTS KEY_NAME 用于检查给定 key 是否存在 Expire KEY_NAME TIME_IN_SECONDS 用于设置 key 的过期时间，key 过期后将不再可用。单位以秒计 Expireat KEY_NAME TIME_IN_UNIX_TIMESTAMP 用于以 UNIX 时间戳(unix timestamp)格式设置 key 的过期时间。key 过期后将不再可用 PEXPIRE key milliseconds 以毫秒为单位设置 key 的生存时间 PEXPIREAT KEY_NAME TIME_IN_MILLISECONDS_IN_UNIX_TIMESTAMP 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计 KEYS PATTERN 用于查找所有符合给定模式 pattern 的 key MOVE KEY_NAME DESTINATION_DATABASE 用于将当前数据库的 key 移动到给定的数据库 db 当中 PERSIST KEY_NAME 用于移除给定 key 的过期时间，使得 key 永不过期 PTTL KEY_NAME 以毫秒为单位返回 key 的剩余过期时间 TTL KEY_NAME 以秒为单位返回 key 的剩余过期时间 RANDOMKEY 从当前数据库中随机返回一个 key RENAME OLD_KEY_NAME NEW_KEY_NAME 用于修改 key 的名称 RENAMENX OLD_KEY_NAME NEW_KEY_NAME 用于在新的 key 不存在时修改 key 的名称 SCAN cursor [MATCH pattern] [COUNT count] 用于迭代数据库中的数据库键 TYPE KEY_NAME 用于返回 key 所储存的值的类型 更多命令请参考菜鸟教程 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:2","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis 应用场景 缓存 作为Key-Value形态的内存数据库，Redis 最先会被想到的应用场景便是作为数据缓存。而使用 Redis 缓存数据非常简单，只需要通过string类型将序列化后的对象存起来即可，不过也有一些需要注意的地方： 必须保证不同对象的 key 不会重复，并且使 key 尽量短，一般使用类名（表名）加主键拼接而成。 选择一个优秀的序列化方式也很重要，目的是提高序列化的效率和减少内存占用。 缓存内容与数据库的一致性，这里一般有两种做法： 只在数据库查询后将对象放入缓存，如果对象发生了修改或删除操作，直接清除对应缓存（或设为过期）。 在数据库新增和查询后将对象放入缓存，修改后更新缓存，删除后清除对应缓存（或设为过期）。 数据共享分布式 String 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享 例如：分布式Session 分布式锁 在分布式环境下，单体锁已不在适用，Redis中string的set命令增加了一些参数： EX：设置键的过期时间（单位为秒） PX：设置键的过期时间（单位为毫秒） NX：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。 XX：只在键已经存在时，才对键进行设置操作。 由于这个操作是原子性的，可以简单地以此实现一个分布式的锁，例如： set lock_key locked NX EX 1 如果这个操作返回false，说明 key 的添加不成功，也就是当前有人在占用这把锁。而如果返回true，则说明得了锁，便可以继续进行操作，并且在操作后通过del命令释放掉锁。并且即使程序因为某些原因并没有释放锁，由于设置了过期时间，该锁也会在 1 秒后自动释放，不会影响到其他程序的运行。 推荐使用 redisson 第三方库实现分布式锁 全局ID int类型，incrby，利用原子性 incrby userid 1000 分库分表的场景，一次性拿一段 计数器 int类型，incr方法 例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库 计数功能应该是最适合 Redis 的使用场景之一了，因为它高频率读写的特征可以完全发挥 Redis 作为内存数据库的高效。在 Redis 的数据结构中，string、hash和sorted set都提供了incr方法用于原子性的自增操作，下面举例说明一下它们各自的使用场景： 如果应用需要显示每天的注册用户数，便可以使用string作为计数器，设定一个名为REGISTERED_COUNT_TODAY的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用incr命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。 每条微博都有点赞数、评论数、转发数和浏览数四条属性，这时用hash进行计数会更好，将该计数器的 key 设为weibo:weibo_id，hash的 field 为like_number、comment_number、forward_number和view_number，在对应操作后通过hincrby使hash 中的 field 自增。 如果应用有一个发帖排行榜的功能，便选择sorted set吧，将集合的 key 设为POST_RANK。当用户发帖后，使用zincrby将该用户 id 的 score 增长 1。sorted set会重新进行排序，用户所在排行榜的位置也就会得到实时的更新。 限流 int类型，incr方法 以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false 位统计 String类型的bitcount，字符是以8位二进制存储的 set k1 a setbit k1 6 1 setbit k1 7 0 get k1 其中6 7 代表的a的二进制位的修改 a-\u003e01100001 b-\u003e01100010 因为bit非常节省空间，可以用来做大数据量的统计 时间轴 list作为双向链表，不光可以作为队列使用。如果将它用作栈便可以成为一个公用的时间轴。当用户发完微博后，都通过lpush将它存放在一个 key 为LATEST_WEIBO的list中，之后便可以通过lrange取出当前最新的微博。 消息队列 Redis 中list的数据结构实现是双向链表，所以可以非常便捷的应用于消息队列（生产者 / 消费者模型）。消息的生产者只需要通过lpush将消息放入 list，消费者便可以通过rpop取出该消息，并且可以保证消息的有序性。如果需要实现带有优先级的消息队列也可以选择sorted set。而pub/sub功能也可以用作发布者 / 订阅者模型的消息。无论使用何种方式，由于 Redis 拥有持久化功能，也不需要担心由于服务器故障导致消息丢失的情况。 List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间 blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低 队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列 栈：先进后出：rpush brpop 抽奖 利用set结构的无序性,通过 Spop（ Redis Spop 命令用于移除集合中的指定 key 的一个或多个随机元素，移除后会返回移除的元素 ） 随机获得值 点赞、签到、打卡 假如微博ID是t1001，用户ID是u3001 用 like:t1001 来维护 t1001 这条微博的所有点赞用户 点赞了这条微博：sadd like:t1001 u3001 取消点赞：srem like:t1001 u3001 是否点赞：sismember like:t1001 u3001 点赞的所有用户：smembers like:t1001 点赞数：scard like:t1001 是不是比数据库简单多了。 好友关系、用户关注、推荐模型 这个场景最开始是是一篇介绍微博 Redis 应用的 PPT 中看到的，其中提到微博的 Redis 主要是用在在计数和好友关系两方面上，当时对好友关系方面的用法不太了解，后来看到《Redis 设计与实现》中介绍到作者最开始去使用 Redis 便是希望能通过set解决传统数据库无法快速计算集合中交集这个功能。后来联想到微博当前的业务场景，确实能够以这种方式实现，所以姑且猜测一下： 对于一个用户 A，将它的关注和粉丝的用户 id 都存放在两个 set 中： A:follow：存放 A 所有关注的用户 id A:follower：存放 A 所有粉丝的用户 id 那么通过sinter命令便可以根据A:follow和A:follower的交集得到与 A 互相关注的用户。当 A 进入另一个用户 B 的主页后，A:follow和B:follow的交集便是 A 和 B 的共同专注，A:follow和B:follower的交集便是 A 关注的人也关注了 B；通过sdiff命令便可得到差集，就可以得到用户间可能认识的人 排行榜 使用sorted set(有序set)和一个计算热度的算法便可以轻松打造一个热度排行榜，zrevrangebyscore可以得到以分数倒序排列的序列，zrank可以得到一个成员在该排行榜的位置（是分数正序排列时的位置，如果要获取倒序排列时的位置需要用zcard-zrank）。 id 为 6001 的新闻点击数加1：zincrby hotNews:20190926 1 n6001 获取今天点击最多的15条：zrevrange hotNews:20190926 0 15 withscores 更多应用案例可以查看本篇文章、或本篇文章 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis集群部署 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"主从复制 部署简单，分为一主一从，或一主N从。数据分布是在所有节点通过replication复制全量的数据。如果主节点挂掉，需要手动把其中的一个从节点设置为主节点 实践： 只需要在从库中执行slaveof ip port ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:1","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"哨兵模式 稍微比第一种复杂点，引入哨兵，此集群的原理还是主从复制。但是此集群中必须至少3个sentinel节点，来对一主两从的节点进行监控。因为sentinel里面存在一个Leader选举机制。必须是单数。此时sentinel(哨兵)其实就是一个Redis的特殊实例。此时的三个sentinel实例又组成了一个集群，两两互相监控，且这三个sentinel实例又分别都监控了所有的Redis节点。当一个主节点（Master）挂掉时，此集群方式会通过配置自动由对应的从节点（slave）变为主节点。如果一个主节点下有N个从节点，则进行选举机制来确定哪一个从节点变为主节点。此时所有节点的数据也都是全量的 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:2","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"分片模式 此集群是Redis从3.0版本开始支持，自带的一种集群方式。它的原理使用了分布的思想，其数据会均分到所有的主节点上。且有一个虚拟槽的概念。此部署方式，当数据量过大时，会让服务器均摊压力。在各个主节点上分配的数据都不是全量的。是分片存储的。目前此种部署方式在生产环境的较多 参考自： https://blog.csdn.net/u014659211/article/details/119805443 https://blog.csdn.net/qq_42815754/article/details/82912130 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:3","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"通过SpringCloud了解微服务 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:0:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"什么是微服务？ 微服务是一种开发软件的架构和组织方法，其中软件由通过明确定义的 API 进行通信的小型独立服务组成。 使用微服务架构，将应用程序构建为独立的组件，并将每个应用程序进程作为一项服务运行。这些服务使用轻量级 API 通过明确定义的接口进行通信。这些服务是围绕业务功能构建的，每项服务执行一项功能。由于它们是独立运行的，因此可以针对各项服务进行更新、部署和扩展，以满足对应用程序特定功能的需求。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"微服务的特性 自主性 可以对微服务架构中的每个组件服务进行开发、部署、运营和扩展，而不影响其他服务的功能。这些服务不需要与其他服务共享任何代码或实施。各个组件之间的任何通信都是通过明确定义的 API 进行的。 专用性 每项服务都是针对一组功能而设计的，并专注于解决特定的问题。如果开发人员逐渐将更多代码增加到一项服务中并且这项服务变得复杂，那么可以将其拆分成多项更小的服务。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:1","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"微服务的优势 敏捷性 微服务促进若干小型独立团队形成一个组织，这些团队负责自己的服务。各团队在小型且易于理解的环境中行事，并且可以更独立、更快速地工作。这缩短了开发周期时间。您可以从组织的总吞吐量中显著获益。 灵活扩展 通过微服务，您可以独立扩展各项服务以满足其支持的应用程序功能的需求。这使团队能够适当调整基础设施需求，准确衡量功能成本，并在服务需求激增时保持可用性。 轻松部署 微服务支持持续集成和持续交付，可以轻松尝试新想法，并可以在无法正常运行时回滚。由于故障成本较低，因此可以大胆试验，更轻松地更新代码，并缩短新功能的上市时间。 技术自由 微服务架构不遵循“一刀切”的方法。团队可以自由选择最佳工具来解决他们的具体问题。因此，构建微服务的团队可以为每项作业选择最佳工具。 可重复使用的代码 将软件划分为小型且明确定义的模块，让团队可以将功能用于多种目的。专为某项功能编写的服务可以用作另一项功能的构建块。这样应用程序就可以自行引导，因为开发人员可以创建新功能，而无需从头开始编写代码。 弹性 服务独立性增加了应用程序应对故障的弹性。在整体式架构中，如果一个组件出现故障，可能导致整个应用程序无法运行。通过微服务，应用程序可以通过降低功能而不导致整个应用程序崩溃来处理总体服务故障。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:2","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"SpringCloud框架 Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发， 如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来， 通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 它有以下优点： 把模块拆分，使用接口通信，降低模块之间的耦合度。 把项目拆分成若干个子项目，不同的团队负责不同的子项目。 增加功能时只需要再增加一个子项目，调用其他系统的接口就可以。 可以灵活的进行分布式部署。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"SpringCloud微服务模块分析 通过RuoYi-Cloud来接触微服务的项目 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"服务网关 API Gateway（APIGW / API 网关），顾名思义，是系统对外的唯一入口。API网关封装了系统内部架构，为每个客户端提供定制的API。 近几年来移动应用与企业间互联需求的兴起。从以前单一的Web应用，扩展到多种使用场景，且每种使用场景对后台服务的要求都不尽相同。 这不仅增加了后台服务的响应量，还增加了后台服务的复杂性。随着微服务架构概念的提出，API网关成为了微服务架构的一个标配组件。 路由（Route）：路由是网关最基础的部分，路由信息由 ID、目标 URI、一组断言和一组过滤器组成。如果断言 路由为真，则说明请求的 URI 和配置匹配。 断言（Predicate）：Java8 中的断言函数。Spring Cloud Gateway 中的断言函数输入类型是 Spring 5.0 框架中 的 ServerWebExchange。Spring Cloud Gateway 中的断言函数允许开发者去定义匹配来自于 Http Request 中的任 何信息，比如请求头和参数等。 过滤器（Filter）：一个标准的 Spring Web Filter。Spring Cloud Gateway 中的 Filter 分为两种类型，分别是 Gateway Filter 和 Global Filter。过滤器将会对请求和响应进行处理。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:1","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"认证中心 身份认证，就是判断一个用户是否为合法用户的处理过程。最常用的简单身份认证方式是系统通过核对用户输入的用户名和口令，看其是否与系统中存储的该用户的用户名和口令一致，来判断用户身份是否正确。 登录请求后台接口，为了安全认证，所有请求都携带token信息进行安全认证，比如使用vue、react后者h5开发的app，用于控制可访问系统的资源。**** ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:2","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"注册中心 注册中心在微服务项目中扮演着非常重要的角色，是微服务架构中的纽带，类似于通讯录，它记录了服务和服务地址的映射关系。在分布式架构中，服务会注册到这里，当服务需要调用其它服务时，就到这里找到服务的地址，进行调用。 注册中心解决了服务发现的问题。在没有注册中心时候，服务间调用需要知道被调方的地址或者代理地址。当服务更换部署地址，就不得不修改调用当中指定的地址或者修改代理配置。而有了注册中心之后，每个服务在调用别人的时候只需要知道服务名称就好，继续地址都会通过注册中心同步过来。 RuoYi-Cloud使用的是Nacos ，阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:3","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"配置中心 在微服务架构中，当系统从一个单体应用，被拆分成分布式系统上一个个服务节点后，配置文件也必须跟着迁移（分割），这样配置就分散了，不仅如此，分散中还包含着冗余，总得来说，配置中心就是一种统一管理各种应用配置的基础服务组件。 Nacos是阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 配置中心的服务流程如下： 用户在配置中心更新配置信息。 服务A和服务B及时得到配置更新通知，从配置中心获取配置。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:4","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"服务调用 Feign Feign 是Spring Cloud Netflix组件中的一量级Restful的 HTTP 服务客户端，实现了负载均衡和 Rest 调用的开源框架，封装了Ribbon和RestTemplate, 实现了WebService的面向接口编程，进一步降低了项目的耦合度。 什么是服务调用 顾名思义，就是服务之间的接口互相调用，在微服务架构中很多功能都需要调用多个服务才能完成某一项功能。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:5","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"简介 生产者消费者问题（Producer-consumer problem），也称有限缓冲问题（Bounded-buffer problem），是一个多线程同步问题的经典案例。生产者生成一定量的数据放到缓冲区中，然后重复此过程；与此同时，消费者也在缓冲区消耗这些数据。生产者和消费者之间必须保持同步，要保证生产者不会在缓冲区满时放入数据，消费者也不会在缓冲区空时消耗数据。不够完善的解决方法容易出现死锁的情况，此时进程都在等待唤醒。 下图为生产者和消费者的示意图： ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:1:0","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"解决思想 保证同一资源被多个线程并发访问时的完整性。常用的同步方法是采用信号或加锁机制，保证资源在任意时刻至多被一个线程访问 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:2:0","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"Java实现的几种方式 wait() / notify() 方法 await() / signal() 方法(可重入锁ReentrantLock) BlockingQueue 阻塞队列方法 信号量方法 管道方法 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:2:1","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"代码实现 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:0","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"wait() / notify() 方法 首先，先介绍一下Thread.sleep()和Object.wait()、Object.notify()的区别。 sleep()是Thread类的方法；而wait()，notify()，notifyAll()是Object类中定义的方法；尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的 Thread.sleep()不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep()不会让线程释放锁。如果能够帮助你记忆的话，可以简单认为和锁相关的方法都定义在Object类中，因此调用Thread.sleep()是不会影响锁的相关行为 Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间 Thread.sleep()让线程从 【running】 -\u003e 【阻塞态】 时间结束/interrupt -\u003e 【runnable】;Object.wait()让线程从 【running】 -\u003e 【等待队列】notify -\u003e 【锁池】 -\u003e 【runnable】 wait()和notify()方法的实现，缓冲区满和为空时都调用wait()方法等待，当生产者生产了一个数据或者消费者消费了一个数据之后会通过notify()唤醒所有线程。 import java.util.*; public class Test { // 缓冲区最大容量 private static final int MAX_SIZE = 100; // 计数 private static int count = 0; // 缓冲区 private static LinkedList\u003cInteger\u003e list = new LinkedList\u003cInteger\u003e(); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } // 生产者 public static class Producer implements Runnable { @Override public void run() { while (true) { // 为list上锁 synchronized (list) { // 缓冲区满时，等待 while (list.size() == MAX_SIZE) { try { System.out.println(\"list is full, Producer waiting\"); list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } // 生产数据 count++; System.out.println(\"Producer produce \" + count); list.add(count); // 唤醒消费者 list.notifyAll(); // 等待一段时间再生产 try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } } // 当生产100个数就结束 if (count == 100) { break; } } } } // 消费者 public static class Consumer implements Runnable { @Override public void run() { while (true) { // 为list上锁 synchronized (list) { // 缓冲区空时，等待 while (list.isEmpty()) { try { System.out.println(\"list is empty, Consumer waiting\"); list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } // 消费数据 int temp = list.poll(); System.out.println(\"Consumer consume \" + temp); // 唤醒生产者 list.notifyAll(); } // 当消费100个数就结束 if (count == 100 \u0026\u0026 list.isEmpty()) { break; } } } } } 执行结果如下： 注意： notifyAll()方法可使所有正在等待队列中等待同一共享资源的“全部”线程从等待状态退出，进入可运行状态。此时，优先级最高的那个线程最先执行，但也有可能是随机执行的，这要取决于JVM虚拟机的实现。即最终也只有一个线程能被运行，上述线程优先级都相同，每次运行的线程都不确定是哪个，后来给线程设置优先级后也跟预期不一样，还是要看JVM的具体实现吧。 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:1","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"await() / signal() 方法(可重入锁ReentrantLock) 在JDK5.0之后，Java提供了更加健壮的线程处理机制，包括同步、锁定、线程池等，它们可以实现更细粒度的线程控制。用ReentrantLock和Condition可以实现等待/通知模型，具有更大的灵活性。通过在Lock对象上调用newCondition()方法，将条件变量和一个锁对象进行绑定，进而控制并发程序访问竞争资源的安全。 Condition接口的await()和signal()就是其中用来做同步的两种方法，它们的功能基本上和Object的wait()/ nofity()相同，完全可以取代它们，但是它们和新引入的锁定机制Lock直接挂钩，具有更大的灵活性。通过在Lock对象上调用newCondition()方法，将条件变量和一个锁对象进行绑定，进而控制并发程序访问竞争资源的安全。 import java.util.*; import java.util.concurrent.locks.*; public class Test1 { private static final int MAX_SIZE = 100; private static int count = 0; private static LinkedList\u003cInteger\u003e list = new LinkedList\u003cInteger\u003e(); // 创建锁及其条件 private static final Lock lock = new ReentrantLock(); private static final Condition fullCondition = lock.newCondition(); private static final Condition emptyCondition = lock.newCondition(); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { while (true) { // 上锁 lock.lock(); try { // 缓冲区满时，等待 while (list.size() == MAX_SIZE) { try { System.out.println(\"list is full, Producer waiting\"); fullCondition.await(); } catch (InterruptedException e) { e.printStackTrace(); } } // 生产数据 count++; System.out.println(\"Producer produce \" + count); list.add(count); // 唤醒消费者 emptyCondition.signalAll(); } finally { lock.unlock(); } try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100) { break; } } } } public static class Consumer implements Runnable { @Override public void run() { while (true) { // 上锁 lock.lock(); try { // 缓冲区空时，等待 while (list.isEmpty()) { try { System.out.println(\"list is empty, Consumer waiting\"); emptyCondition.await(); } catch (InterruptedException e) { e.printStackTrace(); } } // 消费数据 int temp = list.poll(); System.out.println(\"Consumer consume \" + temp); // 唤醒生产者 fullCondition.signalAll(); } finally { lock.unlock(); } if (count == 100 \u0026\u0026 list.isEmpty()) { break; } } } } } 运行结果如下：（与第一种方法类似） ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:2","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"BlockingQueue 阻塞队列方法 JDK 1.5 以后新增的 java.util.concurrent包新增了 BlockingQueue 接口。并提供了如下几种阻塞队列实现： java.util.concurrent.ArrayBlockingQueue java.util.concurrent.LinkedBlockingQueue java.util.concurrent.SynchronousQueue java.util.concurrent.PriorityBlockingQueue 实现生产者-消费者模型使用 ArrayBlockingQueue或者 LinkedBlockingQueue即可。 我们这里使用LinkedBlockingQueue，它是一个已经在内部实现了同步的队列，实现方式采用的是我们第2种await()/ signal()方法。它可以在生成对象时指定容量大小。它用于阻塞操作的是put()和take()方法。 put()方法：类似于我们上面的生产者线程，容量达到最大时，自动阻塞。 take()方法：类似于我们上面的消费者线程，容量为0时，自动阻塞。 import java.util.*; import java.util.concurrent.LinkedBlockingQueue; public class Test2 { private static final int MAX_SIZE = 100; private static int count = 0; // 创建阻塞队列 private static LinkedBlockingQueue\u003cInteger\u003e blockingQueue = new LinkedBlockingQueue\u003cInteger\u003e(MAX_SIZE); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { while (true) { try { count++; // 生产数据到阻塞队列 blockingQueue.put(count); System.out.println(\"Producer produce \" + count); } catch (InterruptedException e) { e.printStackTrace(); } try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100) { break; } } } } public static class Consumer implements Runnable { @Override public void run() { while (true) { try { // 从阻塞队列消费数据 int value = blockingQueue.take(); System.out.println(\"Consumer consume \" + value); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100 \u0026\u0026 blockingQueue.isEmpty()) { break; } } } } } ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:3","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"信号量方法 Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源，在操作系统中是一个非常重要的问题，可以用来解决哲学家就餐问题。Java中的Semaphore维护了一个许可集，一开始先设定这个许可集的数量，可以使用acquire()方法获得一个许可，当许可不足时会被阻塞，release()添加一个许可。 Semaphore可以用来构建一些对象池，资源池之类的，比如数据库连接池，我们也可以创建计数为1的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。 在下列代码中，还加入了另外一个mutex信号量，维护生产者消费者之间的同步关系，保证生产者和消费者之间的交替进行 import java.util.*; import java.util.concurrent.Semaphore; public class Test3 { private static final int MAX_SIZE = 100; private static int count = 0; private static LinkedList\u003cInteger\u003e list = new LinkedList\u003cInteger\u003e(); // 创建信号量 final static Semaphore notFull = new Semaphore(MAX_SIZE); final static Semaphore notEmpty = new Semaphore(0); final static Semaphore mutex = new Semaphore(1); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { while (true) { try { // 获取许可 notFull.acquire(); mutex.acquire(); // 生产数据 count++; list.add(count); System.out.println(\"Producer produce \" + count); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 释放许可 mutex.release(); notEmpty.release(); } try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100) { break; } } } } public static class Consumer implements Runnable { @Override public void run() { while (true) { try { // 获取许可 notEmpty.acquire(); mutex.acquire(); // 消费数据 int value = list.poll(); System.out.println(\"Consumer consume \" + value); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 释放许可 mutex.release(); notFull.release(); } if (count == 100 \u0026\u0026 list.isEmpty()) { break; } } } } } ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:4","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"管道方法 在java的io包下，PipedOutputStream和PipedInputStream分别是管道输出流和管道输入流。 它们的作用是让多线程可以通过管道进行线程间的通讯。在使用管道通信时，必须将PipedOutputStream和PipedInputStream配套使用。 使用方法：先创建一个管道输入流和管道输出流，然后将输入流和输出流进行连接，用生产者线程往管道输出流中写入数据，消费者在管道输入流中读取数据，这样就可以实现了不同线程间的相互通讯。 但是这种方式在生产者和生产者、消费者和消费者之间不能保证同步，也就是说在一个生产者和一个消费者的情况下是可以生产者和消费者之间交替运行的，多个生成者和多个消费者者之间则不行。 这种方式只适用于两个线程之间通信，不适合多个线程之间通信。 import java.io.IOException; import java.io.PipedInputStream; import java.io.PipedOutputStream; import java.util.*; public class Test4 { // 控制生产和消费个100次 private static int countP = 0; private static int countS = 0; // 创建管道输入流和管道输出流 final static PipedInputStream pis = new PipedInputStream(); final static PipedOutputStream pos = new PipedOutputStream(); // 将输入流和输出流进行连接 static { try { pis.connect(pos); } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { try { while (true) { // 写入数据 countP++; pos.write(countP); pos.flush(); System.out.println(\"Producer produce \" + countP); Thread.sleep(new Random().nextInt(1000)); if (countP == 100) { break; } } } catch (Exception e) { e.printStackTrace(); } finally { try { // 关闭输出流 pos.close(); } catch (IOException e) { e.printStackTrace(); } } } } public static class Consumer implements Runnable { @Override public void run() { try { while (true) { // 读取数据 countS++; int value = pis.read(); System.out.println(\"Consumer consume \" + value); if (countS == 100) { break; } } } catch (IOException e) { e.printStackTrace(); } finally { try { // 关闭输入流 pis.close(); } catch (IOException e) { e.printStackTrace(); } } } } } ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:5","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"在进行华为机试时遇到了报数游戏的编程题（约瑟夫环），但是看了很多网上的解题都非常长，于是经过不断的学习参考，有了下面这个解题方法，也不知道是不是最好的😭 题目： 100个人围成一圈，每个人有一个编码，编号从1开始到100.他们从1开始依次报数，报到为M的人自动退出圈圈，然后下一个人接着从1开始报数，直到剩余的人数小于M。请问最后剩余的人在原先的编号为多少？ 例如：输入M=3时，输出为：“58，91”；输入M=4时，输出为： “34，45， 97” 解答： import java.util.*; public class test { public static void main(String[] args) { Scanner in = new Scanner(System.in); int n = in.nextInt(); List list = new ArrayList\u003cInteger\u003e(100); for (int i = 1; i \u003c= 100; i++) { list.add(i); } int i = 0; while (list.size() \u003e= n) { i = (i + n - 1) % list.size(); list.remove(i); } list.stream().forEach(System.out::println); } } ","date":"2022-04-17","objectID":"/%E5%8D%8E%E4%B8%BA%E6%9C%BA%E8%AF%95%E9%A2%98-%E6%8A%A5%E6%95%B0%E6%B8%B8%E6%88%8F/:0:0","tags":["面试"],"title":"华为机试题：报数游戏","uri":"/%E5%8D%8E%E4%B8%BA%E6%9C%BA%E8%AF%95%E9%A2%98-%E6%8A%A5%E6%95%B0%E6%B8%B8%E6%88%8F/"},{"categories":["学习笔记"],"content":"本篇笔记主要记录我在学习Java的stream流中记录的笔记 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:0:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"stream是什么 流是从支持数据处理操作的源生成的元素序列，源可以是数组、文件、集合、函数。流不是集合元素，它不是数据结构并不保存数据，它的主要目的在于计算 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:1:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"生成stream的方法 生成流的方式主要有五种 通过集合生成，应用中最常用的一种 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5, 6); Stream\u003cInteger\u003e stream = integerList.stream(); 通过数组生成 int[] intArr = {1, 2, 3, 4, 5, 6}; IntStream stream = Arrays.stream(intArr); 通过Arrays.stream方法生成流，并且该方法生成的流是数值流【即IntStream】而不是 Stream。补充一点使用数值流可以避免计算过程中拆箱装箱，提高性能。Stream API提供了mapToInt、mapToDouble、mapToLong三种方式将对象流【即Stream 】转换成对应的数值流，同时提供了boxed方法将数值流转换为对象流 通过值生成 // 通过Stream的of方法生成流，通过Stream的empty方法可以生成一个空流 Stream\u003cInteger\u003e stream = Stream.of(1, 2, 3, 4, 5, 6); 通过文件生成 // 通过Files.line方法得到一个流，并且得到的每个流是给定文件中的一行 Stream\u003cString\u003e lines = Files.lines(Paths.get(\"data.txt\"), Charset.defaultCharset()); 通过函数生成 // 1.iterator // terate方法接受两个参数，第一个为初始化值，第二个为进行的函数操作，因为iterator生成的流为无限流，通过limit方法对流进行了截断，只生成5个偶数 Stream\u003cInteger\u003e stream = Stream.iterate(0, n -\u003e n + 2).limit(5); // 2.generator // generate方法接受一个参数，方法参数类型为Supplier ，由它为流提供值。generate生成的流也是无限流，因此通过limit对流进行了截断 Stream\u003cDouble\u003e stream = Stream.generate(Math::random).limit(5); ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:2:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"stream的操作类型 中间操作 一个流可以后面跟随零个或多个中间操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的，仅仅调用到这类方法，并没有真正开始流的遍历，真正的遍历需等到终端操作时，常见的中间操作有下面即将介绍的 filter、map 等。 终端操作 一个流有且只能有一个终端操作，当这个操作执行后，流就被关闭了，无法再被操作，因此一个流只能被遍历一次，若想在遍历需要通过源数据在生成流。终端操作的执行，才会真正开始流的遍历。如下面即将介绍的 count、collect 等。 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:3:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"stream的使用 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:4:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"中间操作 filter 筛选 // 通过使用filter方法进行条件筛选，filter的方法参数为一个条件（过滤保留函数返回值为 true 的元素） List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5, 6); Stream\u003cInteger\u003e stream = integerList.stream().filter(i -\u003e i \u003e 3); // 结果为：4,5,6 distinct 去重 // 通过distinct方法快速去除重复的元素 List\u003cInteger\u003e integerList = Arrays.asList(1, 1, 2, 3, 4, 5); Stream\u003cInteger\u003e stream = integerList.stream().distinct(); // 结果为：1,2,3,4,5 limit 返回指定流个数 // 通过limit方法指定返回流的个数，limit的参数值必须 \u003e=0，否则将会抛出异常。 List\u003cInteger\u003e integerList = Arrays.asList(1, 1, 2, 3, 4, 5); Stream\u003cInteger\u003e stream = integerList.stream().limit(3); 结果为： 1,1,2 skip 跳过流中的元素 // 通过skip方法跳过流中的元素，skip的参数值必须\u003e=0，否则将会抛出异常 List\u003cInteger\u003e integerList = Arrays.asList(1, 1, 2, 3, 4, 5); Stream\u003cInteger\u003e stream = integerList.stream().skip(2); // 结果为： 2,3,4,5 map 流映射 // 所谓流映射就是将接受的元素映射成另外一个元素 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); List\u003cInteger\u003e collect = stringList.stream() .map(String::length) .collect(Collectors.toList()); // 通过map方法可以完成映射，该例子完成中 String -\u003e Integer 的映射 // 结果为：[6, 7, 2, 6] flatMap 流转换 // 将一个流中的每个值都转换为另一个流 List\u003cString\u003e wordList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); List\u003cString\u003e strList = wordList.stream() .map(w -\u003e w.split(\" \")) .flatMap(Arrays::stream) .distinct() .collect(Collectors.toList()); // map(w -\u003e w.split(\" \")) 的返回值为 Stream\u003cString[]\u003e，想获取 Stream，可以通过flatMap方法完成 Stream -\u003eStream 的转换 // 结果为：[Java, 8, Lambdas, In, Action] allMatch 匹配所有元素 // 匹配流中所有元素是否满足条件 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); if (integerList.stream().allMatch(i -\u003e i \u003e 3)) { System.out.println(\"所有元素值都大于3\"); } else { System.out.println(\"并非所有元素值都大于3\"); } // 结果为：并非所有元素值都大于3 anyMatch匹配其中一个 // 匹配流中是否存在一个满足条件的元素 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); if (integerList.stream().anyMatch(i -\u003e i \u003e 3)) { System.out.println(\"存在值大于3的元素\"); } else { System.out.println(\"不存在值大于3的元素\"); } // 结果为：存在值大于3的元素 // 上述代码等同于： for (Integer i : integerList) { if (i \u003e 3) { System.out.println(\"存在大于3的值\"); break; } } noneMatch全部不匹配 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); if (integerList.stream().noneMatch(i -\u003e i \u003e 3)) { System.out.println(\"值都小于3的元素\"); } else { System.out.println(\"值不都小于3的元素\"); } ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:4:1","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"终端操作 count 统计流中元素个数 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); Long result = integerList.stream().count(); // 结果为：5 findFirst 查找第一个 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); Optional\u003cInteger\u003e result = integerList.stream().filter(i -\u003e i \u003e 3).findFirst(); System.out.println(result.orElse(-1)); // 结果为：4 findAny 随机查找一个 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); Optional\u003cInteger\u003e result = integerList.stream().filter(i -\u003e i \u003e 3).findAny(); System.out.println(result.orElse(-1)); // 结果为：4 // 通过findAny方法查找到其中一个大于三的元素并打印，因为内部进行优化的原因，当找到第一个满足大于三的元素时就结束，该方法结果和findFirst方法结果一样。提供findAny方法是为了更好的利用并行流，findFirst方法在并行上限制更多【本篇文章将不介绍并行流】 reduce 将流中的元素组合 用于求和 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); int sum = integerList.stream() .reduce(0, Integer::sum); // 结果为：15 // reduce接受两个参数，一个初始值这里是0，一个 BinaryOperatoraccumulator 来将两个元素结合起来产生一个新值，另外reduce方法还有一个没有初始化值的重载方法 用于取得最大和最小值 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); Optional\u003cInteger\u003e min = stringList.stream() .map(String::length) .reduce(Integer::min); Optional\u003cInteger\u003e max = stringList.stream() .map(String::length) .reduce(Integer::max); // 结果为：Optional[2] 和 Optional[7] min/max 获取最小最大值 // 写法1 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); Optional\u003cInteger\u003e min = stringList.stream() .map(String::length) .min(Integer::compareTo); Optional\u003cInteger\u003e max = stringList.stream() .map(String::length) .max(Integer::compareTo); // 写法2 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); OptionalInt min = stringList.stream() .mapToInt(String::length) .min(); OptionalInt max = stringList.stream() .mapToInt(String::length) .max(); // 使用reduce List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); Optional\u003cInteger\u003e min = stringList.stream() .map(String::length) .reduce(Integer::min); Optional\u003cInteger\u003e max = stringList.stream() .map(String::length) .reduce(Integer::max); sum / summingxxx / reduce 求和 // 方式1：sum List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); int sum = stringList.stream() .mapToInt(String::length) .sum(); // 方式2：summingInt List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); // 如果数据类型为double、long，则通过summingDouble、summingLong方法进行求和 int sum = stringList.stream() .collect(summingInt(String::length)); // 方式3：reduce List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); int sum = stringList.stream() .map(String::length) .reduce(0, Integer::sum); 在上面求和、求最大值、最小值的时候，对于相同操作有不同的方法可以选择执行。可以选择collect、reduce、min/max/sum方法，推荐使用min、max、sum方法。因为它最简洁易读，同时通过mapToInt将对象流转换为数值流，避免了装箱和拆箱操作 averagingxxx 求平均值 // averagingxxx List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); double average = stringList.stream() .collect(averagingInt(String::length)); summarizingxxx 同时求总和、平均值、最大值、最小值 // 如果数据类型为double、long，则通过summarizingDouble、summarizingLong方法 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); IntSummaryStatistics intSummaryStatistics = stringList.stream() .collect(summarizingInt(String::length)); double average = intSummaryStatistics.getAverage(); // 获取平均值 int min = intSummaryStatistics.getMin(); // 获取最小值 int max = intSummaryStatistics.getMax(); // 获取最大值 long sum = intSummaryStatistics.getSum(); // 获取总和 foreach 遍历 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); stringList.stream().forEach(System.out::println); collect 返回集合 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); List\u003cInteger\u003e intList = stringList.stream() .map(String::length) .collect(toList()); Set\u003cInteger\u003e intSet = stringList.stream() .map(String::length) .collect(toSet()); // 等价 List\u003cInteger\u003e intList = new ArrayList\u003c\u003e(); Set\u003cInteger\u003e intSet = new HashSet\u003c\u003e(); for (String item : stringList) { intList.add(item.length()); intSet.add(item.length()); } 通过遍历和返回集合的使用发现流只是把原来的外部迭代放到了内部进行，这也是流的主要特点之一。内部迭代可以减","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:4:2","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"SQL 行转列，列转行 行列转换在做报表分析时还是经常会遇到的，今天就说一下如何实现行列转换吧。 行列转换就是如下图所示两种展示形式的互相转换 ","date":"2022-04-03","objectID":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/:0:0","tags":["SQL"],"title":"数据库Tip:行转列、列转行","uri":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/"},{"categories":["学习笔记"],"content":"行转列 假如我们有下表： 使用PIVOT实现 SELECT*FROMstudentPIVOT(SUM(score)FORsubjectIN(语文,数学,英语)) 通过上面 SQL 语句即可得到下面的结果 PIVOT 后跟一个聚合函数来拿到结果，FOR 后面跟的科目是我们要转换的列，这样的话科目中的语文、数学、英语就就被转换为列。IN 后面跟的就是具体的科目值。 分组后使用case进行条件判断处理 当然我们也可以用 CASE WHEN 得到同样的结果，就是写起来麻烦一点。 SELECTname,MAX(CASEWHENsubject='语文'THENscoreELSE0END)AS\"语文\",MAX(CASEWHENsubject='数学'THENscoreELSE0END)AS\"数学\",MAX(CASEWHENsubject='英语'THENscoreELSE0END)AS\"英语\"FROMstudentGROUPBYname 使用 CASE WHEN 可以得到和 PIVOT 同样的结果，没有 PIVOT 简单直观。 ","date":"2022-04-03","objectID":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/:1:0","tags":["SQL"],"title":"数据库Tip:行转列、列转行","uri":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/"},{"categories":["学习笔记"],"content":"列转行 假设我们有下表 student1 使用UNPIVOT实现 SELECT*FROMstudent1UNPIVOT(scoreFORsubjectIN(\"语文\",\"数学\",\"英语\")) 通过 UNPIVOT 即可得到如下结果： 分组后使用case进行条件判断处理 我们也可以使用下面方法得到同样结果 SELECTNAME,'语文'ASsubject,MAX(\"语文\")ASscoreFROMstudent1GROUPBYNAMEUNIONSELECTNAME,'数学'ASsubject,MAX(\"数学\")ASscoreFROMstudent1GROUPBYNAMEUNIONSELECTNAME,'英语'ASsubject,MAX(\"英语\")ASscoreFROMstudent1GROUPBYNAME UNION \u0026 UNION ALL UNION 操作符用于合并两个或多个 SELECT 语句的结果集。 请注意，UNION 内部的 SELECT 语句必须拥有相同数量的列。列也必须拥有相似的数据类型。同时，每条 SELECT 语句中的列的顺序必须相同。 SQL UNION 语法 SELECTcolumn_name(s)FROMtable_name1UNIONSELECTcolumn_name(s)FROMtable_name2 **注释：**默认地，UNION 操作符选取不同的值。如果允许重复的值，请使用 UNION ALL。 SQL UNION ALL 语法 SELECTcolumn_name(s)FROMtable_name1UNIONALLSELECTcolumn_name(s)FROMtable_name2 另外，UNION 结果集中的列名总是等于 UNION 中第一个 SELECT 语句中的列名。 ","date":"2022-04-03","objectID":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/:2:0","tags":["SQL"],"title":"数据库Tip:行转列、列转行","uri":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/"},{"categories":["收藏分享"],"content":"Yapi简介 Yapi 由 YMFE 开源，旨在为开发、产品、测试人员提供更优雅的接口管理服务，可以帮助开发者轻松创建、发布、维护 API 权限管理 YApi 成熟的团队管理扁平化项目权限配置满足各类企业的需求 可视化接口管理 基于 websocket 的多人协作接口编辑功能和类 postman 测试工具，让多人协作成倍提升开发效率 Mock Server 易用的 Mock Server，再也不用担心 mock 数据的生成了 自动化测试 完善的接口自动化测试,保证数据的正确性 数据导入 支持导入 swagger, postman, har 数据格式，方便迁移旧项目 插件机制 强大的插件机制，满足各类业务需求 ","date":"2022-04-03","objectID":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/:1:0","tags":["Yapi"],"title":"分享一个可以私有部署的接口管理系统Yapi","uri":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/"},{"categories":["收藏分享"],"content":"Yapi使用Docker安装 由于内网开发环境，导致安装各种环境或者系统非常不方便，所以个人比较推荐通过docker来安装 拉取镜像 docker pull registry.cn-hangzhou.aliyuncs.com/anoy/yapi 创建挂载目录 mkdir -p /data/yapi/mongodata 运行专用mongo（也可以放在已有的mongo） docker run -d --name yapimongo --restart always -v /data/yapi/mongodata:/data/db mongo 初始化 Yapi 数据库索引及管理员账号 docker run -it --rm --link yapimongo:mongo --entrypoint npm --workdir /api/vendors registry.cn-hangzhou.aliyuncs.com/anoy/yapi run install-server **–rm：**在 Docker 容器退出时，默认容器内部的文件系统仍然被保留，以方便调试并保留用户数据。但是，对于 foreground 容器，由于其只是在开发调试过程中短期运行，其用户数据并无保留的必要，因而可以在容器启动时设置 –rm 选项，这样在容器退出时就能够自动清理容器内部的文件系统 **–entrypoint：**类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。但是, 如果运行 docker run 时使用了 –entrypoint 选项，将覆盖 ENTRYPOINT 指令指定的程序 **–workdir：**指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在 **run：**用于执行后面跟着的命令行命令 创建Yapi容器并启动 docker run -d --name yapi --restart=always --link yapimongo:mongo --workdir /api/vendors -p 3001:3000 registry.cn-hangzhou.aliyuncs.com/anoy/yapi server/app.js **–link：**用于容器直接的互通 使用Yapi 访问 http://localhost:3000 登录账号admin@admin.com，密码ymfe.org Yapi配置 # 进入Yapi容器中 docker exec -it yapi /bin/bash # 修改配置文件 vi ../config.json # 修改内容如下 { \"port\": \"3000\", \"adminAccount\": \"admin@admin.com\", \"closeRegister\":true, # 配置禁用注册，主要是添加这句配置 \"db\": { # 配置MongoDB \"servername\": \"mongo\", \"DATABASE\": \"yapi\", \"port\": 27017 } } # 退出 exit # 重启容器 docker restart yapi 本文参考至： docker安装yapi 具体使用可参考官方教程 ","date":"2022-04-03","objectID":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/:2:0","tags":["Yapi"],"title":"分享一个可以私有部署的接口管理系统Yapi","uri":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/"},{"categories":["实践笔记"],"content":"本篇文章记录本人搭建CI\u0026CD实现持续集成和持续部署 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:0:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"1.使用docker安装gitlab ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"下载镜像 （使用中文社区版） docker pull twang2218/gitlab-ce-zh ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:1","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"创建所需目录为后续挂载文件 进入所需目录后，打开PowerShell，通过以下命令进行目录创建 mkdir -p gitlab/etc 、 mkdir -p gitlab/etc 、 mkdir -p gitlab/etc 目录结构如下图所示 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:2","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"启动容器 镜像下载完成后可通过docker images查看下载结果，再通过镜像启动为容器 docker run -d -p 9443:443 -p 9080:80 -p 9022:22 --restart always --name testgitlab -v D:\\testgitlab\\gitlab\\etc:/etc/gitlab -v D:\\testgitlab\\gitlab\\log:/var/log/gitlab -v D:\\testgitlab\\gitlab\\data:/var/opt/gitlab --privileged=true twang2218/gitlab-ce-zh # 执行完成后会返回一串字符串 其中： **-d：**后台执行 **-p：**端口映射 **–restart：**重启机制 **–name：**容器名称 **-v：**挂载文件，使得容器内文件在宿主机内有映射 **–privileged：**使得容器获取宿主机root权限 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:3","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"进入容器，修改配置 输入命令 docker exec -it testgitlab bash 即可进入刚刚创建好的容器 修改gitlab.rb配置的两种方式：1. 进入挂载好的etc目录下找到gitlab.rb文件进行修改；2. 通过进入容器内进行命令行vi /etc/gitlab/gitlab.rb 修改 # 整个gitlab.rb都是注释了的，我们可以按需加入我们的配置 # 1. gitlab访问地址，可以写域名。如果端口不写的话默认为80端口 eaxternal_url 'http://192.168.3.12:9080' # 2. ssh主机ip gitlab_rails['gitlab_ssh_host'] = '192.168.3.12' # 3. ssh连接端口 gitlab_rails['gitlab_shell_ssh_port'] = 9022 # 4. 防止内存占用过大，限制线程数 unicorn['worker_processes'] = 2 修改gitlab.yml配置（这一步原本不是必须的，因为gitlab.rb内配置会覆盖这个，为了防止没有成功覆盖所以我在这里进行配置，当然你也可以选择不修改gitlab.rb直接修改这里） 通过命令行vi /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml修改，或者找到挂载文件修改 修改上图红框配置 让修改后的配置生效，并重启 gitlab-ctl reconfigure 、 gitlab-ctl restart 、 exit（退出容器命令行） 或者重启容器docker restart testgitlab ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:4","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"访问gitlab 输入http://192.168.3.12:9080打开页面（ip请输入前面设置的），默认账户root，密码需要重新设置至少8位 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:5","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"2.使用docker安装jenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"下载镜像 docker pull jenkins/jenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:1","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"创建所需目录为后续挂载文件 在服务器上先创建一个jenkins工作目录 /var/jenkins_mount，赋予相应权限，稍后我们将jenkins容器目录挂载到这个目录上，这样我们就可以很方便地对容器内的配置文件进行修改。如何后续在容器内修改的话会非常麻烦，由于容器中无vi命令。 mkdir -p /var/jenkins_mount 、 chmod 777 /var/jenkins_mount ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:2","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"启动容器 docker run -d -p 10240:8080 -p 10241:50000 -v D:\\testjenkins\\jenkins_mount:/var/jenkins_home -v /etc/localtime:/etc/localtime --name testjenkins jenkins/jenkins # 其中-v /etc/localtime:/etc/localtime让容器使用和服务器同样的时间设置 可以通过docker ps来查看启动情况 可以通过docker logs testjenkins来查看容器日志 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:3","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"修改配置 进入刚刚挂载的文件，修改hudson.model.UpdateCenter.xml文件 将 url 修改为 清华大学官方镜像：https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json ，配置镜像加速 还需要修改default.json文件，位置为cd /var/jenkins_home/updates 使用sed命令修改default.json linux下： sed -i 's/http:\\/\\/updates.jenkins-ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' default.json \u0026\u0026 sed -i 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' default.json mac下： sed -i \"\" 's/http:\\/\\/updates.jenkins-ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' default.json \u0026\u0026 sed -i \"\" 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' default.json 重启容器 docker restart testjenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:4","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"访问jenkins 输入http://localhost:10240打开页面 选择默认插件安装即可 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:5","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"3.gitlab + jenkins 为了实现自动持续构建, 不需要人工操作 ( 留人工操作用于处理特殊情况 )，通过gitlab+jenkins实现CI\u0026CD，具体流程如下 开发提交代码 开发对需要发布的版本打上 Tag 触发 GitLab 的 tag push 事件, 调用 Webhook Webhook 触发 Jenkins 的构建任务 Jenkins 构建完项目可以按版本号上传到仓库、部署、通知相关人员等等 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"配置gitlab 建一个测试项目 test ，随便 commit 一些内容，比如通过网页添加README.md 创建账号的 access token ，用于 Jenkins 调用 GitLab 的 API 记下生成的 access token , 后面需要用到！！！且它只会展示一次，请记录好！！！ ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:1","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"配置jenkins 安装环境所需插件 Git Parameter ( 用于参数化构建中动态获取项目分支 ) Generic Webhook Trigger ( 用于解析 Webhook 传过来的参数 ) GitLab ( 用于推送构建结果给 GitLab ) 添加 GitLab 凭据 在系统配置中配置gitlab 创建新的FreeStyle任务 General 勾选 参数化构建过程, 添加 Git Parameter 类型的参数 ref , 这样构建的时候就可以指定分支进行构建 源码管理 选择 Git , 添加项目地址和授权方式 ( 帐号密码 或者 ssh key ) , 分支填写构建参数 $ref 构建触发器 选择 Generic Webhook Trigger 方式用于解析 GitLab 推过来的详细参数 ( jsonpath 在线测试 ) 。其他触发方式中: Trigger builds remotely 是 Jenkins 自带的, Build when a change is pushed to GitLab 是 GitLab 插件 提供的, 都属于简单的触发构建, 无法做复杂的处理 Optional filter 虽然 Generic Webhook Trigger 提供了 Token 参数进行鉴权, 但为了避免不同项目进行混调 ( 比如 A 项目提交代码却触发了 B 项目的构建) , 还要对请求做下过滤。Optional filter 中 Text 填写需要校验的内容 ( 可使用变量 ) , Expression 使用正则表达式对 Text 进行匹配, 匹配成功才允许触发构建 构建 构建内容按自己实际的项目类型进行调整, 使用 Maven 插件 或 脚本 等等 构建后操作 构建后操作添加 Publish build status to GitLab 动作, 实现构建结束后通知构建结果给 GitLab 在GitLab的项目页面中, 添加一个Webhook 添加一个 Webhook ( http://JENKINS_URL/generic-webhook-trigger/invoke?token=\u003c上面 Jenkins 项目配置中的 token\u003e ) , 触发器选择 标签推送事件。因为日常开发中 push 操作比较频繁而且不是每个版本都需要构建, 所以只针对需要构建的版本打上 Tag 就好了 http://172.20.10.7:10240//generic-webhook-trigger/invoke?token=d63ad84eb18cb04d4459ec347a196dce 创建完使用 test 按钮 先测试下, 可能会出现下面的错误 Requests to the local network are not allowed 通过下面方法解决 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:2","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"测试效果 将代码拉下来在本地操作通过IDEA进行操作 然后使用快捷键 Cmd + Shift + K 调出 Push 窗口 , 把 Tag 推送到 GitLab 中 回到 GitLab 页面可以看到触发了 Webhook , View details 查看请求详情, Response body 中 triggered 字段值为 true 则表示成功触发了 Jenkins 进行构建 注意: 每添加一个 Tag 就会触发一次事件, 不管是不是一起 push 的。所以一次 push 多个 Tag 会触发 Jenkins 进行多次构建。不过 Jenkins 已经做了处理, 默认串行执行任务 ( 一个任务结束再执行下一个 ) , 而且在构建前有一个 pending 状态, 此时被多次触发会进行合并, 并取首次触发的参数, 如下图所示: ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:3","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"关于 Tag 的几点说明 推送 Tag 到远端的时候, 远端已存在 ( 同名 ) 的 Tag 不会被添加到远端 拉取远端的 Tag 时, 本地已存在 ( 同名 ) 的 Tag 不会添加到本地 拉取远端的 Tag 时, 本地不会删除远端已删除的 Tag , 需要同步远端的 Tag 可以先删除本地所有 Tag 再 pull 删除 Tag 也会推送事件, 要做好过滤 ( 上面配置中已使用 commitsId 字段进行过滤 ) 本篇文章产考下列文章： docker安装gitlab docker安装jenkins docker中jenkins插件加速 整合gitlab+jenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:4","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"Docker 简介 Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker 的应用场景： Web 应用的自动化打包和发布。 自动化测试和持续集成、发布。 在服务型环境中部署和调整数据库或其他的后台应用。 从头编译或者扩展现有的 OpenShift 或 Cloud Foundry 平台来搭建自己的 PaaS 环境。 Docker 的优点： Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 快速，一致地交付您的应用程序 响应式部署和扩展 在同一硬件上运行更多工作负载 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:1:0","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"Docker 命令 详细命令可以查看Docker 命令大全 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:0","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"常用镜像命令 1. 查看服务器中 Docker 镜像列表 docker images 2. 搜索镜像 docker search 镜像名 3. 拉取镜像（不加tag(版本号)就默认拉取Docker仓库中该镜像的最新版本latest; 加:tag则是拉取指定版本） docker pull 镜像名 docker pull 镜像名:v1 4. 运行镜像 docker run -itd --name=\"nginx\" --restart=always -p 80:80 -v /data:/data nginx:latest 5. 删除镜像 docker rmi -f 镜像名/镜像ID 6. 保存镜像 docker save nginx -o /nginx.tar 7. 加载镜像 docker load -i 镜像文件位置 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:1","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"常用容器命令 1. 查看正在运行容器列表 docker ps 2. 查看所有容器 docker ps -a 3. 停止容器 docker stop 容器名/容器ID 4. 删除容器 docker rm -f 容器名/容器ID 5. 进入容器方式 docker exec -it 容器名/容器ID /bin/bash exit/ctl+p+q #退出 6. 重启容器 docker restart 容器名/容器ID 7. 启动容器 docker start 容器名/容器ID 8. kill 容器 docker kill 容器名/容器ID 9. 容器文件拷贝 docker cp 容器名/ID:容器内路径 容器外路径 #容器内拷出 docker cp 容器外路径 容器名/ID:容器内路径 #容器外拷入 10. 查看容器日志 docker logs -f --tail=100 容器 #tail查看末尾多少行 默认all 11. 修改存在容器的启动配置 docker update --restart=always 容器 12. 更换容器名 docker rename 容器 容器新名字 13. 通过容器提交镜像！！！### docker commit -a=\"提交作者\" -m=\"提交信息\" 容器 提交镜像:tag ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:2","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"Docker 运维命令 1. 查看Docker工作目录 sudo docker info | grep \"Docker Root Dir\" 2. 查看Docker磁盘占用总体情况 du -hs /var/lib/docker/ 3. 查看Docker的磁盘使用具体情况 docker system df 4. 删除无用的容器和镜像 docker rm `docker ps -a | grep Exited | awk '{print $1}'` docker rmi -f `docker images | grep '\u003cnone\u003e' | awk '{print $3}'` 5. 清除所有无容器使用的镜像 docker system prune -a 6. 查找大文件 find / -type f -size +100M -print0 | xargs -0 du -h | sort -nr 7. 查找指定Docker使用目录下大于指定大小文件 find / -type f -size +100M -print0 | xargs -0 du -h | sort -nr | grep '/var/lib/docker/overlap2/*' ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:3","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"构建一个带libgdiplus的DotNetCore基础镜像 通过Docker拉取一个.netcore3.1基础镜像：docker pull mcr.microsoft.com/dotnet/aspnet:3.1 进入容器：docker run -it mcr.microsoft.com/dotnet/aspnet:3.1 /bin/bash 安装libgdiplus： apt-get update -y apt-get install -y libgdiplus apt-get clean ln -s /usr/lib/libgdiplus.so /usr/lib/gdiplus.dll 提交为新镜像：docker commit -a=\"Lesan\" -m=\"added libgdiplus based on .netcore3.1\" 28a66ebccd55 dotnetcore-with-libgdiplus:v3.1 修改项目Dockerfile基础镜像为刚刚构建的自定义镜像dotnetcore-with-libgdiplus:v3.1 借鉴参考以下文章： https://blog.csdn.net/leilei1366615/article/details/106267225 https://www.runoob.com/docker/docker-command-manual.html https://blog.csdn.net/u014374975/article/details/115436174 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:3:0","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"本笔记为Docker与Kubernetes的学习笔记 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:0:0","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"将.NET Core的项目发布为Docker镜像 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:0","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"通过VS支持创建Docker镜像 第一步，创建一个空的.NET Core项目，用来测试 第二步，为项目添加Docker支持 添加成功后会在项目根目录创建Dockerfile，以及在Docker Desktop中创建对应的image及container，如下图所示 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:1","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"通过已发布的文件包创建Docker镜像 第一步，将项目发布到文件夹 第二步，去到发布的文件夹下，添加Dockerfile来构建镜像 FROMmcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base# 配置工作目录WORKDIR/app# 暴露容器端口EXPOSE80EXPOSE443# 设置时区ENV TZ = Asia/shanghaiRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026\u0026 $TZ \u003e /etc/timezone #执行命令# 复制文件到工作目录COPY . .#指定执行程序ENTRYPOINT [\"dotnet\", \"DockerAndK8s.dll\"] 第三步，通过Docker命令进行构建镜像 第五步，启动镜像 最后，在浏览器中访问可以发现成功部署 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:2","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"将镜像发布到Docker Hub 通过命令行进行 F:\\Visual Studio\\repos\\DockerAndK8s\\output\u003edocker tag dockerandk8s:v1 lesan0u0/dockerandk8s:v1 F:\\Visual Studio\\repos\\DockerAndK8s\\output\u003edocker push lesan0u0/dockerandk8s:v1 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:3","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"添加Kubernetes支持 Kubernetes的安装与使用通过本篇文章 ASP.NET Core on K8S学习初探（1）K8S单节点环境搭建 第一步，打开控制面板 kubectl create -f kubernetes-dashboard.yaml // 部署Kubernetes dashboard kubectl get pod -n kubernetes-dashboard // 检查 kubernetes-dashboard 应用状态 kubectl proxy // 开启 API Server 访问代理 //dashboard地址 http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ // 控制台访问令牌 $TOKEN=((kubectl -n kube-system describe secret default | Select-String \"token:\") -split \" +\")[1] kubectl config set-credentials docker-desktop --token=\"${TOKEN}\" echo $TOKEN 第二步，准备Department YAML apiVersion:apps/v1kind:Deploymentmetadata:name:dockerandk8snamespace:testlabels:name:dockerandk8sspec:replicas:2selector:matchLabels:name:dockerandk8stemplate:metadata:labels:name:dockerandk8sspec:containers:- name:dockerandk8simage:lesan0u0/dockerandk8s:v1ports:- containerPort:80imagePullPolicy:Always---kind:ServiceapiVersion:v1metadata:name:dockerandk8snamespace:testspec:type:NodePortports:- port:80targetPort:80selector:name:dockerandk8s 第三步，通过kubectl部署到K8S kubectl create -f deploy.yaml //部署 kubectl get svc -n aspnetcore //验证 可以通过Dashboard来查看部署情况 最后，大功告成 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:2:0","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["学习笔记"],"content":"简介 Java集合框架为程序员提供了预先包装的数据结构和算法来操纵他们。这使得我们使用复杂的数据结构变得非常的方便，并且这些集合框架是高性能的，基本集合（动态数组，链表，树，哈希表）的实现也必须是高效的；允许不同类型的集合，以类似的方式工作，具有高度的互操作性。 从上面的集合框架图可以看到，Java 集合框架主要包括两种类型的容器，一种是集合（Collection），存储一个元素集合，另一种是图（Map），存储键/值对映射。Collection 接口又有 3 种子类型，List、Set 和 Queue，再下面是一些抽象类，最后是具体实现类，常用的有 ArrayList、LinkedList、HashSet、LinkedHashSet、HashMap、LinkedHashMap 等等。 集合框架是一个用来代表和操纵集合的统一架构。所有的集合框架都包含如下内容： **接口：**是代表集合的抽象数据类型。例如 Collection、List、Set、Map 等。之所以定义多个接口，是为了以不同的方式操作集合对象 **实现（类）：**是集合接口的具体实现。从本质上讲，它们是可重复使用的数据结构，例如：ArrayList、LinkedList、HashSet、HashMap。 **算法：**是实现集合接口的对象里的方法执行的一些有用的计算，例如：搜索和排序。这些算法被称为多态，那是因为相同的方法可以在相似的接口上有着不同的实现。 除了集合，该框架也定义了几个 Map 接口和类。Map 里存储的是键/值对。尽管 Map 不是集合，但是它们完全整合在集合中。 Java 集合框架提供了一套性能优良，使用方便的接口和类，java集合框架位于java.util包中， 所以当使用集合框架的时候需要进行导包。 下面我们就分别详细介绍集合框架中的每个数据结构！ ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:1:0","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"List接口 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:0","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"简介 List集合代表一个有序、可重复集合，集合中每个元素都有其对应的顺序索引。List集合默认按照元素的添加顺序设置元素的索引，可以通过索引（类似数组的下标）来访问指定位置的集合元素。 实现List接口的集合主要有：ArrayList、LinkedList、Vector、Stack。 |–List:元素是有序的(怎么存的就怎么取出来，顺序不会乱)，元素可以重复（角标1上有个3，角标2上也可以有个3）因为该集合体系有索引 ​ |– ArrayList：底层的数据结构使用的是数组结构（数组长度是可变的百分之五十延长）（特点是查询很快，但增删较慢）线程不同步 ​ |– LinkedList：底层的数据结构是链表结构（特点是查询较慢，增删较快） 线程不同步 ​ |– Vector：底层是数组数据结构 线程同步（数组长度是可变的百分之百延长）（无论查询还是增删都很慢，被ArrayList替代了） List排序通用方法 Collections.sort(list, new Comparator() { public int compare(Student s1, Student s2) { //先按成绩 降序 排序，如果成绩一样的话按id 升序 排序 if(s1.getScore()\u003es2.getScore()){ //greater return -1; }else if(s1.getScore()==s2.getScore()){ //equals if(s1.getId()\u003es2.getId()){ return 1; }else if(s1.getId()==s2.getId()){ return 0; }else{ return -1; } }else{ //less return 1; }　} }); List通用方法 List list = new ArrayList(); // 向列表的尾部追加指定的元素 list.add(\"lwc\"); // 在列表的指定位置插入指定元素 list.add(1, \"nxj\"); // 追加指定 collection 中的所有元素到此列表的结尾 list.addAll(new ArrayList()); // 从列表中移除所有元素 list.clear(); // 如果列表包含指定的元素,则返回true list.contains(\"nxj\"); // 如果列表包含指定 collection 的所有元素,则返回 true list.containsAll(new ArrayList()); // 比较指定的对象与列表是否相等 list.equals(new ArrayList()); // 返回列表中指定位置的元素 list.get(0); // 返回列表的哈希码值 list.hashCode(); // 返回列表中首次出现指定元素的索引,如果列表不包含此元素,则返回 -1 list.indexOf(\"lwc\"); // 返回列表中最后出现指定元素的索引,如果列表不包含此元素,则返回 -1 list.lastIndexOf(\"lwc\"); // 如果列表不包含元素,则返回 true list.isEmpty(); // 移除列表中指定位置的元素 list.remove(0); // 移除列表中出现的首个指定元素 list.remove(\"lwc\"); // 从列表中移除指定 collection 中包含的所有元素 list.removeAll(new ArrayList()); // 用指定元素替换列表中指定位置的元素 list.set(0, \"lp\"); // 返回列表中的元素数 list.size(); // 返回列表中指定的fromIndex(包括)和toIndex(不包括)之间的部分视图 list.subList(1, 2); // 返回以正确顺序包含列表中的所有元素的数组 list.toArray(); // 返回以正确顺序包含列表中所有元素的数组 list.toArray(new String[] { \"a\", \"b\" }); List通用遍历 // 迭代方式 // 第一种for-size循环 for (int i = 0; i \u003c sites.size(); i++) { System.out.println(sites.get(i)); } // 第二种for-each循环 for (String i : sites) { System.out.println(i); } // 第三种Iterator循环 for(Iterator\u003cString\u003e it = sites.iterator(); it.hasNext();){ String value=it.next(); } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:1","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"ArrayList类 ArrayList是一个动态数组，也是我们最常用的集合，是List类的典型实现。它允许任何符合规则的元素插入甚至包括null。每一个ArrayList都有一个初始容量（10），该容量代表了数组的大小。随着容器中的元素不断增加，容器的大小也会随着增加。在每次向容器中增加元素的同时都会进行容量检查，当快溢出时，就会进行扩容操作。所以如果我们明确所插入元素的多少，最好指定一个初始容量值，避免过多的进行扩容操作而浪费时间、效率。 示例： import java.util.ArrayList; public class Test { public static void main(String[] args) { ArrayList\u003cString\u003e sites = new ArrayList\u003cString\u003e(); // 创建ArrayList sites.add(\"Google\"); // 添加元素 sites.add(\"Runoob\"); sites.add(\"Taobao\"); sites.add(\"Weibo\"); sites.set(2, \"Wiki\"); // 修改元素 sites.remove(3); // 删除元素，下标为3的元素，就是第四个元素 System.out.println(sites.get(1)); // 访问元素 System.out.println(sites.size()); // 获取大小 // 将 lambda 表达式传递给 forEach numbers.forEach((e) -\u003e { e = e * 10; System.out.print(e + \" \"); }); } } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:2","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"LinkedList类 链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的地址。链表可分为单向链表和双向链表。Java LinkedList（链表） 类似于 ArrayList，是一种常用的数据容器。与 ArrayList 相比，LinkedList 的增加和删除的操作效率更高，而查找和修改的操作效率较低。 以下情况使用 ArrayList : 频繁访问列表中的某一个元素。 只需要在列表末尾进行添加和删除元素操作。 以下情况使用 LinkedList : 你需要通过循环迭代来访问列表中的某些元素。 需要频繁的在列表开头、中间、末尾等位置进行添加和删除元素操作。 LinkedList 继承了 AbstractSequentialList 类。 LinkedList 实现了 Queue 接口，可作为队列使用。 LinkedList 实现了 List 接口，可进行列表的相关操作。 LinkedList 实现了 Deque 接口，可作为队列使用。 LinkedList 实现了 Cloneable 接口，可实现克隆。 LinkedList 实现了 java.io.Serializable 接口，即可支持序列化，能通过序列化去传输。 示例： import java.util.LinkedList; public class Test { public static void main(String[] args) { LinkedList\u003cString\u003e sites = new LinkedList\u003cString\u003e(); //创建LinkedList sites.add(\"Google\"); //添加元素 sites.add(\"Runoob\"); sites.add(\"Taobao\"); sites.addFirst(\"Wiki\"); //头部添加元素 sites.addLast(\"Weibo\"); //尾部添加元素 sites.removeFirst(); //移除头部元素 sites.removeLast(); //移除尾部元素 System.out.println(sites.getFirst()); //获取头部元素 System.out.println(sites.getLast()); //获取尾部元素 } } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:3","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Set接口 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:0","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"简介 Set体系集合可以知道某物是否已近存在于集合中,不会存储重复的元素。加入Set的每个元素必须是唯一的，否则，Set是不会把它加进去的。要想加进Set，Object必须定义equals()，这样才能标明对象的唯一性。Set的接口和Collection的一摸一样。Set的接口不保证它会用哪种顺序来存储元素。 |–Set ​ |–HashSet : 为快速查找设计的Set。存入HashSet的对象必须定义hashCode()。 ​ |–TreeSet : 保存次序的Set, 底层为树结构。使用它可以从Set中提取有序的序列。 ​ |–LinkedHashSet : 具有HashSet的查询速度，且内部使用链表维护元素的顺序(插入的次序)。于是在使用迭代器遍历Set时，结果会按元素插入的次序显示。 Set排序 //把HashSet保存在ArrayList里，再用Collections.sort()方法比较 final HashSet\u003cInteger\u003e va = new HashSet\u003cInteger\u003e(); va.add(2007111315); va.add(2007111314); va.add(2007111318); va.add(2007111313); final List\u003cInteger\u003e list = new ArrayList\u003cInteger\u003e(); for(final Integer value : va){ list.add(value); } Collections.sort(list); System.out.println(list); //把这个HashSet做为构造参数放到TreeSet中就可以排序了 final TreeSet ts = new TreeSet(va); ts.comparator(); System.out.println(ts); Set遍历 //Iterator迭代遍历 Set\u003cString\u003e set = new HashSet\u003cString\u003e(); Iterator\u003cString\u003e it = set.iterator(); while (it.hasNext()) { String str = it.next(); System.out.println(str); } //for-each循环遍历 for (String str : set) { System.out.println(str); } Set转List //通过ArrayList进行转换 List\u003cString\u003e list1 = new ArrayList\u003cString\u003e(set); //List实现类进行转换 List\u003cString\u003e list2 = new ArrayList\u003cString\u003e (); list2.addAll(set); ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:1","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"HashSet类 HashSet使用的是相当复杂的方式来存储元素的，使用HashSet能够最快的获取集合中的元素，效率非常高（以空间换时间）。它会根据hashcode和equals来判断是否是同一个对象，如果hashcode一样，并且equals返回true，则是同一个对象，不能重复存放。 |–HashSet 底层是由HashMap实现的，通过对象的hashCode方法与equals方法来保证插入元素的唯一性，无序(存储顺序和取出顺序不一致)，。 ​ |–LinkedHashSet 底层数据结构由哈希表和链表组成。哈希表保证元素的唯一性，链表保证元素有序。(存储和取出是一致) LinkedHashSet类 LinkedHashSet是HashSet的一个子类，具有HashSet的特性，也是根据元素的hashCode值来决定元素的存储位置。但它使用链表维护元素的次序，元素的顺序与添加顺序一致。由于LinkedHashSet需要维护元素的插入顺序，因此性能略低于HashSet，但在迭代访问Set里的全部元素时由很好的性能。 (1)HashSet是Set接口的实现。HashSet按Hash算法来存储集合中的元素，具有很好的存取和查找性能。 (2)HashSet不是同步的，多个线程访问是需要通过代码保证同步 (3)HashSet集合元素值可以使null。 (4)HashSet不能保证元素的排列顺序，顺序可能与添加顺序不同，顺序也有可能发生变化。 (5)当向HashSet集合中存入一个元素时，HashSet会调用该对象的hashCode()方法来得到该对象的hashCode值，然后根据该HashCode值决定该对象在HashSet中的存储位置。如果有两个元素通过equals()方法比较返回true，但它们的hashCode()方法返回值不相等，HashSet将会把它们存储在不同的位置，依然可以添加成功。即，HashSet集合判断两个元素相等的标准是两个对象通过equals()方法比较相等，并且两个对象的hashCode()方法返回值也相等。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:2","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"TreeSet类 TreeSet时SortedSet接口的实现类，TreeSet可以保证元素处于排序状态，它采用红黑树的数据结构来存储集合元素。TreeSet支持两种排序方法：自然排序和定制排序，默认采用自然排序。 自然排序 　TreeSet会调用集合元素的compareTo(Object obj)方法来比较元素的大小关系，然后将元素按照升序排列，这就是自然排序。如果试图将一个对象添加到TreeSet集合中，则该对象必须实现Comparable接口，否则会抛出异常。当一个对象调用方法与另一个对象比较时，例如obj1.compareTo(obj2)，如果该方法返回0，则两个对象相等；如果返回一个正数，则obj1大于obj2；如果返回一个负数，则obj1小于obj2。 　Java常用类中已经实现了Comparable接口的类有以下几个： 　♦ BigDecimal、BigDecimal以及所有数值型对应的包装类：按照它们对应的数值大小进行比较。 　♦ Charchter：按照字符的unicode值进行比较。 　♦ Boolean：true对应的包装类实例大于false对应的包装类实例。 　♦ String：按照字符串中的字符的unicode值进行比较。 　♦ Date、Time：后面的时间、日期比前面的时间、日期大。 　对于TreeSet集合而言，它判断两个对象是否相等的标准是：两个对象通过compareTo(Object obj)方法比较是否返回0，如果返回0则相等。 定制排序 　想要实现定制排序，需要在创建TreeSet集合对象时，提供一个Comparator对象与该TreeSet集合关联，由Comparator对象负责集合元素的排序逻辑。 　综上：自然排序实现的是Comparable接口，定制排序实现的是Comparator接口。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:3","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Map接口 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:0","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"简介 Map 提供了一个更通用的元素存储方法。Map 集合类用于存储元素对（称作“键”和“值”），其中每个键映射到一个值。从概念上而言，您可以将 List 看作是具有数值键的 Map。 |–Map 是映射接口，Map中存储的内容是键值对(key-value)。 ​ |–TreeMap 继承于AbstractMap，且实现了NavigableMap接口；因此，TreeMap中的内容是“有序的键值对” ​ |–HashMap 继承于AbstractMap，但没实现NavigableMap接口；因此，HashMap的内容是“键值对，但不保证次序” ​ |–Hashtable 虽然不是继承于AbstractMap，但它继承于Dictionary(Dictionary也是键值对的接口)，而且也实现Map接口；因此，Hashtable的内容也是“键值对，也不保证次序”。但和HashMap相比，Hashtable是线程安全的，而且它支持通过Enumeration去遍历。 Map通用方法 abstract void clear() abstract boolean containsKey(Object key) abstract boolean containsValue(Object value) abstract Set\u003cEntry\u003cK, V\u003e\u003e entrySet() abstract boolean equals(Object object) abstract V get(Object key) abstract int hashCode() abstract boolean isEmpty() abstract Set\u003cK\u003e keySet() abstract V put(K key, V value) abstract void putAll(Map\u003c? extends K, ? extends V\u003e map) abstract V remove(Object key) abstract int size() abstract Collection\u003cV\u003e values() Map提供接口分别用于返回 键集、值集或键-值映射关系集。entrySet()用于返回键-值集的Set集合;keySet()用于返回键集的Set集合;values()用户返回值集的Collection集合,因为Map中不能包含重复的键；每个键最多只能映射到一个值。所以，键-值集、键集都是Set，值集时Collection。 Map提供了“键-值对”、“根据键获取值”、“删除键”、“获取容量大小”等方法。 Map遍历 //用for循环遍历 for(Map.Entry\u003cString, String\u003e entry:map.entrySet()){ System.out.println(entry.getKey()+\"---\u003e\"+entry.getValue()); } //用Iterator迭代遍历 Set set = map.entrySet(); Iterator i = set.iterator(); while(i.hasNext()){ Map.Entry\u003cString, String\u003e entry1=(Map.Entry\u003cString, String\u003e)i.next(); System.out.println(entry1.getKey()+\"==\"+entry1.getValue()); } //用keySet()迭代遍历 Iterator it=map.keySet().iterator(); while(it.hasNext()){ String key; String value; key=it.next().toString(); value=map.get(key); System.out.println(key+\"--\"+value); } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:1","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"HashMap类 HashMap是我们使用非常多的Collection，它是基于哈希表的 Map 接口的实现，以key-value的形式存在。 HashMap实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了不同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap不是线程安全的，如果想要线程安全的HashMap，可以通过Collections类的静态方法synchronizedMap获得线程安全的HashMap,例如：Map map = Collections.synchronizedMap(new HashMap()); 归纳起来简单地说，HashMap 在底层将 key-value 当成一个整体进行处理，这个整体就是一个 Entry 对象。HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据 Hash 算法来决定其存储位置；当需要取出一个 Entry 时，也会根据 Hash 算法找到其存储位置，直接取出该 Entry。由此可见：HashMap 之所以能快速存、取它所包含的 Entry，完全类似于现实生活中母亲从小教我们的：不同的东西要放在不同的位置，需要时才能快速找到它。 当创建 HashMap 时，有一个默认的负载因子（load factor），其默认值为 0.75，这是时间和空间成本上一种折衷：增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。 LinkedHashMap实现类 LinkedHashMap使用双向链表来维护key-value对的次序（其实只需要考虑key的次序即可），该链表负责维护Map的迭代顺序，与插入顺序一致，因此性能比HashMap低，但在迭代访问Map里的全部元素时有较好的性能。 HashMap按照key进行排序 HashMap本身就是升序排列,如果要获取集合数据，见如下代码： Map\u003cString, Integer\u003e map = new HashMap\u003cString, Integer\u003e(); map.put(\"d\", 3); map.put(\"c\", 1); Set keySet = map.keySet(); Collections.sort(keySet); for(Iterator ite = keySet.iterator(); ite.hasNext();) { String temp = ite.next(); System.out.println(\"key-value: \"+temp+\",\"+map.getValue(temp); } 但是如果想要通过key进行降序排列，则需要重写sort方法，见如下代码： Collections.sort(keySet, new Comparator() { public int compare(Object o1, Object o2) { //如果map里面是其他类型直接更改sort里面的比较方法。 if (Integer.parseInt(o1.toString()) \u003e Integer.parseInt(o2.toString()) return 1; if (Integer.parseInt(o1.toString()) == Integer.parseInt(o2.toString()) return 0; else return - 1; } }); HashMap按照value值排序的方法 HashMap的value值没有排序功能，若要进行较轻松的排序，可改写Comparator接口方法compare进行排序，代码如下： Map\u003cString, Integer\u003e map = new HashMap\u003cString, Integer\u003e(); map.put(\"d\", 2); map.put(\"c\", 1); map.put(\"b\", 1); map.put(\"a\", 3); List\u003cMap.Entry\u003cString, Integer\u003e\u003e infoIds = new ArrayList\u003cMap.Entry\u003cString, Integer\u003e\u003e(map.entrySet()); //排序前 for (int i = 0; i \u003c infoIds.size(); i++) { String id = infoIds.get(i).toString(); System.out.println(id); } //根据value排序 Collections.sort(infoIds, new Comparator\u003cMap.Entry\u003cString, Integer\u003e\u003e() { public int compare(Map.Entry\u003cString, Integer\u003e o1, Map.Entry\u003cString, Integer\u003e o2) { return (o2.getValue() - o1.getValue()); //return (o1.getKey()).toString().compareTo(o2.getKey()); } }); //排序后 for (int i = 0; i \u003c infoIds.size(); i++) { String id = infoIds.get(i).toString(); System.out.println(id); } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:2","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"TreeMap类 TreeMap继承了NavigableMap，而NavigableMap继承自SortedMap，为SortedMap添加了搜索选项，NavigableMap有几种方法，分别是不同的比较要求：floorKey是小于等于，ceilingKey是大于等于，lowerKey是小于，higherKey是大于。TreeMap的本质是R-B Tree(红黑树)，它包含几个重要的成员变量： root, size, comparator。 TreeMap 是一个有序的key-value集合，它是通过红黑树实现的。 TreeMap 继承于AbstractMap，所以它是一个Map，即一个key-value集合。 TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合。 TreeMap 实现了Cloneable接口，意味着它能被克隆。 TreeMap 实现了java.io.Serializable接口，意味着它支持序列化。 TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。 TreeMap的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n) 。 TreeMap是非同步的。 它的iterator 方法返回的迭代器是fail-fastl的。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:3","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"HashTable类 hashTable将key和value结合起来构成键值对通过put(key,value)方法保存起来，然后通过get(key)方法获取相对应的value值。它是线程安全的哈希映射表，内部采用Entry[]数组，每个Entry均可作为链表的头，用来解决冲突（碰撞）。同时Hashtables提供了一个很有用的方法可以使应用程序的性能达到最佳。 线程安全。 Key、Value均不能为null。 包含了一个Entry[]数组，而Entry又是一个链表，用来处理冲突。 每个Key对应了Entry数组中固定的位置（记为index），称为槽位（Slot）。槽位计算公式为： (key.hashCode() \u0026 0x7FFFFFFF) % Entry[].length() 。 当Entry[]的实际元素数量（Count）超过了分配容量（Capacity）的75%时，新建一个Entry[]是原先的2倍，并重新Hash（rehash）。 rehash的核心思路是，将旧Entry[]数组的元素重新计算槽位，散列到新Entry[]中。 HashTable与HashMap的区别 HashTable和HashMap存在很多的相同点，但是他们还是有几个比较重要的不同点。 第一：我们从他们的定义就可以看出他们的不同，HashTable基于Dictionary类，而HashMap是基于AbstractMap。Dictionary是什么？它是任何可将键映射到相应值的类的抽象父类，而AbstractMap是基于Map接口的骨干实现，它以最大限度地减少实现此接口所需的工作。 第二：HashMap可以允许存在一个为null的key和任意个为null的value，但是HashTable中的key和value都不允许为null。当HashMap遇到为null的key时，它会调用putForNullKey方法来进行处理。对于value没有进行任何处理，只要是对象都可以。 而当HashTable遇到null时，他会直接抛出NullPointerException异常信息。 第三：Hashtable的方法是同步的，而HashMap的方法不是。所以有人一般都建议如果是涉及到多线程同步时采用HashTable，没有涉及就采用HashMap，但是在Collections类中存在一个静态方法：synchronizedMap()，该方法创建了一个线程安全的Map对象，并把它作为一个封装的对象来返回，所以通过Collections类的synchronizedMap方法是可以我们你同步访问潜在的HashMap。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:4","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Queue接口 Queue，java中模拟队列的一种数据结构，先进先出（FIFO）,不支持随机访问数据，通过offer（）方法增加数据到队列尾部，poll（）获取队列头部元素，可以将Queue看成一个通道，最先走进的通道的也是最先走出通道的，最后走进去的，在通道里面呆的时间最久。 常用方法： add 增加一个元索 如果队列已满，则抛出一个IIIegaISlabEepeplian异常 remove 移除并返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常 element 返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常 offer 添加一个元素并返回true 如果队列已满，则返回false poll 移除并返问队列头部的元素 如果队列为空，则返回null peek 返回队列头部的元素 如果队列为空，则返回null put 添加一个元素 如果队列满，则阻塞 take 移除并返回队列头部的元素 如果队列为空，则阻塞 drainTo(list) 一次性取出队列所有元素 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:5:0","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"PriorityQueue类 优先队列PriorityQueue是Queue接口的实现，可以对其中元素进行排序，可以放基本数据类型的包装类（如：Integer，Long等）或自定义的类对于基本数据类型的包装器类，优先队列中元素默认排列顺序是升序排列，但对于自己定义的类来说，需要自己定义比较器。 常用方法： peek()//返回队首元素 poll()//返回队首元素，队首元素出队列 add()//添加元素 size()//返回队列元素个数 isEmpty()//判断队列是否为空，为空返回true,不空返回false 示例： public static void main(String[] args) { //不用比较器，默认升序排列 Queue\u003cInteger\u003e q = new PriorityQueue\u003c\u003e(); q.add(3); q.add(2); q.add(4); while(!q.isEmpty()) { System.out.print(q.poll()+\" \"); //2 3 4 } //使用自定义比较器，降序排列 Queue\u003cInteger\u003e qq = new PriorityQueue\u003c\u003e(new Comparator\u003cInteger\u003e() { public int compare(Integer e1, Integer e2) { return e2 - e1; //升序:e1-e2,降序:e2-e1 } }); qq.add(3); qq.add(2); qq.add(4); while(!qq.isEmpty()) { System.out.print(qq.poll()+\" \"); //4 3 2 } } 本文参考至，如需更多详情，请查阅以下网站 菜鸟教程 Java School ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:5:1","tags":["Java"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["实践笔记"],"content":"消息推送是大部分系统都需要做到的功能，在.NET中我分别通过RabbitMQ、MQTT、SignalR实现消息推送功能，本篇文章将通过它们实现简单的推送功能，手把手带大家完成编程。本文环境为.NET Core 3.1下 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:0:0","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"SignalR实现 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:1:0","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"简介 SignalR是一个开源的库，跨平台；让Web应用与其他应用通讯变得很简单，Web服务端可以实时的将内容推送给对应的客户端，客户端发送的信息也可以实时到其他客户端。 SignalR提供了一种远程过程调用(RPC)的方式，使得客户端可以调用服务器的方法，同样在服务器端的方法中也能调用客户端的方法。 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:1:1","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"示例 Nuget包为：\u003cPackageReference Include=\"Microsoft.AspNetCore.SignalR.Core\" Version=\"1.1.0\" /\u003e 首先我们需要创建一个自己的SignalR Hub using Microsoft.AspNetCore.SignalR; using System.Threading.Tasks; namespace KBEAM.Hubs { public class ChatHub : Hub // 继承自SignalR Hub库 { public async Task SendMessage(string user, string message) { await Clients.All.SendAsync(\"ReceiveMessage\", user, message); } public async Task SendMessageToGroup(string group, string message) { await Clients.Group(group).SendAsync(\"ReceiveMessageFromGroup\", group, message); } public async Task AddToGroup(string groupName) { await Groups.AddToGroupAsync(Context.ConnectionId, groupName); await Clients.Group(groupName).SendAsync(\"ReceiveMessage\", $\"{Context.ConnectionId} has joined the group {groupName}.\"); } public async Task RemoveFromGroup(string groupName) { await Groups.RemoveFromGroupAsync(Context.ConnectionId, groupName); //await Clients.Group(groupName).SendAsync(\"ReceiveMessage\", $\"{Context.ConnectionId} has left the group {groupName}.\"); } } } 在Startup.cs文件中注册相关服务及管道 // 1.在ConfigureServices函数中添加以下语句，注册相关服务 services.AddSignalR(); // 2.在Configure函数中添加以下语句，配置管道终结点 app.UseEndpoints(endpoints =\u003e { // ... endpoints.MapHub\u003cChatHub\u003e(\"/chatHub\"); // ... }); 编写服务端业务，推送消息 // 定义一个上下文 private readonly IHubContext\u003cChatHub\u003e hubContext; // 通过构造函数注入依赖 public MonitorService(IHubContext\u003cChatHub\u003e hub) { hubContext = hub; } //在需要的地方调用方法，进行消息推送 await hubContext.Clients.Group(group).SendAsync(\"ReceiveMessageFromGroup\",group, \"需要发送的消息\"); JS客户端程序编写 首先，需要通过npm来安装SignalR封装好的JS文件，npm install @microsoft/signalr // 1.首先进行SignalR客户端连接 const signalR = require(\"@microsoft/signalr\") let conn = new signalR.HubConnectionBuilder() .withUrl(\"http://localhost:8988/chatHub\") .withAutomaticReconnect() .configureLogging(signalR.LogLevel.Error) .build() export default conn import signalR from \"@/utils/signalR\"; // 2.客户端调用服务端方法（RPC） signalR.invoke(\"AddToGroup\", \"groupName\").catch(function (err) { // 加入用户组 return console.error(err.toString()); }); signalR.invoke(\"RemoveFromGroup\", \"大屏\").catch(function (err) { // 移除用户组 return console.error(err.toString()); }); // 3.客户端监听服务器消息 signalR.on(\"ReceiveMessageFromGroup\", function (group, message) { console.log(group + \" \" + message); that.lineChartData = JSON.parse(message); }); ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:1:2","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"RabbitMQ实现 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:2:0","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"简介 RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件），由以高性能、健壮以及可伸缩性出名的 Erlang 写成。 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:2:1","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"示例 首先您需要在电脑上安装好 Erlang及RabbitMQ服务器，这一步大家就自行搜索解决吧，网上应该有很多的解决方法 RabbitMQ准备 首先开启Stomp插件 rabbitmq-plugins enable rabbitmq_management # 开启此插件后有管理界面http://localhost:15672/ rabbitmq-plugins enable rabbitmq_web_stomp rabbitmq-plugins enable rabbitmq_web_stomp_examples 服务端发送消息 所需Nuget包：\u003cPackageReference Include=\"RabbitMQ.Client\" Version=\"6.2.4\" /\u003e // 建立RabbitMQ连接 private static readonly ConnectionFactory rabbitMqFactory = new ConnectionFactory() { HostName = \"localhost\", UserName = \"用户名\", Password = \"密码\", Port = 5672, VirtualHost = \"虚拟主机配置\" }; // 发送消息 using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { channel.ExchangeDeclare(\"monitor\", ExchangeType.Direct, durable: true, autoDelete: false, arguments: null); channel.QueueDeclare(\"message\", durable: true, autoDelete: false, exclusive: false, arguments: null); channel.QueueBind(\"message\", \"monitor\", routingKey: \"message\"); var props = channel.CreateBasicProperties(); props.Persistent = true; channel.BasicPublish(exchange: \"monitor\", routingKey: \"message\", basicProperties: props, body: Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(new { expectedData, actualData }))); } } 具体RabbitMQ使用可以看我的RabbitMQ学习笔记 客户端接受消息 首先需要安装npm库文件，npm install stompjs import Stomp from \"stompjs\"; // 定义一个RabbitMQ客户端 data() { return { client: Stomp.client(\"ws://localhost:15674/ws\"), }; }, // 初始化连接操作 created() { this.client.connect( \"用户名\", \"密码\", this.onConnected, this.onFailed, \"虚拟主机名称\" ); } methods: { onConnected: function () { //订阅频道 // const topic = localStorage.getItem(\"Lesan\"); console.log(\"连接成功\"); this.client.subscribe( \"/exchange/monitor/message\", this.responseCallback, this.onFailed ); }, onFailed: function (frame) { console.log(\"MQ Failed: \" + frame); this.$message.error(\"连接失败\"); }, // 回传消息 responseCallback: function (frame) { console.log(\"MQ msg=\u003e\" + frame.body); this.lineChartData = JSON.parse(frame.body); //接收消息处理 }, // 断开相应的连接 close: function () { this.client.disconnect(function () { console.log(\"已退出账号\"); }); }, }, ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:2:2","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"MQTT实现 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:3:0","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"简介 MQTT是IBM开发的一个即时通讯协议，该协议支持所有的平台，几乎可以把所有联网的物品和外部连接起来。 使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合。这一点很类似于XMPP，但是MQTT的信息冗余远小于XMPP。 使用TCP/IP提供网络连接。主流的MQTT是基于TCP连接进行数据推送的，但是同样有基于UDP的版本，叫做MQTT-SN。这两种版本由于基于不同的连接方式，优缺点自然也就各有不同了。 三种消息传输方式QoS： 0代表“至多一次”，消息发布完全依赖底层 TCP/IP 协议。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送 1代表“至少一次”，确保消息到达，但消息重复可能会发生 2代表“只有一次”，确保消息到达一次。这一级别可用于如下情况，在计费系统中，消息重复或丢失会导致不正确的结果 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:3:1","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"示例 服务端开发 所需Nuget包：\u003cPackageReference Include=\"MQTTnet.AspNetCore\" Version=\"3.1.2\" /\u003e 对Program.cs修改： public static IHostBuilder CreateHostBuilder(string[] args) =\u003e Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =\u003e { webBuilder.UseKestrel(o =\u003e { o.ListenAnyIP(8988); o.ListenAnyIP(1884, t =\u003e t.UseMqtt()); }); webBuilder.UseStartup\u003cStartup\u003e(); //webBuilder.UseUrls(\"http://0.0.0.0:8988\"); }); 对Startup.cs修改： // 在ConfigureServices函数中添加 services.AddHostedMqttServer(mqttServer =\u003e mqttServer.WithoutDefaultEndpoint().WithConnectionValidator(c =\u003e { if (c.Username != \"admin\" || c.Password != \"123456\") { c.ReasonCode = MqttConnectReasonCode.BadUserNameOrPassword; return; } c.ReasonCode = MqttConnectReasonCode.Success; })) .AddMqttConnectionHandler() .AddConnections(); // 在Configure函数中添加 app.UseEndpoints(endpoints =\u003e { endpoints.MapConnectionHandler\u003cMqttConnectionHandler\u003e( \"/mqtt\", httpConnectionDispatcherOptions =\u003e httpConnectionDispatcherOptions.WebSockets.SubProtocolSelector = protocolList =\u003e protocolList.FirstOrDefault() ?? string.Empty); }); app.UseMqttServer(S =\u003e { MqttHelper.Server = S; S.ClientConnectedHandler = new MqttServerClientConnectedHandlerDelegate(OnConnected); S.StartedHandler = new MqttServerStartedHandlerDelegate(OnStarted); }); // 添加事件处理函数 private void OnStarted(EventArgs obj) { RecurringJob.AddOrUpdate\u003cMonitorService\u003e(\"MonitorData\", p =\u003e p.UpdateDataAsync(\"大屏\"), \"0/15 * * * * *\"); } private void OnConnected(MqttServerClientConnectedEventArgs args) { Console.WriteLine(args.ClientId); } // 消息推送方法 MqttHelper.PublishAsync(\"monitor\", JsonConvert.SerializeObject(new { expectedData, actualData })); 添加MqttHelper类： using MQTTnet.Server; using System.Text; namespace Common { public class MqttHelper { public static IMqttServer Server { get; set; } public static void PublishAsync(string topic, byte[] payload) { if (Server != null) { Server.PublishAsync(new MQTTnet.MqttApplicationMessage() { Topic = topic, Payload = payload }, new System.Threading.CancellationToken(false)); } } public static void PublishAsync(string topic, string payload) { if (Server != null) { Server.PublishAsync(new MQTTnet.MqttApplicationMessage() { Topic = topic, Payload = Encoding.UTF8.GetBytes(payload) }, new System.Threading.CancellationToken(false)); ; } } } } 客服端开发 首先需要引入npm包：npm install mqtt import mqtt from \"mqtt\"; // 连接Mqtt服务器，并订阅消息 mounted() { let that = this; let mqttClient = mqtt.connect(\"ws://localhost:8988/mqtt\", { username: \"用户名\", password: \"密码\", clientId: \"客户端ID\", }); mqttClient.on(\"connect\", (e) =\u003e { console.log(\"connected\", e); mqttClient.subscribe(\"monitor\", { qos: 1 }, (err) =\u003e { if (!err) { console.log(\"subscribed\"); } }); }); mqttClient.on(\"message\", (topic, message) =\u003e { console.log(topic, message.toString()); that.lineChartData = JSON.parse(message.toString()); }); }, ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:3:2","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"其他 Vue前端测试客户端全部代码，通过Vue-cli搭建的项目，修改App.vue即可 \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cimg alt=\"Vue logo\" src=\"./assets/logo.png\" /\u003e \u003cHelloWorld msg=\"Welcome to Your Vue.js App\" /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import HelloWorld from \"./components/HelloWorld.vue\"; import mqtt from \"mqtt\"; import Stomp from \"stompjs\"; export default { name: \"App\", components: { HelloWorld, }, data() { return { rabbitClient: Stomp.client(\"ws://172.21.30.233:15674/ws\"), }; }, created() {}, mounted() { // this.useMqtt(); // this.useRabbitMQ(); this.useSignalR(); }, methods: { useSignalR() { const signalR = require(\"@microsoft/signalr\"); const conn = new signalR.HubConnectionBuilder() .withUrl(\"http://172.21.30.233:8988/chatHub\") .withAutomaticReconnect() .configureLogging(signalR.LogLevel.Error) .build(); conn .start() .then(() =\u003e { console.log(\"conneted\"); conn.invoke(\"AddToGroup\", \"大屏\").catch(function (err) { return console.error(err.toString()); }); conn.on(\"ReceiveMessageFromGroup\", function (group, message) { console.log(group + \" \" + message); }); }) .catch((err) =\u003e { return console.error(err.toString()); }); }, useMqtt() { let mqttClient = mqtt.connect(\"ws://172.21.30.233:8988/mqtt\", { username: \"admin\", password: \"123456\", // clientId: \"Lesan\", }); mqttClient.on(\"connect\", (e) =\u003e { console.log(\"connected\", e); mqttClient.subscribe(\"monitor\", { qos: 1 }, (err) =\u003e { if (!err) { console.log(\"subscribed\"); } }); }); mqttClient.on(\"message\", (topic, message) =\u003e { console.log(topic, message.toString()); }); }, useRabbitMQ() { // this.rabbitClient.heartbeat.outgoing = 0; // this.rabbitClient.heartbeat.incoming = 0; this.rabbitClient.connect( \"KB\", \"KB\", this.onConnected, this.onFailed, \"kb_monitor\" ); }, onConnected: function () { //订阅频道 // const topic = localStorage.getItem(\"Lesan\"); console.log(\"连接成功\"); this.rabbitClient.subscribe( \"/exchange/monitor/message\", this.responseCallback, this.onFailed ); }, onFailed: function (frame) { console.log(\"MQ Failed: \" + frame); this.$message.error(\"连接失败\"); }, // 回传消息 responseCallback: function (frame) { console.log(\"MQ msg=\u003e\" + frame.body); //接收消息处理 }, // 断开相应的连接 close: function () { this.rabbitClient.disconnect(function () { console.log(\"已退出账号\"); }); }, }, }; \u003c/script\u003e \u003cstyle\u003e #app { font-family: Avenir, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px; } \u003c/style\u003e ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:4:0","tags":["消息推送"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["学习笔记"],"content":"RabbitMQ简述 MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。RabbitMQ是一个在AMQP基础上完整的，可复用的企业消息系统。他遵循Mozilla Public License开源协议。AMQP(高级消息队列协议) 是一个异步消息传递所使用的应用层协议规范，作为线路层协议，而不是API（例如JMS），AMQP 客户端能够无视消息的来源任意发送和接受信息。AMQP的原始用途只是为金融界提供一个可以彼此协作的消息协议，而现在的目标则是为通用消息队列架构提供通用构建工具。因此，面向消息的中间件 （MOM）系统，例如发布/订阅队列，没有作为基本元素实现。AMQP当中有四个概念非常重要（一个虚拟主机持有一组交换机、队列和绑定）： virtual host，虚拟主机 exchange，交换机 queue，队列 binding，绑定 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:1:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息传递过程 上图为RabbitMQ中一些重要名词的概述，其中包括Connection、Channel、Exchange、Queue、Bind、Routing Key 上图为消息从生产到消费的整个流程，其中Exchange，与Queue都是可以设置相关属性，队列的持久化，交换器类型制定 这个过程走分三个部分，1、客户端（生产消息队列），2、RabbitMQ服务端（负责路由规则的绑定与消息的分发），3、客户端（消费消息队列中的消息） 由图可以看出，一个消息可以走一次网络却被分发到不同的消息队列中，然后被多个的客户端消费，那么这个过程就是RabbitMQ的核心机制，RabbitMQ的路由类型与消费模式 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:2:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"RabbitMQ中Exchange的类型 类型有4种，direct，fanout，topic，headers。其中headers不常用，本篇不做介绍，其他三种类型，会做详细介绍。 那么这些类型是什么意思呢？就是Exchange与队列进行绑定后，消息根据exchang的类型，按照不同的绑定规则分发消息到消息队列中，可以是一个消息被分发给多个消息队列，也可以是一个消息分发到一个消息队列。具体请看下文。 介绍之初还要说下RoutingKey，这是个什么玩意呢？他是exchange与消息队列绑定中的一个标识。有些路由类型会按照标识对应消息队列，有些路由类型忽略routingkey。具体看下文。 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Exchange类型direct 根据交换器名称与routingkey来找队列的 Note:消息从client发出，传送给交换器ChangeA，RoutingKey为routingkey.ZLH,那么不管你发送给Queue1，还是Queue2一个消息都会保存在Queue1，Queue2，Queue3，三个队列中。这就是交换器的direct类型的路由规则。只要找到路由器与routingkey绑定的队列，那么他有多少队列，他就分发给多少队列。 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:1","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Exchange类型fanout 这个类型忽略Routingkey，他为广播模式 Note:消息从客户端发出，只要queue与exchange有绑定，那么他不管你的Routingkey是什么他都会将消息分发给所有与该exchang绑定的队列中。 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:2","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Exchange类型topic 这个类型的路由规则如果你掌握啦，那是相当的好用，与灵活。他是根据RoutingKey的设置，来做匹配的，其中这里还有两个通配符为： *，代表任意的一个词。例如topic.zlh.*，他能够匹配到，topic.zlh.one ,topic.zlh.two ,topic.zlh.abc, …. #，代表任意多个词。例如topic.#，他能够匹配到，topic.zlh.one ,topic.zlh.two ,topic.zlh.abc, …. Note：这个图看上去很乱，但是他是根据匹配符做匹配的，这里我建议你自己做下消息队列的具体操作。ss ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:3","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息队列的消费与消息确认 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:4:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息队列的消费 Note:如果一个消息队列中有大量消息等待操作时，我们可以用多个客户端来处理消息，这里的分发机制是采用负载均衡算法中的轮询。第一个消息给A，下一个消息给B，下下一个消息给A，下下下一个消息给B……以此类推 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:4:1","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息确认 保证消息的安全性，保证此消息被正确处理后才能在服务端的消息队列中删除。那么rabbitmq提供啦ack应答机制，来实现这一功能。 ack应答有两种方式：1、自动应答，2、手动应答 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:4:2","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"使用例子 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:5:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"生产者 using RabbitMQ.Client; using System; using System.Text; namespace RabbitMQProduct { internal class Program { static void Main(string[] args) { Console.WriteLine(\"Welcome to RabbitMQ Product!\"); DirectExchangeSendMsg(); // TopicExchangeSendMsg(); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } /// \u003csummary\u003e /// 连接配置 /// \u003c/summary\u003e private static readonly ConnectionFactory rabbitMqFactory = new ConnectionFactory() { UserName = \"guest\", Password = \"guest\", Port = 5672, //VirtualHost = \"LesanVirtualHost\" }; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string ExchangeName = \"Lesan.exchange\"; //队列名称 const string QueueName = \"Lesan.queue\"; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string TopExchangeName = \"topic.Lesan.exchange\"; //队列名称 const string TopQueueName = \"topic.Lesan.queue\"; /// \u003csummary\u003e /// 单点精确路由模式 /// \u003c/summary\u003e public static void DirectExchangeSendMsg() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //设置交换器的类型 channel.ExchangeDeclare(ExchangeName, ExchangeType.Direct, durable: true, autoDelete: false, arguments: null); //声明一个队列，设置队列是否持久化，排他性，与自动删除 channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); //绑定消息队列，交换器，routingkey channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); var props = channel.CreateBasicProperties(); //队列持久化 props.Persistent = true; string vadata = Console.ReadLine(); while (vadata != \"exit\") { var msgBody = Encoding.UTF8.GetBytes(vadata); //发送信息 channel.BasicPublish(exchange: ExchangeName, routingKey: QueueName, basicProperties: props, body: msgBody); Console.WriteLine(string.Format(\"***发送时间:{0}，发送完成，输入exit退出消息发送\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"))); vadata = Console.ReadLine(); } } } } /// \u003csummary\u003e /// topic 模糊匹配模式，符号“#”匹配一个或多个词，符号“*”匹配不多不少一个词。因此“log.#”能够匹配到“log.info.oa”，但是“log.*” 只会匹配到“log.error” /// \u003c/summary\u003e public static void TopicExchangeSendMsg() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { channel.ExchangeDeclare(TopExchangeName, ExchangeType.Topic, durable: false, autoDelete: false, arguments: null); channel.QueueDeclare(TopQueueName, durable: false, autoDelete: false, exclusive: false, arguments: null); channel.QueueBind(TopQueueName, TopExchangeName, routingKey: TopQueueName); //var props = channel.CreateBasicProperties(); //props.Persistent = true; string vadata = Console.ReadLine(); while (vadata != \"exit\") { var msgBody = Encoding.UTF8.GetBytes(vadata); channel.BasicPublish(exchange: TopExchangeName, routingKey: TopQueueName, basicProperties: null, body: msgBody); Console.WriteLine(string.Format(\"***发送时间:{0}，发送完成，输入exit退出消息发送\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"))); vadata = Console.ReadLine(); } } } } } } ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:5:1","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消费者 using RabbitMQ.Client; using RabbitMQ.Client.Events; using System; using System.Text; namespace RabbitMQConsumer { internal class Program { static void Main(string[] args) { Console.WriteLine(\"Welcome to RabbitMQ Consumer!\"); //DirectAcceptExchange(); //DirectAcceptExchangeEvent(); DirectAcceptExchangeTask(); //TopicAcceptExchange(); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } /// \u003csummary\u003e /// 连接配置 /// \u003c/summary\u003e private static readonly ConnectionFactory rabbitMqFactory = new ConnectionFactory() { UserName = \"guest\", Password = \"guest\", Port = 5672, //VirtualHost = \"LesanVirtualHost\" }; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string ExchangeName = \"Lesan.exchange\"; //队列名称 const string QueueName = \"Lesan.queue\"; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string TopExchangeName = \"topic.Lesan.exchange\"; //队列名称 const string TopQueueName = \"topic.Lesan.queue\"; /// \u003csummary\u003e /// 基于时间轮询的，每隔一段时间获取一次 /// \u003c/summary\u003e public static void DirectAcceptExchange() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //设置交换器的类型 channel.ExchangeDeclare(ExchangeName, ExchangeType.Direct, durable: true, autoDelete: false, arguments: null); //声明一个队列，设置队列是否持久化，排他性，与自动删除 channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); //绑定消息队列，交换器，routingkey channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); while (true) { BasicGetResult msgResponse = channel.BasicGet(QueueName, true); if (msgResponse != null) { var msgBody = Encoding.UTF8.GetString(msgResponse.Body.ToArray()); Console.WriteLine(string.Format(\"***接收时间:{0}，消息内容：{1}\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"), msgBody)); } System.Threading.Thread.Sleep(TimeSpan.FromSeconds(1)); } } } } /// \u003csummary\u003e /// 基于事件的，当消息到达时触发事件，获取数据 /// \u003c/summary\u003e public static void DirectAcceptExchangeEvent() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //channel.ExchangeDeclare(ExchangeName, \"direct\", durable: true, autoDelete: false, arguments: null); channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); //channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u003e { var msgBody = Encoding.UTF8.GetString(ea.Body.ToArray()); Console.WriteLine(string.Format(\"***接收时间:{0}，消息内容：{1}\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"), msgBody)); }; channel.BasicConsume(QueueName, true, consumer: consumer); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } } } /// \u003csummary\u003e /// 基于事件的，当消息到达时触发事件，获取数据 /// \u003c/summary\u003e public static void DirectAcceptExchangeTask() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //channel.ExchangeDeclare(ExchangeName, \"direct\", durable: true, autoDelete: false, arguments: null); channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); channel.BasicQos(prefetchSize: 0, prefetchCount: 1, global: false);//告诉broker同一时间只处理一个消息 //channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); //定义这个队列的消费者 var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u003e { var msgBody = Encoding.UTF8.GetString(ea.Body.ToArray()); Console.WriteLine(string.Format(\"***接收时间:{0}，消息内容：{1}\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"), msgBody)); int dots = msgBody.Split('.').Length - 1; System.Threading.Thread.Sleep(dots * 1000); //处理完成，告诉Broker可以服务端可以删除消息，分配新的消息过来 channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false); }; //noAck设置false,告诉broker，发送消息之后，消息暂时不要删除，等消费者处理完成再说 //false为手动应答，true为自动应答 channel.BasicConsume(QueueName, false, consumer: consumer); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } } } /// \u003csummary\u003e /// topic 模糊匹配模式，符号“#”匹配一个或多个词，符号“*”匹配不多不少一个词。因此“log.#”能够匹配到“log.info.oa”，但是“log.*” 只会匹配到“log.error” /","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:5:2","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"引用 以上笔记摘录自网络 https://www.cnblogs.com/knowledgesea/p/5296008.html https://www.cnblogs.com/personblog/p/10681741.html ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:6:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"本文为个人学习和实践 Nginx 的笔记 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:0:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 常用功能 Nginx 有以下几个常用功能 反向代理 这是它的主要功能之一，客户端向服务器发送请求时，会先通过 Nginx 服务器，由服务器将请求分发到相应的Web服务器。正向代理是代理客户端，而反向代理则是代理服务器，Nginx 在提供反向代理服务方面，通过使用正则表达式进行相关配置，采取不同的转发策略，配置相当灵活，而且在配置后端转发请求时，完全不用关心网络环境如何，可以指定任意的IP地址和端口号，或其他类型的连接、请求等。 负载均衡 这也是 Nginx 最常用的功能之一，负载均衡，一方面是将单一的重负载分担到多个网络节点上做并行处理，每个节点处理结束后将结果汇总返回给用户，这样可以大幅度提高网络系统的处理能力；另一方面将大量的前端并发请求或数据流量分担到多个后端网络节点分别处理，这样可以有效减少前端用户等待相应的时间。而 Nginx 负载均衡都是属于后一方面，主要是对大量前端访问或流量进行分流，已保证前端用户访问效率，并可以减少后端服务器处理压力。 Web缓存 在很多优秀的网站中，Nginx 可以作为前置缓存服务器，它被用于缓存前端请求，从而提高 Web服务器的性能。Nginx 会对用户已经访问过的内容在服务器本地建立副本，这样在一段时间内再次访问该数据，就不需要通过 Nginx 服务器向后端发出请求。减轻网络拥堵，减小数据传输延时，提高用户访问速度。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:1:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 安装 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"下载地址 Nginx 下载地址：http://nginx.org/en/download.html ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Windows 版本安装 解压下载的文件后 下面对上面文件夹进行介绍： conf 目录：存放 Nginx 的主要配置文件，很多功能实现都是通过配置该目录下的 nginx.conf 文件，后面我们会详细介绍。 docs目录：存放 Nginx 服务器的主要文档资料，包括 Nginx 服务器的 LICENSE、OpenSSL 的 LICENSE 、PCRE 的 LICENSE 以及 zlib 的 LICENSE ，还包括本版本的 Nginx服务器升级的版本变更说明，以及 README 文档。 html目录：存放了两个后缀名为 .html 的静态网页文件，这两个文件与 Nginx 服务器的运行相关。 logs目录：存放 Nginx 服务器运行的日志文件。 nginx.exe：启动 Nginx 服务器的exe文件，如果 conf 目录下的 nginx.conf 文件配置正确的话，通过该文件即可启动 Nginx 服务器。 关闭 nginx 的方法： 进入到 nginx 目录并且输入以下命令：nginx.exe -s stop ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Linux 版本安装 首先需要安装 nginx 的依赖环境： yum install gcc-c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 对于 gcc，因为安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境的话，需要安装gcc。 对于 pcre，prce(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。 对于 zlib，zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。 对于 openssl，OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。 编译及安装： 1. 首先将下载的文件放到 Linux 系统中，然后解压： tar -zxvf nginx-1.14.0.tar.gz 2. 接着进入解压之后的目录进行编译安装 ./configure --prefix=/usr/local/nginx make make install 3. 进入到/usr/local/nginx目录，再进入sbin目录，通过以下命令启动nginx: ./nginx 通过 ps -ef | grep nginx 查看nginx的进程 4. 关闭nginx： 快速关闭：cd /usr/local/nginx/sbin ./nginx -s stop 相当于直接kill掉nginx的进程id 平缓关闭：cd /usr/local/nginx/sbin ./nginx -s quit 等nginx服务处理完所有请求后再关闭连接，停止工作 5. 重启nginx 先停止再启动：./nginx -s quit ./nginx 重新加载配置文件：./nginx -s reload 6. 检测配置文件语法是否正确 指定需要检测的配置文件：nginx -t -c /usr/local/nginx/conf/nginx.conf 检测默认nginx.conf配置文件：nginx -t ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:3","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"nginx.conf 配置文件 根据默认配置文件，我们可以将nginx.conf配置文件分为三部分： ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"全局块 从配置文件开始到 events 块之间的内容，主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。 比如：worker_processes 1; 这是Nginx服务器并发处理服务的关键配置，worker_processes 值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"events 块 比如： events { worker_connections 1024; } events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 work process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 word process 可以同时支持的最大连接数等。 上述例子就表示每个 work process 支持的最大连接数为 1024. 这部分的配置对 Nginx 的性能影响较大，在实际中应该灵活配置。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"http 块 http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 这是Nginx服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 http 块也可以包括 http全局块、server 块： http全局块 http全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。 server块 这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。后面会详细介绍虚拟主机的概念。 每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。 而每个 server 块也分为全局 server 块，以及可以同时包含多个 locaton 块。 全局server块：最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或IP配置。 location块：一个 server 块可以配置多个 location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是IP别名）之外的字符串（例如 前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:3","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"反向代理 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"代理定义 Nginx 主要能够代理如下几种协议，其中用到的最多的就是做Http代理服务器。 在Java设计模式中，代理模式是这样定义的：给某个对象提供一个代理对象，并由代理对象控制原对象的引用。 代理简单来说，就是如果我们想做什么，但又不想直接去做，那么这时候就找另外一个人帮我们去做。那么这个例子里面的中介公司就是给我们做代理服务的，我们委托中介公司帮我们找房子。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"正向代理定义 　弄清楚什么是代理了，那么什么又是正向代理呢？ 　这里我再举一个例子：大家都知道，现在国内是访问不了 Google的，那么怎么才能访问 Google呢？我们又想，美国人不是能访问 Google吗（这不废话，Google就是美国的），如果我们电脑的对外公网 IP 地址能变成美国的 IP 地址，那不就可以访问 Google了。你很聪明，VPN 就是这样产生的。我们在访问 Google 时，先连上 VPN 服务器将我们的 IP 地址变成美国的 IP 地址，然后就可以顺利的访问了。 　这里的 VPN 就是做正向代理的。正向代理服务器位于客户端和服务器之间，为了向服务器获取数据，客户端要向代理服务器发送一个请求，并指定目标服务器，代理服务器将目标服务器返回的数据转交给客户端。这里客户端是要进行一些正向代理的设置的。 　PS：这里介绍一下什么是 VPN，VPN 通俗的讲就是一种中转服务，当我们电脑接入 VPN 后，我们对外 IP 地址就会变成 VPN 服务器的 公网 IP，我们请求或接受任何数据都会通过这个VPN 服务器然后传入到我们本机。这样做有什么好处呢？比如 VPN 游戏加速方面的原理，我们要玩网通区的 LOL，但是本机接入的是电信的宽带，玩网通区的会比较卡，这时候就利用 VPN 将电信网络变为网通网络，然后在玩网通区的LOL就不会卡了（注意：VPN 是不能增加带宽的，不要以为不卡了是因为网速提升了）。 　可能听到这里大家还是很抽象，没关系，和下面的反向代理对比理解就简单了。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"反向代理定义 　反向代理和正向代理的区别就是：正向代理代理客户端，反向代理代理服务器。 　反向代理，其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。 　下面我们通过两张图来对比正向代理和方向代理： 理解这两种代理的关键在于代理服务器所代理的对象是什么，正向代理代理的是客户端，我们需要在客户端进行一些代理的设置。而反向代理代理的是服务器，作为客户端的我们是无法感知到服务器的真实存在的。 总结起来还是一句话：正向代理代理客户端，反向代理代理服务器。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:3","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 反向代理 相关指令 listen 该指令用于配置网络监听。主要有如下三种配置语法结构： ① 配置监听的IP地址 listen address[:port] [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [deferred] [accept_filter=filter] [bind] [ssl]; ② 配置监听端口 listen port [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deffered] [bind] [ipv6only=on|off] [ssl]; ③ 配置 UNIX Domain Socket listen unix:path [default_server] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deffered] [bind] [ssl] 上面的配置看似比较复杂，其实使用起来是比较简单的： listen *:80 | *:8080 #监听所有80端口和8080端口 listen IP_address:port #监听指定的地址和端口号 listen IP_address #监听指定ip地址所有端口 listen port #监听该端口的所有IP连接 下面分别解释每个选项的具体含义： 1、address:IP地址，如果是 IPV6地址，需要使用中括号[] 括起来，比如[fe80::1]等。 2、port:端口号，如果只定义了IP地址，没有定义端口号，那么就使用80端口。 3、path:socket文件路径，如 var/run/nginx.sock等。 4、default_server:标识符，将此虚拟主机设置为 address:port 的默认主机。（在 nginx-0.8.21 之前使用的是 default 指令） 5、 setfib=number:Nginx-0.8.44 中使用这个变量监听 socket 关联路由表，目前只对 FreeBSD 起作用，不常用。 6、backlog=number:设置监听函数listen()最多允许多少网络连接同时处于挂起状态，在 FreeBSD 中默认为 -1,其他平台默认为511. 7、rcvbuf=size:设置监听socket接收缓存区大小。 8、sndbuf=size:设置监听socket发送缓存区大小。 9、deferred:标识符，将accept()设置为Deferred模式。 10、accept_filter=filter:设置监听端口对所有请求进行过滤，被过滤的内容不能被接收和处理，本指令只在 FreeBSD 和 NetBSD 5.0+ 平台下有效。filter 可以设置为 dataready 或 httpready 。 11、bind:标识符，使用独立的bind() 处理此address:port，一般情况下，对于端口相同而IP地址不同的多个连接，Nginx 服务器将只使用一个监听指令，并使用 bind() 处理端口相同的所有连接。 12、ssl:标识符，设置会话连接使用 SSL模式进行，此标识符和Nginx服务器提供的 HTTPS 服务有关。 server_name 该指令用于虚拟主机的配置。通常分为以下两种： 1、基于名称的虚拟主机配置 语法格式如下： server_name name ...; 一、对于name 来说，可以只有一个名称，也可以有多个名称，中间用空格隔开。而每个名字由两段或者三段组成，每段之间用“.”隔开。 server_name 123.com www.123.com 二、可以使用通配符“*”，但通配符只能用在由三段字符组成的首段或者尾端，或者由两端字符组成的尾端。 server_name *.123.com www.123.* 三、还可以使用正则表达式，用“~”作为正则表达式字符串的开始标记。 server_name ~^www\\d+\\.123\\.com$; 该表达式“~”表示匹配正则表达式，以www开头（“^”表示开头），紧跟着一个0~9之间的数字，在紧跟“.123.co”，最后跟着“m”($表示结尾) 以上匹配的顺序优先级如下： 1 ①、准确匹配 server_name 2 ②、通配符在开始时匹配 server_name 成功 3 ③、通配符在结尾时匹配 server_name 成功 4 ④、正则表达式匹配 server_name 成功 2、基于 IP 地址的虚拟主机配置 语法结构和基于域名匹配一样，而且不需要考虑通配符和正则表达式的问题。 server_name 192.168.1.1 location 该指令用于匹配 URL。 　语法如下： location [ = | ~ | ~* | ^~] uri { } 　1、= ：用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。 　2、~：用于表示 uri 包含正则表达式，并且区分大小写。 　3、~*：用于表示 uri 包含正则表达式，并且不区分大小写。 　4、^~：用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配。 　注意：如果 uri 包含正则表达式，则必须要有 ~ 或者 ~* 标识。 proxy_pass 　该指令用于设置被代理服务器的地址。可以是主机名称、IP地址加端口号的形式。 　语法结构如下： proxy_pass URL; 　URL 为被代理服务器的地址，可以包含传输协议、主机名称或IP地址加端口号，URI等。 proxy_pass http://www.123.com/uri; index 　该指令用于设置网站的默认首页。 　语法为： index filename ...; 　后面的文件名称可以有多个，中间用空格隔开。 index index.html index.jsp; 　通常该指令有两个作用：第一个是用户在请求访问网站时，请求地址可以不写首页名称；第二个是可以对一个请求，根据请求内容而设置不同的首页。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:4","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"配置案例 server { listen 80; server_name localhost; charset utf-8; location / { root /home/ruoyi/projects/ruoyi-ui; try_files $uri $uri/ /index.html; index index.html index.htm; } location /prod-api/ { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8080/; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:5","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"负载均衡 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:5:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"负载均衡的由来 早期的系统架构，基本上都是如下形式的： 客户端发送多个请求到服务器，服务器处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回给客户端。 这种架构模式对于早期的系统相对单一，并发请求相对较少的情况下是比较适合的，成本也低。但是随着信息数量的不断增长，访问量和数据量的飞速增长，以及系统业务的复杂度增加，这种架构会造成服务器相应客户端的请求日益缓慢，并发量特别大的时候，还容易造成服务器直接崩溃。很明显这是由于服务器性能的瓶颈造成的问题，那么如何解决这种情况呢？ 我们首先想到的可能是升级服务器的配置，比如提高CPU执行频率，加大内存等提高机器的物理性能来解决此问题，但是我们知道摩尔定律的日益失效，硬件的性能提升已经不能满足日益提升的需求了。最明显的一个例子，天猫双十一当天，某个热销商品的瞬时访问量是极其庞大的，那么类似上面的系统架构，将机器都增加到现有的顶级物理配置，都是不能够满足需求的。那么怎么办呢？ 上面的分析我们去掉了增加服务器物理配置来解决问题的办法，也就是说纵向解决问题的办法行不通了，那么横向增加服务器的数量呢？这时候集群的概念产生了，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡。 负载均衡完美的解决了单个服务器硬件性能瓶颈的问题，但是随着而来的如何实现负载均衡呢？客户端怎么知道要将请求发送到那个服务器去处理呢？ ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:5:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 实现负载均衡 Nginx 服务器是介于客户端和服务器之间的中介，通过上一节的反向代理的功能，客户端发送的请求先经过 Nginx ，然后通过 Nginx 将请求根据相应的规则分发到相应的服务器。 主要配置指令为上一讲的 pass_proxy 指令以及 upstream 指令。负载均衡主要通过专门的硬件设备或者软件算法实现。通过硬件设备实现的负载均衡效果好、效率高、性能稳定，但是成本较高。而通过软件实现的负载均衡主要依赖于均衡算法的选择和程序的健壮性。均衡算法又主要分为两大类： 静态负载均衡算法：主要包括轮询算法、基于比率的加权轮询算法或者基于优先级的加权轮询算法。 动态负载均衡算法：主要包括基于任务量的最少连接优化算法、基于性能的最快响应优先算法、预测算法及动态性能分配算法等。 静态负载均衡算法在一般网络环境下也能表现的比较好，动态负载均衡算法更加适用于复杂的网络环境。 例子： 普通轮询算法 upstream OrdinaryPolling { server 127.0.0.1:8080; server 127.0.0.1:8081; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 基于比例加权轮询 upstream OrdinaryPolling { server 127.0.0.1:8080 weight=5; server 127.0.0.1:8081 weight=2; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 基于IP路由负载 　我们知道一个请求在经过一个服务器处理时，服务器会保存相关的会话信息，比如session，但是该请求如果第一个服务器没处理完，通过nginx轮询到第二个服务器上，那么这个服务器是没有会话信息的。 　最典型的一个例子：用户第一次进入一个系统是需要进行登录身份验证的，首先将请求跳转到Tomcat1服务器进行处理，登录信息是保存在Tomcat1 上的，这时候需要进行别的操作，那么可能会将请求轮询到第二个Tomcat2上，那么由于Tomcat2 没有保存会话信息，会以为该用户没有登录，然后继续登录一次，如果有多个服务器，每次第一次访问都要进行登录，这显然是很影响用户体验的。 　这里产生的一个问题也就是集群环境下的 session 共享，如何解决这个问题？ 　通常由两种方法： 　1、第一种方法是选择一个中间件，将登录信息保存在一个中间件上，这个中间件可以为 Redis 这样的数据库。那么第一次登录，我们将session 信息保存在 Redis 中，跳转到第二个服务器时，我们可以先去Redis上查询是否有登录信息，如果有，就能直接进行登录之后的操作了，而不用进行重复登录。 　2、第二种方法是根据客户端的IP地址划分，每次都将同一个 IP 地址发送的请求都分发到同一个 Tomcat 服务器，那么也不会存在 session 共享的问题。 　而 nginx 的基于 IP 路由负载的机制就是上诉第二种形式。大概配置如下： upstream OrdinaryPolling { ip_hash; server 127.0.0.1:8080 weight=5; server 127.0.0.1:8081 weight=2; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 注意：我们在 upstream 指令块中增加了 ip_hash 指令。该指令就是告诉 nginx 服务器，同一个 IP 地址客户端发送的请求都将分发到同一个 Tomcat 服务器进行处理。 基于服务器响应时间负载分配 根据服务器处理请求的时间来进行负载，处理请求越快，也就是响应时间越短的优先分配。 upstream OrdinaryPolling { server 127.0.0.1:8080 weight=5; server 127.0.0.1:8081 weight=2; fair; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 通过增加了 fair 指令。 对不同域名实现负载均衡 通过配合location 指令块我们还可以实现对不同域名实现负载均衡。 upstream wordbackend { server 127.0.0.1:8080; server 127.0.0.1:8081; } upstream pptbackend { server 127.0.0.1:8082; server 127.0.0.1:8083; } server { listen 80; server_name localhost; location /word/ { proxy_pass http://wordbackend; index index.html index.htm index.jsp; } location /ppt/ { proxy_pass http://pptbackend; index index.html index.htm index.jsp; } } ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:5:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"引用 以上学习笔记多处摘录自网络 https://www.cnblogs.com/ysocean/p/9392912.html ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:6:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["算法学习"],"content":"本篇文章是学习leetcode中链表相关算法总结的链表技巧 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:0:0","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"虚拟头节点 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:1:0","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 21 题「合并两个有序链表」 ListNode *mergeTwoLists(ListNode *l1, ListNode *l2) { ListNode *head = new ListNode(-1), *p = head; while (l1 \u0026\u0026 l2) { if (l1-\u003eval \u003c l2-\u003eval) { p-\u003enext = l1; l1 = l1-\u003enext; } else { p-\u003enext = l2; l2 = l2-\u003enext; } p = p-\u003enext; } p-\u003enext = l1 ? l1 : l2; return head-\u003enext; } 这个算法的逻辑类似于「拉拉链」，l1, l2 类似于拉链两侧的锯齿，指针 p 就好像拉链的拉索，将两个有序链表合并 ListNode *head = new ListNode(-1), *p = head;中使用到了虚拟头节点，如果不使用虚拟节点，代码会复杂很多，而有了 head 节点这个占位符，可以避免处理空指针的情况，降低代码的复杂性 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:1:1","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"优先队列 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:2:0","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 23 题「合并K个升序链表」 struct cmp { bool operator()(ListNode *p1, ListNode *p2) { return p1-\u003eval \u003e p2-\u003eval; } }; ListNode *mergeKLists(vector\u003cListNode *\u003e \u0026lists) { if (lists.size() == 0) return nullptr; ListNode *head = new ListNode(-1), *tail = head; priority_queue\u003cListNode *, vector\u003cListNode *\u003e, cmp\u003e pq; for (auto i : lists) { if (i) pq.push(i); } while (!pq.empty()) { ListNode *node = pq.top(); pq.pop(); tail-\u003enext = node; tail = tail-\u003enext; if (node-\u003enext) pq.push(node-\u003enext); } return head-\u003enext; } 这里我们就要用到 优先级队列 这种数据结构，把链表节点放入一个最小堆，就可以每次获得 k 个节点中的最小节点 它的时间复杂度是多少呢？ 优先队列 pq 中的元素个数最多是 k，所以一次 poll 或者 add 方法的时间复杂度是 O(logk)；所有的链表节点都会被加入和弹出 pq，所以算法整体的时间复杂度是 O(Nlogk)，其中 k 是链表的条数，N 是这些链表的节点总数。 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:2:1","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"单链表的倒数第k个节点 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:3:0","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 19 题「删除链表的倒数第 N 个结点」 ListNode *removeNthFromEnd(ListNode *head, int n) { ListNode *dummy = new ListNode(-1); dummy-\u003enext = head; auto temp = FindFromEnd(dummy, n + 1); temp-\u003enext = temp-\u003enext-\u003enext; return dummy-\u003enext; } ListNode *FindFromEnd(ListNode *head, int n) { ListNode *first = head, *second = head; while (n--) { first = first-\u003enext; } while (first) { first = first-\u003enext; second = second-\u003enext; } return second; } 首先，我们先让一个指针 p1 指向链表的头节点 head，然后走 k 步 现在的 p1，只要再走 n - k 步，就能走到链表末尾的空指针了对吧？趁这个时候，再用一个指针 p2 指向链表头节点 head 接下来就很显然了，让 p1 和 p2 同时向前走，p1 走到链表末尾的空指针时走了 n - k 步，p2 也走了 n - k 步，也就是链表的倒数第 k 个节点 这样，只遍历了一次链表，就获得了倒数第 k 个节点 p2 不过注意我们又使用了虚拟头结点的技巧，也是为了防止出现空指针的情况，比如说链表总共有 5 个节点，题目就让你删除倒数第 5 个节点，也就是第一个节点，那按照算法逻辑，应该首先找到倒数第 6 个节点。但第一个节点前面已经没有节点了，这就会出错。 但有了我们虚拟节点 dummy 的存在，就避免了这个问题，能够对这种情况进行正确的删除。 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:3:1","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"双指针 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:0","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 876 题「链表的中间结点」 如果想一次遍历就得到中间节点，也需要耍点小聪明，使用「快慢指针」的技巧： 我们让两个指针 slow 和 fast 分别指向链表头结点 head。 每当慢指针 slow 前进一步，快指针 fast 就前进两步，这样，当 fast 走到链表末尾时，slow 就指向了链表中点。 ListNode *middleNode(ListNode *head) { ListNode *slow = head, *fast = head; while (fast \u0026\u0026 fast-\u003enext) { slow = slow-\u003enext; fast = fast-\u003enext-\u003enext; } return slow; } ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:1","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 141 题「环形链表」 判断链表是否包含环属于经典问题了，解决方案也是用快慢指针： 每当慢指针 slow 前进一步，快指针 fast 就前进两步。 如果 fast 最终遇到空指针，说明链表中没有环；如果 fast 最终和 slow 相遇，那肯定是 fast 超过了 slow 一圈，说明链表中含有环。 bool hasCycle(ListNode *head) { ListNode *slow = head, *fast = head; while (fast \u0026\u0026 fast-\u003enext) { slow = slow-\u003enext; fast = fast-\u003enext-\u003enext; if (slow == fast) return true; } return false; } 当然，这个问题还有进阶版：如果链表中含有环，如何计算这个环的起点？ 这里简单提一下解法： ListNode detectCycle(ListNode head) { ListNode fast, slow; fast = slow = head; while (fast != null \u0026\u0026 fast.next != null) { fast = fast.next.next; slow = slow.next; if (fast == slow) break; } // 上面的代码类似 hasCycle 函数 if (fast == null || fast.next == null) { // fast 遇到空指针说明没有环 return null; } // 重新指向头结点 slow = head; // 快慢指针同步前进，相交点就是环起点 while (slow != fast) { fast = fast.next; slow = slow.next; } return slow; } ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:2","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 160 题「相交链表」 ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) { ListNode *A = headA, *B = headB; while (A != B) { if (A) A = A-\u003enext; else A = headB; if (B) B = B-\u003enext; else B = headA; } return A; } 如果用两个指针 p1 和 p2 分别在两条链表上前进，并不能同时走到公共节点，也就无法得到相交节点 c1。 解决这个问题的关键是，通过某些方式，让 p1 和 p2 能够同时到达相交节点 c1。 所以，我们可以让 p1 遍历完链表 A 之后开始遍历链表 B，让 p2 遍历完链表 B 之后开始遍历链表 A，这样相当于「逻辑上」两条链表接在了一起。 如果这样进行拼接，就可以让 p1 和 p2 同时进入公共部分，也就是同时到达相交节点 c1： 那你可能会问，如果说两个链表没有相交点，是否能够正确的返回 null 呢？ 这个逻辑可以覆盖这种情况的，相当于 c1 节点是 null 空指针嘛，可以正确返回 null。 这样，这道题就解决了，空间复杂度为 O(1)，时间复杂度为 O(N)。 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:3","tags":["链表"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["学习笔记"],"content":"API Collection 接口的接口 对象的集合（单列集合） ​ |–List 接口：元素按进入先后有序保存，可重复 ​ |–LinkedList 接口实现类， 链表， 插入删除， 没有同步， 线程不安全 ​ |–ArrayList 接口实现类， 数组， 随机访问， 没有同步， 线程不安全 ​ |–Vector 接口实现类 数组， 同步， 线程安全 ​ |–Stack 是Vector类的实现类 ​ |–Set 接口： 仅接收一次，不可重复，并做内部排序 ​ |–HashSet 使用hash表（数组）存储元素 ​ |–LinkedHashSet 链表维护元素的插入次序 ​ |–TreeSet 底层实现为二叉树，元素排好序 Map 接口 键值对的集合 （双列集合） ​ |–Hashtable 接口实现类， 同步， 线程安全 ​ |–HashMap 接口实现类 ，没有同步， 线程不安全- ​ |–LinkedHashMap 双向链表和哈希表实现 ​ |–WeakHashMap ​ |–TreeMap 红黑树对所有的key进行排序 ​ |–IdentifyHashMap ","date":"2021-01-13","objectID":"/java%E9%9B%86%E5%90%88hashset%E5%92%8Chashmap/:0:0","tags":["Java"],"title":"Java集合(HashSet和HashMap)","uri":"/java%E9%9B%86%E5%90%88hashset%E5%92%8Chashmap/"},{"categories":["学习笔记"],"content":"HashSet HashSet 基于 HashMap 来实现的，是一个不允许有重复元素的集合。 HashSet 允许有 null 值。 HashSet 是无序的，即不会记录插入的顺序。 HashSet 不是线程安全的， 如果多个线程尝试同时修改 HashSet，则最终结果是不确定的。 您必须在多线程访问时显式同步对 HashSet 的并发访问。 HashSet 实现了 Set 接口。 HashSet 类位于 java.util 包中，使用前需要引入它，语法格式如下： import java.util.HashSet; // 引入 HashSet 类 以下实例我们创建一个 HashSet 对象 sites，用于保存字符串元素： HashSet\u003cString\u003e sites = new HashSet\u003cString\u003e(); 部分方法： HashSet\u003cString\u003e sites = new HashSet\u003cString\u003e(); sites.add(\"Google\"); sites.contains(\"Taobao\"); sites.remove(\"Taobao\"); sites.clear(); for (String i : sites) { System.out.println(i); } ","date":"2021-01-13","objectID":"/java%E9%9B%86%E5%90%88hashset%E5%92%8Chashmap/:0:1","tags":["Java"],"title":"Java集合(HashSet和HashMap)","uri":"/java%E9%9B%86%E5%90%88hashset%E5%92%8Chashmap/"},{"categories":["学习笔记"],"content":"HashMap HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。 HashMap 实现了 Map 接口，根据键的 HashCode 值存储数据，具有很快的访问速度，最多允许一条记录的键为 null，不支持线程同步。 HashMap 是无序的，即不会记录插入的顺序。 HashMap 继承于AbstractMap，实现了 Map、Cloneable、java.io.Serializable 接口。 HashMap 类位于 java.util 包中，使用前需要引入它，语法格式如下： import java.util.HashMap; // 引入 HashMap 类 以下实例我们创建一个 HashMap 对象 Sites， 整型（Integer）的 key 和字符串（String）类型的 value： HashMap\u003cInteger, String\u003e Sites = new HashMap\u003cInteger, String\u003e(); 部分方法： // 创建 HashMap 对象 Sites HashMap\u003cInteger, String\u003e Sites = new HashMap\u003cInteger, String\u003e(); // 添加键值对 Sites.put(1, \"Google\"); Sites.get(3); Sites.remove(4); // 输出 key 和 value for (Integer i : Sites.keySet()) { System.out.println(\"key: \" + i + \" value: \" + Sites.get(i)); } // 返回所有 value 值 for(String value: Sites.values()) { // 输出每一个value System.out.print(value + \", \"); } Java HashMap 常用方法列表如下： 方法 描述 clear() 删除 hashMap 中的所有键/值对 clone() 复制一份 hashMap isEmpty() 判断 hashMap 是否为空 size() 计算 hashMap 中键/值对的数量 put() 将键/值对添加到 hashMap 中 putAll() 将所有键/值对添加到 hashMap 中 putIfAbsent() 如果 hashMap 中不存在指定的键，则将指定的键/值对插入到 hashMap 中。 remove() 删除 hashMap 中指定键 key 的映射关系 containsKey() 检查 hashMap 中是否存在指定的 key 对应的映射关系。 containsValue() 检查 hashMap 中是否存在指定的 value 对应的映射关系。 replace() 替换 hashMap 中是指定的 key 对应的 value。 replaceAll() 将 hashMap 中的所有映射关系替换成给定的函数所执行的结果。 get() 获取指定 key 对应对 value getOrDefault() 获取指定 key 对应对 value，如果找不到 key ，则返回设置的默认值 forEach() 对 hashMap 中的每个映射执行指定的操作。 entrySet() 返回 hashMap 中所有映射项的集合集合视图。 keySet() 返回 hashMap 中所有 key 组成的集合视图。 values() 返回 hashMap 中存在的所有 value 值。 merge() 添加键值对到 hashMap 中 compute() 对 hashMap 中指定 key 的值进行重新计算 computeIfAbsent() 对 hashMap 中指定 key 的值进行重新计算，如果不存在这个 key，则添加到 hasMap 中 computeIfPresent() 对 hashMap 中指定 key 的值进行重新计算，前提是该 key 存在于 hashMap 中。 ","date":"2021-01-13","objectID":"/java%E9%9B%86%E5%90%88hashset%E5%92%8Chashmap/:0:2","tags":["Java"],"title":"Java集合(HashSet和HashMap)","uri":"/java%E9%9B%86%E5%90%88hashset%E5%92%8Chashmap/"},{"categories":["学习笔记"],"content":"API ","date":"2021-01-13","objectID":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:0","tags":["Java"],"title":"Java数据结构","uri":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["学习笔记"],"content":"Vector Vector 类实现了一个动态数组。和 ArrayList 很相似，但是两者是不同的： Vector 是同步访问的。 Vector 包含了许多传统的方法，这些方法不属于集合框架。 Vector 主要用在事先不知道数组的大小，或者只是需要一个可以改变大小的数组的情况。 Vector 类支持 4 种构造方法。 第一种构造方法创建一个默认的向量，默认大小为 10： Vector() 第二种构造方法创建指定大小的向量。 Vector(int size) 第三种构造方法创建指定大小的向量，并且增量用 incr 指定。增量表示向量每次增加的元素数目。 Vector(int size,int incr) 第四种构造方法创建一个包含集合 c 元素的向量： Vector(Collection c) 序号 方法描述 1 void add(int index, Object element) 在此向量的指定位置插入指定的元素。 2 boolean add(Object o) 将指定元素添加到此向量的末尾。 3 void clear() 从此向量中移除所有元素。 4 boolean contains(Object elem) 如果此向量包含指定的元素，则返回 true。 5 Object get(int index) 返回向量中指定位置的元素。 6 int indexOf(Object elem) 返回此向量中第一次出现的指定元素的索引，如果此向量不包含该元素，则返回 -1。 7 boolean isEmpty() 测试此向量是否不包含组件。 8 int size() 返回此向量中的组件数。 ","date":"2021-01-13","objectID":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:1","tags":["Java"],"title":"Java数据结构","uri":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["学习笔记"],"content":"Stack 栈是Vector的一个子类，它实现了一个标准的后进先出的栈。 堆栈只定义了默认构造函数，用来创建一个空栈。 堆栈除了包括由Vector定义的所有方法，也定义了自己的一些方法。 Stack() 除了由Vector定义的所有方法，自己也定义了一些方法： 序号 方法描述 1 boolean empty() 测试堆栈是否为空。 2 Object peek( ) 查看堆栈顶部的对象，但不从堆栈中移除它。 3 Object pop( ) 移除堆栈顶部的对象，并作为此函数的值返回该对象。 4 Object push(Object element) 把项压入堆栈顶部。 5 int search(Object element) 返回对象在堆栈中的位置，以 1 为基数。 ","date":"2021-01-13","objectID":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:2","tags":["Java"],"title":"Java数据结构","uri":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["学习笔记"],"content":"ArrayList ArrayList 类是一个可以动态修改的数组，与普通数组的区别就是它是没有固定大小的限制，我们可以添加或删除元素。 ArrayList 继承了 AbstractList ，并实现了 List 接口。 ArrayList 类位于 java.util 包中，使用前需要引入它，语法格式如下： import java.util.ArrayList; // 引入 ArrayList 类 ArrayList\u003cE\u003e objectName =new ArrayList\u003c\u003e();　// 初始化 E: 泛型数据类型，用于设置 objectName 的数据类型，只能为引用数据类型。 objectName: 对象名。 ArrayList 是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 Java ArrayList 常用方法列表如下： 方法 描述 add() 将元素插入到指定位置的 arraylist 中 addAll() 添加集合中的所有元素到 arraylist 中 clear() 删除 arraylist 中的所有元素 clone() 复制一份 arraylist contains() 判断元素是否在 arraylist get() 通过索引值获取 arraylist 中的元素 indexOf() 返回 arraylist 中元素的索引值 removeAll() 删除存在于指定集合中的 arraylist 里的所有元素 remove() 删除 arraylist 里的单个元素 size() 返回 arraylist 里元素数量 isEmpty() 判断 arraylist 是否为空 subList() 截取部分 arraylist 的元素 set() 替换 arraylist 中指定索引的元素 sort() 对 arraylist 元素进行排序 toArray() 将 arraylist 转换为数组 toString() 将 arraylist 转换为字符串 ensureCapacity() 设置指定容量大小的 arraylist lastIndexOf() 返回指定元素在 arraylist 中最后一次出现的位置 retainAll() 保留 arraylist 中在指定集合中也存在的那些元素 containsAll() 查看 arraylist 是否包含指定集合中的所有元素 trimToSize() 将 arraylist 中的容量调整为数组中的元素个数 removeRange() 删除 arraylist 中指定索引之间存在的元素 replaceAll() 将给定的操作内容替换掉数组中每一个元素 removeIf() 删除所有满足特定条件的 arraylist 元素 forEach() 遍历 arraylist 中每一个元素并执行特定操作 ","date":"2021-01-13","objectID":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:3","tags":["Java"],"title":"Java数据结构","uri":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["学习笔记"],"content":"LinkedList 链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的地址。 链表可分为单向链表和双向链表。 一个单向链表包含两个值: 当前节点的值和一个指向下一个节点的链接。 一个双向链表有三个整数值: 数值、向后的节点链接、向前的节点链接。 Java LinkedList（链表） 类似于 ArrayList，是一种常用的数据容器。 与 ArrayList 相比，LinkedList 的增加和删除对操作效率更高，而查找和修改的操作效率较低。 以下情况使用 ArrayList : 频繁访问列表中的某一个元素。 只需要在列表末尾进行添加和删除元素操作。 以下情况使用 LinkedList : 你需要通过循环迭代来访问列表中的某些元素。 需要频繁的在列表开头、中间、末尾等位置进行添加和删除元素操作。 LinkedList 继承了 AbstractSequentialList 类。 LinkedList 实现了 Queue 接口，可作为队列使用。 LinkedList 实现了 List 接口，可进行列表的相关操作。 LinkedList 实现了 Deque 接口，可作为队列使用。 LinkedList 实现了 Cloneable 接口，可实现克隆。 LinkedList 实现了 java.io.Serializable 接口，即可支持序列化，能通过序列化去传输。 ","date":"2021-01-13","objectID":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:4","tags":["Java"],"title":"Java数据结构","uri":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["学习笔记"],"content":"Queue Queue： 基本上，一个队列就是一个先入先出（FIFO）的数据结构 Queue接口与List、Set同一级别，都是继承了Collection接口。LinkedList实现了Deque接 口。 ​ add 增加一个元索 如果队列已满，则抛出一个IIIegaISlabEepeplian异常 remove 移除并返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常 element 返回队列头部的元素 如果队列为空，则抛出一个NoSuchElementException异常 offer 添加一个元素并返回true 如果队列已满，则返回false poll 移除并返问队列头部的元素 如果队列为空，则返回null peek 返回队列头部的元素 如果队列为空，则返回null put 添加一个元素 如果队列满，则阻塞 take 移除并返回队列头部的元素 如果队列为空，则阻塞 remove、element、offer 、poll、peek 其实是属于Queue接口。 ","date":"2021-01-13","objectID":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:5","tags":["Java"],"title":"Java数据结构","uri":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["学习笔记"],"content":"Comparator自定义排序 Comparator接口可以实现自定义排序，实现Comparator接口时，要重写compare方法： int compare(Object o1, Object o2) 返回一个基本类型的整型 如果要按照升序排序,则o1 小于o2，返回-1（负数），相等返回0，01大于02返回1（正数） 如果要按照降序排序,则o1 小于o2，返回1（正数），相等返回0，01大于02返回-1（负数） list.sort(new Comparator\u003cPerson\u003e() { int flag=0; @Override public int compare(Person o1, Person o2) { int a=o1.getSex().compareTo(o2.getSex()); if(a!=0\u0026\u0026a\u003e0){ return -1; } else if(o1.getSex().equals(o2.getSex())){ if(o1.getAge()\u003co2.getAge()){ return -1; } else if(o1.getAge()==o2.getAge()){ if(o1.getWeigth()\u003co2.getWeigth()){ return -1; } else if(o1.getWeigth()==o2.getWeigth()){ if(o1.getHeight()\u003eo2.getHeight()){ return -1; } else if(o1.getHeight()==o2.getHeight()){ if(o1.getName().length()\u003co2.getName().length()){ return -1; } } } } } return 1; } }); ","date":"2021-01-13","objectID":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:6","tags":["Java"],"title":"Java数据结构","uri":"/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":["个人网站"],"content":"安装Hugo 到 Hugo Releases 下载对应的操作系统版本的Hugo二进制文件（hugo或者hugo.exe） Mac下直接使用 Homebrew 安装： brew install hugo ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:1","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"生成站点 使用Hugo快速生成站点，比如希望生成到 /path/to/site 路径： $ hugo new site /path/to/site 这样就在 /path/to/site 目录里生成了初始站点，进去目录： $ cd /path/to/site 站点目录结构： ▸ archetypes/ ▸ content/ ▸ layouts/ ▸ static/ config.toml ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:2","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"创建文章 创建一个 about 页面： $ hugo new about.md about.md 自动生成到了 content/about.md ，打开 about.md 看下： +++ date = \"2015-10-25T08:36:54-07:00\" draft = true title = \"about\" +++ 正文内容 内容是 Markdown 格式的，+++ 之间的内容是 TOML 格式的，根据你的喜好，你可以换成 YAML 格式（使用 --- 标记）或者 JSON 格式。 创建第一篇文章，放到 post 目录，方便之后生成聚合页面。 $ hugo new post/first.md ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:3","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"安装皮肤 到 皮肤列表 挑选一个心仪的皮肤，比如你觉得 Hyde 皮肤不错，找到相关的 GitHub 地址，创建目录 themes，在 themes 目录里把皮肤 git clone 下来： # 创建 themes 目录 $ cd themes $ git clone https://github.com/spf13/hyde.git ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:4","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"运行Hugo 在你的站点根目录执行 Hugo 命令进行调试： $ hugo server --theme=hyde --buildDrafts 若在config.toml设置了theme和buildDrafts： $ hugo server 浏览器里打开： http://localhost:1313 ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:5","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"部署 假设你需要部署在 GitHub Pages 上，首先在GitHub上创建一个Repository，命名为：coderzh.github.io（coderzh替换为你的github用户名）。 在站点根目录执行 Hugo 命令生成最终页面： $ hugo --theme=hyde --baseUrl=\"http://coderzh.github.io/\" 或者 $ hugo （注意，以上命令并不会生成草稿页面，如果未生成任何文章，请去掉文章头部的 draft=true 再重新生成。） 如果一切顺利，所有静态页面都会生成到 public 目录，将pubilc目录里所有文件 push 到刚创建的Repository的 master 分支。 浏览器里访问：http://coderzh.github.io/ ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:6","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"其他相关 关于文章内容 它使您可以直接包含内容的元数据。Hugo支持几种不同的格式，每种格式都有自己的识别令牌。 支持的格式： TOML，以“+++”标识。 YAML，由“---”标识。 JSON，一个单独的JSON对象，由’{‘和’}‘包围，每行各自。 YAML Example ---title:\"spf13-vim 3.0 release and new website\"description:\"spf13-vim is a cross platform distribution of vim plugins and resources for Vim.\"tags:[\".vimrc\",\"plugins\",\"spf13-vim\",\"vim\"]lastmod:2015-12-23date:\"2012-04-06\"categories:- \"Development\"- \"VIM\"slug:\"spf13-vim-3-0-release-and-new-website\"---Content of the file goes Here Required variables title The title for the content description The description for the content date The date the content will be sorted by taxonomies These will use the field name of the plural form of the index (see tags and categories above) Optional variables aliases An array of one or more aliases (e.g. old published path of a renamed content) that would be created to redirect to this content. See Aliases for details. draft If true, the content will not be rendered unless hugo is called with --buildDrafts publishdate If in the future, content will not be rendered unless hugo is called with --buildFuture type The type of the content (will be derived from the directory automatically if unset) isCJKLanguage If true, explicitly treat the content as CJKLanguage (.Summary and .WordCount can work properly in CJKLanguage) weight Used for sorting markup (Experimental) Specify \"rst\" for reStructuredText (requires rst2html) or \"md\" (default) for Markdown slug The token to appear in the tail of the URL, or url The full path to the content from the web root. If neither slug or url is present, the filename will be used. 关于配置 通常的使用情况下，一个网站并不需要一个配置文件，因为它的目录结构和模板就提供了主要的配置。 Hugo 需要在源目录查找一个 config.toml 的配置文件。如果这个文件不存在，将会查找 config.yaml，然后是 config.json 。 这个配置文件是一个整站的配置。它给 Hugo 提供了如何构建站点的方式，比如全局的参数和菜单。 配置变量 下面是 Hugo 定义好的变量列表，以及他们的默认值，你可以设置他们： --- archetypedir: \"archetype\" # hostname (and path) to the root, e.g. http://spf13.com/ baseURL: \"\" # include content marked as draft buildDrafts: false # include content with publishdate in the future buildFuture: false # enable this to make all relative URLs relative to content root. Note that this does not affect absolute URLs. relativeURLs: false canonifyURLs: false # config file (default is path/config.yaml|json|toml) config: \"config.toml\" contentdir: \"content\" dataDir: \"data\" defaultExtension: \"html\" defaultLayout: \"post\" disableLiveReload: false # Do not build RSS files disableRSS: false # Do not build Sitemap file disableSitemap: false # edit new content with this editor, if provided editor: \"\" footnoteAnchorPrefix: \"\" footnoteReturnLinkContents: \"\" # google analytics tracking id googleAnalytics: \"\" languageCode: \"\" layoutdir: \"layouts\" # Enable Logging log: false # Log File path (if set, logging enabled automatically) logFile: \"\" # \"yaml\", \"toml\", \"json\" metaDataFormat: \"toml\" newContentEditor: \"\" # Don't sync modification time of files noTimes: false paginate: 10 paginatePath: \"page\" permalinks: # Pluralize titles in lists using inflect pluralizeListTitles: true # Preserve special characters in taxonomy names (\"Gérard Depardieu\" vs \"Gerard Depardieu\") preserveTaxonomyNames: false # filesystem path to write files to publishdir: \"public\" # color-codes for highlighting derived from this style pygmentsStyle: \"monokai\" # true: use pygments-css or false: color-codes directly pygmentsUseClasses: false # default sitemap configuration map sitemap: # filesystem path to read files relative from source: \"\" staticdir: \"static\" # display memory and timing of different steps of the program stepAnalysis: false # theme to use (located in /doc/themes/THEMENAME/) theme: \"\" title: \"\" # if true, use /filename.html instead of /filename/ uglyURLs: false # Do not make the url/path to lowercase disablePathToLower: false # if true, auto-detect Chinese/Japanese/Korean Languages in the content. (.Summary and .WordCount can work properly in CJKLanguage) hasCJKLanguage false # verbose output verbose: false # verbose logging verboseLog: false # watch filesystem for","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:7","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"GitHub Pages GitHub Pages是GitHub提供给大家的快速部署静态网页的功能，但是由于国内访问比较慢，这里提供一个相对较快的解决办法，就是用GitHub加Vercel。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:1","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["个人网站"],"content":"第一步：注册登录Vercel 我想大家应该都有GitHub账号吧，这里就不多说了。 点击Vercel官网,并使用GitHub登录。 注意⚠️：GitHub账号不要使用QQ邮箱作为主邮箱。如果已经用QQ邮箱注册了GitHub，可以到Setting -\u003e Emails里修改自己的主邮箱。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:2","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["个人网站"],"content":"第二步：导入仓库 它会让你选择一种登录Vercel的方法，支持使用GitHub，GitLab和Bitbucket登录，这里我们选GitHub，后面就是无脑Next的步骤。 顺利的话稍等片刻就会弹出部署成功的页面，还有浮夸的撒花。 部署完成之后可以点击visit进入网页看看效果。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:3","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["个人网站"],"content":"第三步：配置域名 1.点击view Domains进行绑定自己的域名或者点击Settings👉Domains👉输入自己的域名 2.输入自己的域名，然后点Add，它会弹出来一些需要做的配置，接下来需要去我们的域名提供商那里根据Vercel给出的要求进行配置。需要修改的有：Name Servers以及域名解析 最后等待等这两个改动都生效之后就可以用我们自己的域名访问刚刚建立的网站啦~ 以后想要修改网站的话，只需要将改动push到GitHub上，vercel会自动把改动同步过来，完全不用管，超省心。 在一级域名配置好之后，也可以直接在vercel中使用二级域名，无需进行额外设置。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:4","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["学习笔记"],"content":"一、引入依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.thymeleaf.extras\u003c/groupId\u003e \u003cartifactId\u003ethymeleaf-extras-springsecurity4\u003c/artifactId\u003e \u003cversion\u003e3.0.4.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2020-10-12","objectID":"/%E6%B5%85%E5%AD%A6springsecurity-springmybatis/:0:1","tags":["SpringBoot"],"title":"浅学SpringSecurity+SpringMybatis","uri":"/%E6%B5%85%E5%AD%A6springsecurity-springmybatis/"},{"categories":["学习笔记"],"content":"二、配置WebSecurityConfigurerAdapter 使用内存用户储存且认证 @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true) // 开启方法级安全验证 public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests()//表示下面是认证的配置 .antMatchers(\"/login\").permitAll() .antMatchers(\"/login/form\").permitAll() .antMatchers(\"/css/**\").permitAll() .antMatchers(\"/js/**\").permitAll() .anyRequest()//任何请求 .authenticated();//都需要身份认证 http.formLogin()//表单认证 .loginPage(\"/login\")//使用本人制作的登录界面 .usernameParameter(\"user\")//username更改 .loginProcessingUrl(\"/login/form\")//表单提交的api .defaultSuccessUrl(\"/\")//登录成功跳转页面 .failureUrl(\"/login/error\").permitAll();//登录错误跳转界面 http.logout().logoutSuccessUrl(\"/login\");//登出 http.csrf().disable();//防止跨站攻击 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.inMemoryAuthentication()//使用内存用户储存 //配置了一个user用户和一个admin用户 .withUser(\"user\").password(\"password\").roles(\"USER\").and() .withUser(\"admin\").password(\"password\").roles(\"USER\", \"ADMIN\"); } } ","date":"2020-10-12","objectID":"/%E6%B5%85%E5%AD%A6springsecurity-springmybatis/:0:2","tags":["SpringBoot"],"title":"浅学SpringSecurity+SpringMybatis","uri":"/%E6%B5%85%E5%AD%A6springsecurity-springmybatis/"},{"categories":["学习笔记"],"content":"三、由数据库认证登录 在MySQL中创建用户表 CREATETABLE`admin`(`username`varchar(255)CHARACTERSETutf8COLLATEutf8_general_ciDEFAULTNULL,`password`varchar(255)CHARACTERSETutf8COLLATEutf8_general_ciDEFAULTNULL,`id`int(11)NOTNULLAUTO_INCREMENT,`role`varchar(255)DEFAULTNULL,PRIMARYKEY(`id`))ENGINE=InnoDBAUTO_INCREMENT=2DEFAULTCHARSET=utf8;INSERTINTO`admin`VALUES('admin','123',1,'admin'); entity层创建实体 @Data //使用lombok,简化get,set public class UserInfo { private Integer id; private String username; private String password; private String role; } dao层创建数据存取对象 @Mapper//mapper.xml分离 @Repository public interface UserInfoDao { UserInfo getUserInfoByUsername(String username); } 创建dao对应的mapper.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003cmapper namespace=\"cn.llssit.ls.dao.UserInfoDao\"\u003e \u003cselect id=\"getUserInfoByUsername\" resultType=\"UserInfo\"\u003e select * from admin where username = #{username} \u003c/select\u003e \u003c/mapper\u003e service层 interface public interface UserInfoSevice { UserInfo getUserInfoByUsername(String username); } impl @Service public class UserInfoServiceImpl implements UserInfoSevice { @Autowired private UserInfoDao userInfoDao; @Override public UserInfo getUserInfoByUsername(String username) { return userInfoDao.getUserInfoByUsername(username); } } controller层或者其他运用 springsecurity数据库认证 首先需要重写接口loadUserByUsername @Component public class MyUserDetailService implements UserDetailsService { @Autowired private UserInfoSevice userInfoService; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException { // 通过用户名从数据库获取用户信息 UserInfo userInfo = userInfoService.getUserInfoByUsername(s); if (userInfo == null) { throw new UsernameNotFoundException(\"用户不存在\"); } // 得到用户角色 String role = userInfo.getRole(); // 角色集合 List\u003cGrantedAuthority\u003e authorities = new ArrayList\u003c\u003e(); // 角色必须以`ROLE_`开头，数据库中没有，则在这里加 authorities.add(new SimpleGrantedAuthority(\"ROLE_\" + role)); return new User( userInfo.getUsername(), // 因为数据库是明文，所以这里需加密密码 new BCryptPasswordEncoder().encode(userInfo.getPassword()), authorities ); } } 然后创建Security的配置类WebSecurityConfig继承WebSecurityConfigurerAdapter，并重写configure(auth)方法 @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true) // 开启方法级安全验证 public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private MyUserDetailService userDatailService; @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\"/login\").permitAll() .antMatchers(\"/login/form\").permitAll() .antMatchers(\"/css/**\").permitAll() .antMatchers(\"/js/**\").permitAll() .anyRequest() .authenticated(); http.formLogin() .loginPage(\"/login\") .usernameParameter(\"user\") .loginProcessingUrl(\"/login/form\") .defaultSuccessUrl(\"/\") .failureUrl(\"/login/error\").permitAll(); http.logout().logoutSuccessUrl(\"/login\"); http.csrf().disable(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth // 从数据库读取的用户进行身份认证 .userDetailsService(userDatailService) .passwordEncoder(new BCryptPasswordEncoder()); } } 角色访问 @EnableGlobalMethodSecurity(prePostEnabled = true) // 开启方法级安全验证 修改Controller.java类，增加方法的访问权限@PreAuthorize(\"hasAnyRole('admin')\") ","date":"2020-10-12","objectID":"/%E6%B5%85%E5%AD%A6springsecurity-springmybatis/:0:3","tags":["SpringBoot"],"title":"浅学SpringSecurity+SpringMybatis","uri":"/%E6%B5%85%E5%AD%A6springsecurity-springmybatis/"},{"categories":["学习笔记"],"content":"Java集合框架 导入包 import java.util.*; ArrayList 一、定义一个ArrayList //默认创建一个ArrayList集合 List\u003cString\u003e list = new ArrayList\u003c\u003e(); //创建一个初始化长度为100的ArrayList集合 List\u003cString\u003e initlist = new ArrayList\u003c\u003e(100); //将其他类型的集合转为ArrayList List\u003cString\u003e setList = new ArrayList\u003c\u003e(new HashSet()); 二、ArrayList常用方法 add(E element) set(int index, E element) 因为ArrayList底层是由数组实现的，set实现非常简单，调用 set(4, \"4\") 通过传入的数字下标找到对应的位置，替换其中的元素，前提也需要首先判断传入的数组下标是否越界。 get(int index) remove(int index) remove(Object o) 其他方法 size() : 获取集合长度，通过定义在ArrayList中的私有变量size得到 isEmpty()：是否为空，通过定义在ArrayList中的私有变量size得到 contains(Object o)：是否包含某个元素，通过遍历底层数组elementData，通过equals或==进行判断 clear()：集合清空，通过遍历底层数组elementData，设置为null ArrayList的遍历 List\u003cString\u003e list=new ArrayList\u003cString\u003e(); list.add(\"Hello\"); list.add(\"World\"); list.add(\"HAHAHAHA\"); //第一种遍历方法使用 For-Each 遍历 List for (String str : list) { //也可以改写 for(int i=0;i\u003clist.size();i++) 这种形式 System.out.println(str); } //第二种遍历，把链表变为数组相关的内容进行遍历 String[] strArray=new String[list.size()]; list.toArray(strArray); for(int i=0;i\u003cstrArray.length;i++) //这里也可以改写为 for(String str:strArray) 这种形式 { System.out.println(strArray[i]); } //第三种遍历 使用迭代器进行相关遍历 Iterator\u003cString\u003e ite=list.iterator(); while(ite.hasNext())//判断下一个元素之后有值 { System.out.println(ite.next()); } HashMap 一、定义一个HashMap Map\u003cString, String\u003e map = new HashMap\u003c\u003e(); 二、HashMap常用方法 public V put(K key, V value) :插入键值对数据 public V get(Object key) :根据键值获取键值对值数据 public int size() :获取Map中键值对的个数 public boolean containsKey(Object key) :判断Map集合中是否包含键为key的键值对 boolean containsValue(Object value) :判断Map集合中是否包含值为value的键值对 public boolean isEmpty() :判断Map集合中是否没有任何键值对 public V remove(Object key) :根据键值删除Map中键值对 public void clear() :清空Map集合中所有的键值对 HashMap的遍历 Map\u003cString, String\u003e map = new HashMap\u003cString, String\u003e(); map.put(\"1\", \"value1\"); map.put(\"2\", \"value2\"); map.put(\"3\", \"value3\"); //第一种：普遍使用，二次取值 System.out.println(\"通过Map.keySet遍历key和value：\"); for (String key : map.keySet()) { System.out.println(\"key= \"+ key + \" and value= \" + map.get(key)); } //第二种 System.out.println(\"通过Map.entrySet使用iterator遍历key和value：\"); Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it = map.entrySet().iterator(); while (it.hasNext()) { Map.Entry\u003cString, String\u003e entry = it.next(); System.out.println(\"key= \" + entry.getKey() + \" and value= \" + entry.getValue()); } //第三种：推荐，尤其是容量大时 System.out.println(\"通过Map.entrySet遍历key和value\"); for (Map.Entry\u003cString, String\u003e entry : map.entrySet()) { System.out.println(\"key= \" + entry.getKey() + \" and value= \" + entry.getValue()); } //第四种 System.out.println(\"通过Map.values()遍历所有的value，但不能遍历key\"); for (String v : map.values()) { System.out.println(\"value= \" + v); } ","date":"2020-10-12","objectID":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:1","tags":["Java"],"title":"Java学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Java多线程 Java 给多线程编程提供了内置的支持。 一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 多线程是多任务的一种特别的形式，但多线程使用了更小的资源开销。 这里定义和线程相关的另一个术语 - 进程：一个进程包括由操作系统分配的内存空间，包含一个或多个线程。一个线程不能独立的存在，它必须是进程的一部分。一个进程一直运行，直到所有的非守护线程都结束运行后才能结束。 多线程能满足程序员编写高效率的程序来达到充分利用 CPU 的目的。 一个线程的生命周期 线程是一个动态执行的过程，它也有一个从产生到死亡的过程。 下图显示了一个线程完整的生命周期。 新建状态： 使用 new 关键字和 Thread 类或其子类建立一个线程对象后，该线程对象就处于新建状态。它保持这个状态直到程序 start() 这个线程。 就绪状态： 当线程对象调用了start()方法之后，该线程就进入就绪状态。就绪状态的线程处于就绪队列中，要等待JVM里线程调度器的调度。 运行状态： 如果就绪状态的线程获取 CPU 资源，就可以执行 run()，此时线程便处于运行状态。处于运行状态的线程最为复杂，它可以变为阻塞状态、就绪状态和死亡状态。 阻塞状态： 如果一个线程执行了sleep（睡眠）、suspend（挂起）等方法，失去所占用资源之后，该线程就从运行状态进入阻塞状态。在睡眠时间已到或获得设备资源后可以重新进入就绪状态。可以分为三种： 等待阻塞：运行状态中的线程执行 wait() 方法，使线程进入到等待阻塞状态。 同步阻塞：线程在获取 synchronized 同步锁失败(因为同步锁被其他线程占用)。 其他阻塞：通过调用线程的 sleep() 或 join() 发出了 I/O 请求时，线程就会进入到阻塞状态。当sleep() 状态超时，join() 等待线程终止或超时，或者 I/O 处理完毕，线程重新转入就绪状态。 死亡状态： 一个运行状态的线程完成任务或者其他终止条件发生时，该线程就切换到终止状态。 线程的优先级 每一个 Java 线程都有一个优先级，这样有助于操作系统确定线程的调度顺序。 Java 线程的优先级是一个整数，其取值范围是 1 （Thread.MIN_PRIORITY ） - 10 （Thread.MAX_PRIORITY ）。 默认情况下，每一个线程都会分配一个优先级 NORM_PRIORITY（5）。 具有较高优先级的线程对程序更重要，并且应该在低优先级的线程之前分配处理器资源。但是，线程优先级不能保证线程执行的顺序，而且非常依赖于平台。 Thread 方法 序号 方法描述 1 public void start()使该线程开始执行；==Java== 虚拟机调用该线程的 run 方法。 2 public void run()如果该线程是使用独立的 Runnable 运行对象构造的，则调用该 Runnable 对象的 run 方法；否则，该方法不执行任何操作并返回。 3 public final void setName(String name)改变线程名称，使之与参数 name 相同。 4 public final void setPriority(int priority) 更改线程的优先级。 5 public final void setDaemon(boolean on)将该线程标记为守护线程或用户线程。 6 public final void join(long millisec)等待该线程终止的时间最长为 millis 毫秒。 7 public void interrupt()中断线程。 8 public final boolean isAlive()测试线程是否处于活动状态。 测试线程是否处于活动状态。 上述方法是被Thread对象调用的。下面的方法是Thread类的静态方法。 序号 方法描述 1 public static void yield()暂停当前正在执行的线程对象，并执行其他线程。 2 public static void sleep(long millisec)在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），此操作受到系统计时器和调度程序精度和准确性的影响。 3 public static boolean holdsLock(Object x)当且仅当当前线程在指定的对象上保持监视器锁时，才返回 true。 4 public static Thread currentThread()返回对当前正在执行的线程对象的引用。 5 public static void dumpStack()将当前线程的堆栈跟踪打印至标准错误流。 创建一个线程 Java 提供了三种创建线程的方法： 通过实现 Runnable 接口； 通过继承 Thread 类本身； 通过 Callable 和 Future 创建线程。 通过实现Runnable 接口来创建线程 创建一个线程，最简单的方法是创建一个实现 Runnable 接口的类。 为了实现 Runnable，一个类只需要执行一个方法调用 run()，声明如下： public void run() 你可以重写该方法，重要的是理解的 run() 可以调用其他方法，使用其他类，并声明变量，就像主线程一样。 在创建一个实现 Runnable 接口的类之后，你可以在类中实例化一个线程对象。 Thread 定义了几个构造方法，下面的这个是我们经常使用的： Thread(Runnable threadOb,String threadName); 这里，threadOb 是一个实现 Runnable 接口的类的实例，并且 threadName 指定新线程的名字。 新线程创建之后，你调用它的 start() 方法它才会运行。 void start(); 下面是一个创建线程并开始让它执行的实例： class RunnableDemo implements Runnable { private Thread t; private String threadName; RunnableDemo( String name) { threadName = name; System.out.println(\"Creating \" + threadName ); } public void run() { System.out.println(\"Running \" + threadName ); try { for(int i = 4; i \u003e 0; i--) { System.out.println(\"Thread: \" + threadName + \", \" + i); // 让线程睡眠一会 Thread.sleep(50); } }catch (InterruptedException e) { System.out.println(\"Thread \" + threadName + \" interrupted.\"); } System.out.println(\"Thread \" + threadName + \" exiting.\"); } public void start () { System.out.println(\"Starting \" + threadName ); if (t == null) { t = new Thread (this, threadName); t.start (); } } } public class TestThread { public static void main(String args[]) { RunnableDemo R1 = new RunnableDemo( \"Thread-1\"); R1.start(); RunnableDemo R2 = new RunnableDemo( \"Thread-2\"); R2.start(); } } 通过继承Thread来创建线程 创建一个线程的第二种方法是创建一个新的类，该类继承 Thread 类，然后创建一个该类的实例。 继承类必须重写 run() 方法，该方法是新线程的入口点。它也必须调用 start() 方法才能执行。 该方法尽管被列为一种多线程实现方式，但是本质上也是实现了 Runnable 接口的一个实例。 class ThreadDemo extends Thread { private Thread t; private String threadName; ThreadDemo( String name) { threadName = name; System.out.println(\"Creating \" + threadName ); } public void run() { System.out.println(\"Running \" + threadName ); try { for(int i = 4; i \u003e 0; i--) { System.out.println(\"Thread: \" + threadName + \", \" + i); // 让线程睡眠一会 Thread.sleep(50); } }catch (InterruptedException e) { System.out.println(\"Thread \" + threadName + \" interrupted.\"); } System.out.println(\"Thread \" + t","date":"2020-10-12","objectID":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:2","tags":["Java"],"title":"Java学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"一、写前准备 在atom文本编译器中自带着markdown的编写与浏览功能。 浏览使用快捷键ctl+shift+m就可以打开markdown预览。 简书中在设置-\u003e默认编辑器-\u003emarkdown编译，就可以设置markdown。 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:1:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"二、标题 在想要设置为标题的文字前面加#来表示标题 一个#号是以及标题，两个#是二级标题，最多有六级标题 标准语法需要在#后加空格才能表示 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:2:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"三、字体 加粗 在要加粗的文字左右分别用两个*标注 斜体 在要倾斜的文字左右分别用一个*标注 斜体加粗 在要倾斜和加粗的文字左右分别用三个*标注 删除线 在要加删除线的文字左右分别用两个～标注 例如： **加粗字体** *斜体字体* ***斜体加粗字体*** ~~删除字体~~ 效果： 加粗字体，斜体字体，斜体加粗字体，删除字体 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:3:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"四、引用 在引用文字前加\u003e。引用可以嵌套，如一个\u003e、两个\u003e等等 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:4:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"五、\u0008分割线 三个或三个以上的-或者*\u0008\u0008 例： --- *** \u0008效果: ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:5:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"六、\u0008图片 使用方法： ![图片alt](图片地址 ''图片title'') 图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:6:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"七、超链接 使用方法： [超链接名](超链接地址 \"超链接title\") title可加可不加 注：Markdown本身语法不支持链接在新页面中打开，貌似简书做了处理，是可以的。别的平台可能就不行了，如果想要在新页面中打开的话可以用html语言的a标签代替。 \u003ca href=\"超链接地址\" target=\"_blank\"\u003e超链接名\u003c/a\u003e 示例 \u003ca href=\"https://www.jianshu.com/u/1f5ac0cf6a8b\" target=\"_blank\"\u003e简书\u003c/a\u003e ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:7:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"八、列表 无序列表 使用方法：无序列表用 - + * 任何一种都可以 - 列表内容 + 列表内容 * 列表内容 注意：- + * 跟内容之间都要有一个空格 有序列表 使用方法：数字加点 1.列表内容 2.列表内容 3.列表内容 注意：序号跟内容之间要有空格 列表嵌套 使用方法：上一级和下一级之间敲三个空格 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:8:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"九、表格 使用方法： |表头|表头|表头| |-|:-:|-:| |内容|内容|内容| |内容|内容|内容| 第二行分割表头和内容。 -有一个就行 文字默认居左 -两边加：表示文字居中 -右边加：表示文字居右 注：原生的语法两边都要用 | 包起来。此处省略 效果： 表头 表头 表头 内容 内容 内容 内容 内容 内容 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:9:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十、代码 使用方法： 单行代码：代码之间分别用一个反引号包起来 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行 代码\u0008高亮：在第一行反引号后面输入代码块所使用的语言 代码高亮演示： `c #include \"stdio.h\" int main(){ printf(\"hello world\\n\"); return 0; } ` #include \"stdio.h\" int main(){ printf(\"hello world\\n\"); return 0; } ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:10:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十一、流程图 使用方法： st=\u003estart: 开始 op=\u003eoperation: My Operation cond=\u003econdition: Yes or No? e=\u003eend st-\u003eop-\u003econd cond(yes)-\u003ee cond(no)-\u003eop ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:11:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十二、数学表达式 用反引号将数学表达式封装,并在第三个号后标注math代表数学公式. E = mc^2 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:12:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十三、待办事项 在待办的事项文本或者清单文本前加上- 、- [x]即可 - [ ] 表示未完成，- [x] 表示已完成。 注：键入字符与字符之间都要保留一个字符的空格。 \u0008效果 分析需求 研发 测试 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:13:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"结语 Markdown换行方法： 在本行最后\u0008敲两个空格即可 每行间空一行即可 Mac上反引号方法： 在英文状态下按住option键+数字\u00081左边的键 本文章为个人学习笔记，转载了多人的博客，如有雷同请见谅。 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:14:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"}]