[{"categories":["收藏分享"],"content":"在用threejs渲染3D模型时，往往需要选择一个最适合的模型格式，通常都是使用GLB作为Web渲染模型。然而许多工业的模型往往都是以STEP或者IGES作为导出格式，这种格式对于目前主流的3D渲染库支持并不好，所以需要转换模型格式。本篇文章为个人通过查找总结的转换方法，虽然并不是最优解🙃。 ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:0:0","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"各种3D模型格式 ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:1:0","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"STEP \u0026 IGES 简单来说，这两种格式都是CAD的一种文件标准，在工业上使用比较广泛，STEP比IGES出现得更晚一些，由于IGES格式的最新版本是96年发布的，现在多由更高效的STEP等新格式替代，不支持材质。 IGES 可以安装 iges viewer 免费工具查看。 但是，现行主流的web3d库，比如 three.js、Babylon 均不支持 STEP 和 IGES 模型，需要解决这个问题有两个思路： 深入了解格式含义，编写代码给对应库提交对应的解析方案（想法很好，但是实践不易） 将格式转换为适合web展示的格式，比如称为3d界JPG的 GLTF 格式（本文就是讲这个的） ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:1:1","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"STL STL格式更多出现在3D打印中，只能用来表示封闭的体或者面，且文件内部都用三角形表示，所以转换精度比较粗的话，看起来效果比较诡异，包括 Ascii 编码和二进制两种编码模式，一般采用二进制，因为体积相对较小，并且与STEP和IGES一样不支持材质 比如同一个模型（STEP大小：4.81M），转换精度不同可能就是如下两种效果 粗精度（Ascii编码：3.7M）；细精度（Ascii编码：63.3M，二进制编码：12.1M） ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:1:2","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"GLTF 简单来说，就是最小化的把模型资源整理起来，称为3d模型界的JPG，支持材质贴图等，在各个Web3D库中得到了广泛支持，具体怎么加载这里就不赘述了，网上demo很多 Github上的格式介绍和相关技术汇总: https://github.com/mrdoob/three.js/pull/14308 GLTF的详细介绍中文资料: https://zhuanlan.zhihu.com/p/65265611 ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:1:3","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"格式转换 整体思路如下： 使用 pythonocc 将 STEP/IGES/Ascii的STL文件 统一转换为二进制模式的 STL， 再使用 stl2gltf 将STL转换转换为 gltf 格式， 最后使用 gltf-pipeline 将glb文件压缩输出即可 ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:2:0","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"环境安装 pythonocc环境 Pythonocc是python的CAD，安装和使用都很方便 下载并安装AnaConda：https://www.anaconda.com/distribution/#download-section 创建pythonocc 环境：conda create -n pythonocct -c dlr-sc -c pythonocc pythonocc-core=7.4.0rc1 gltf-pipeline环境 下载并安装nodejs：https://nodejs.org/zh-cn/ 安装gltf-pipeline：npm install -g gltf-pipeline ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:2:1","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"实现转换（方法1） pythonocc读取转换STP/IGS/STL 在 Anaconda Prompt 中执行进入环境命令 activate pythonocct STP转换为 STL 文件（StpConverter.py） import os from OCC.Extend.DataExchange import read_iges_file,read_step_file,write_stl_file input_file = 'temp2.stp' output_file = 'out.stl' if not os.path.exists(input_file): print('Input file need exists') exit() shapes=read_step_file(input_file) write_stl_file(shapes, output_file, 'binary', 0.03, 0.5) IGES转换为 STL 文件（IgsConverter.py） import os from OCC.Extend.DataExchange import read_iges_file,read_step_file,write_stl_file input_file = 'temp2.stp' output_file = 'out.stl' if not os.path.exists(input_file): print('Input file need exists') exit() shapes=read_step_file(input_file) write_stl_file(shapes, output_file, 'binary', 0.03, 0.5) stl2gltf（将STL转换为GLTF） 将二进制模式的 STL 文件转换为 GLTF 文件，支持浏览器本地转换、Python脚本以及C++源码 stl2gltf.py 执行转换命令python stl2gltf.py out.stl out.glb -b ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:2:2","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"实现转换（方法2） 使用在线转换网址得到GLB文件(3D模型在线转换) ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:2:3","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["收藏分享"],"content":"GLB文件压缩 直接转换出来的 glb 文件可能比较大，对于WEB来说还是太大了，需使用 gltf-pipeline 进行文件压缩 执行压缩命令gltf-pipeline -i out.glb -o out.glb -b -d glb/gltf格式模型文件压缩–gltf-pipeline相关参数说明 本文参考自：https://www.codeleading.com/article/26425971329/ ","date":"2022-11-26","objectID":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/:2:4","tags":["3D"],"title":"STEP、IGES、STL等3D模型转换为GLB","uri":"/stepigesstl%E7%AD%893d%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BAglb/"},{"categories":["实践笔记"],"content":"简介 服务端向客户端推送消息，其实除了可以用WebSocket这种耳熟能详的机制外，还有一种服务器发送事件(Server-sent events)，简称SSE。 SSE它是基于HTTP协议的，我们知道一般意义上的HTTP协议是无法做到服务端主动向客户端推送消息的，但SSE是个例外，它变换了一种思路。 SSE在服务器和客户端之间打开一个单向通道，服务端响应的不再是一次性的数据包而是text/event-stream类型的数据流信息，在有数据变更时从服务器流式传输到客户端。 整体的实现思路有点类似于在线视频播放，视频流会连续不断的推送到浏览器，你也可以理解成，客户端在完成一次用时很长（网络不畅）的下载。 SSE与WebSocket作用相似，都可以建立服务端与浏览器之间的通信，实现服务端向客户端推送消息，但还是有些许不同： SSE 是基于HTTP协议的，它们不需要特殊的协议或服务器实现即可工作；WebSocket需单独服务器来处理协议。 SSE 单向通信，只能由服务端向客户端单向通信；webSocket全双工通信，即通信的双方可以同时发送和接受信息。 SSE 实现简单开发成本低，无需引入其他组件；WebSocket传输数据需做二次解析，开发门槛高一些。 SSE 默认支持断线重连；WebSocket则需要自己实现。 SSE 只能传送文本消息，二进制数据需要经过编码后传送；WebSocket默认支持传送二进制数据。 SSE 与 WebSocket 该如何选择？ SSE好像一直不被大家所熟知，一部分原因是出现了WebSocket，这个提供了更丰富的协议来执行双向、全双工通信。对于游戏、即时通信以及需要双向近乎实时更新的场景，拥有双向通道更具吸引力。 但是，在某些情况下，不需要从客户端发送数据。而你只需要一些服务器操作的更新。比如：站内信、未读消息数、状态更新、股票行情、监控数量等场景，SEE不管是从实现的难易和成本上都更加有优势。此外，SSE 具有WebSocket在设计上缺乏的多种功能，例如：自动重新连接、事件ID和发送任意事件的能力。 ","date":"2022-11-26","objectID":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/:1:0","tags":["消息推送","SSE"],"title":"SSE实现服务器推送","uri":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/"},{"categories":["实践笔记"],"content":"实践 ","date":"2022-11-26","objectID":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/:2:0","tags":["消息推送","SSE"],"title":"SSE实现服务器推送","uri":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/"},{"categories":["实践笔记"],"content":"前端 前端只需进行一次HTTP请求，带上唯一ID，打开事件流，监听服务端推送的事件就可以了 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003cscript src=\"http://libs.baidu.com/jquery/2.0.0/jquery.min.js\" type=\"text/javascript\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv\u003e \u003cul\u003e \u003cli class=\"active\"\u003e\u003ci class=\"\"\u003e\u003c/i\u003e 未读消息 \u003cspan id=\"count\" class=\"\"\u003e0\u003c/span\u003e\u003c/li\u003e \u003c/ul\u003e \u003cdiv\u003e \u003cinput style=\"height: 25px; width: 180px;\" maxlength=\"60\" value=\"\" id=\"message\" /\u003e \u003cbutton class=\"button\" id=\"mySendBtn\" onclick=\"sendMessage()\"\u003e 点击发送\u003c/button\u003e \u003chr /\u003e \u003cdiv id=\"arrivedDiv\" style=\"height:200px; width:300px; overflow:scroll; background:#EEEEEE;\"\u003e \u003cbr /\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003cscript\u003e let source = null; let userId = \"111\"; if (window.EventSource) { // 建立连接 source = new EventSource('http://localhost:8080/sse/sub/'+userId); setMessageInnerHTML(\"连接用户=\" + userId); // 连接一旦建立，就会触发open事件，另一种写法：source.onopen = function (event) {} source.addEventListener('open', function (e) { setMessageInnerHTML(\"建立连接。。。\"); }, false); // 客户端收到服务器发来的数据，另一种写法：source.onmessage = function (event) {} source.addEventListener('message', function (e) { setMessageInnerHTML(e.data); }); // 如果发生通信错误（比如连接中断），就会触发error事件，另一种写法：source.onerror = function (event) {} source.addEventListener('error', function (e) { if (e.readyState === EventSource.CLOSED) { setMessageInnerHTML(\"连接关闭\"); } else { console.log(e); } }, false); } else { setMessageInnerHTML(\"你的浏览器不支持SSE\"); } // 监听窗口关闭事件，主动去关闭sse连接，如果服务端设置永不过期，浏览器关闭后手动清理服务端数据 window.onbeforeunload = function () { closeSse(); }; // 关闭Sse连接 function closeSse() { source.close(); const httpRequest = new XMLHttpRequest(); httpRequest.open('GET', 'http://localhost:8080/sse/close/' + userId, true); httpRequest.send(); console.log(\"close\"); } // 将消息显示在网页上 function setMessageInnerHTML(innerHTML) { $(\"#arrivedDiv\").append(\"\u003cbr/\u003e\"+innerHTML); var count = $(\"#count\").text(); count = Number(count) + 1; $(\"#count\").text(count); } // 发送信息 function sendMessage() { var content = $(\"#message\").val(); $.ajax({ url: 'http://localhost:8080/sse/push', type: 'GET', data: { \"id\": userId, \"content\": content }, success: function (data) { console.log(data) }, error: function (err) { }, done: function () { } }) } \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2022-11-26","objectID":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/:2:1","tags":["消息推送","SSE"],"title":"SSE实现服务器推送","uri":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/"},{"categories":["实践笔记"],"content":"后端 基本步骤，创建一个SseEmitter对象放入sseEmitterMap进行管理 下面是SseEmitterUtils类，里面主要是对SseEmitter的基本操作，以及当前所有的连接管理 @Slf4j @Component public class SseEmitterUtils { /** * 当前连接数 */ private static AtomicInteger count = new AtomicInteger(0); /** * 使用map对象，便于根据userId来获取对应的SseEmitter，或者放redis里面 */ private static Map\u003cString, SseEmitter\u003e sseEmitterMap = new ConcurrentHashMap\u003c\u003e(); /** * 创建用户连接并返回 SseEmitter */ public static SseEmitter connect(String userId) { if (sseEmitterMap.containsKey(userId)) { return sseEmitterMap.get(userId); } try { /** * 设置超时时间，0表示不过期。默认30秒 */ SseEmitter sseEmitter = new SseEmitter(0L); /** * 注册回调 */ sseEmitter.onCompletion(completionCallBack(userId)); sseEmitter.onError(errorCallBack(userId)); sseEmitter.onTimeout(timeoutCallBack(userId)); sseEmitterMap.put(userId, sseEmitter); /** * 数量+1 */ count.getAndIncrement(); return sseEmitter; } catch (Exception e) { log.error(\"创建新的sse连接异常，当前用户：{}\", userId); } return null; } /** * 给指定用户发送消息 */ public static void sendMessage(String userId, String message) { if (sseEmitterMap.containsKey(userId)) { try { sseEmitterMap.get(userId).send(message); } catch (IOException e) { log.error(\"用户[{}]推送异常:{}\", userId, e.getMessage()); removeUser(userId); } } } /** * 向同组人发布消息 （要求userId+groupId） */ public static void groupSendMessage(String groupId, String message) { if (MapUtil.isNotEmpty(sseEmitterMap)) { sseEmitterMap.forEach((k, v) -\u003e { try { if (k.startsWith(groupId)) { v.send(message, MediaType.APPLICATION_JSON); } } catch (IOException e) { log.error(\"用户[{}]推送异常:{}\", k, e.getMessage()); removeUser(k); } }); } } public static List\u003cString\u003e getIds() { return new ArrayList\u003c\u003e(sseEmitterMap.keySet()); } public static void removeUser(String userId) { sseEmitterMap.remove(userId); // 数量-1 count.getAndDecrement(); log.info(\"移除用户：{}\", userId); } private static Runnable completionCallBack(String userId) { return () -\u003e { log.info(\"结束连接：{}\", userId); removeUser(userId); }; } private static Runnable timeoutCallBack(String userId) { return () -\u003e { log.info(\"连接超时：{}\", userId); removeUser(userId); }; } private static Consumer\u003cThrowable\u003e errorCallBack(String userId) { return throwable -\u003e { log.info(\"连接异常：{}\", userId); removeUser(userId); }; } } 最后是Controller，主要是创建连接、发送消息、断开连接对外的接口 @RestController @CrossOrigin(\"*\") @RequestMapping(\"/sse\") public class SSEController { /** * 基础接口 */ @GetMapping(\"/index\") public String sse(){ return \"sse\"; } /** * sse 订阅消息 */ @GetMapping(path = \"sub/{id}\", produces = {MediaType.TEXT_EVENT_STREAM_VALUE}) public SseEmitter sub(@PathVariable String id) { return SseEmitterUtils.connect(id); } /** * sse 发布消息 */ @GetMapping(\"push\") public void push(String id, String content) { SseEmitterUtils.sendMessage(id, content); } /** * sse 断开连接 */ @GetMapping(\"breakConnect\") public void breakConnect(String id, HttpServletRequest request, HttpServletResponse response) { request.startAsync(); SseEmitterUtils.removeUser(id); } } ","date":"2022-11-26","objectID":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/:2:2","tags":["消息推送","SSE"],"title":"SSE实现服务器推送","uri":"/sse%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81/"},{"categories":["学习笔记"],"content":"多行转成一列（并用\",“分割） SELECT NAME, STUFF (( SELECT ',' + VALUE FROM A WHERE NAME = Test.NAME FOR XML PATH ( '' ) ),1,1,'') VALUE FROM A AS Test GROUP BY NAME; STUFF语句就是为了去掉第一个【逗号】 STUFF用法：（从原字符的第二个开始共三个字符替换为后面的字符） SELECT STUFF('abcdef', 2, 3, 'ijklmn'); -- 查询结果：aijklmnef 其余行列转换用法请参考文章：https://www.cnblogs.com/no27/p/6398130.html ","date":"2022-11-26","objectID":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/:1:0","tags":["SQL"],"title":"SQLServer一些小技巧分享","uri":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/"},{"categories":["学习笔记"],"content":"根据符号将一列拆分多行 select name, SUBSTRING(a.comp,number,CHARINDEX(',',a.comp+',',number)-number) as company, from data_base a,master..spt_values where and number \u003e=1 and number \u003c len(comp) and type='p' and SUBSTRING(','+comp,number,1)=',' SUBSTRING()从输入字符串中的位置(从1开始计数)开始提取具有指定长度的子字符串 SUBSTRING(input_string, start, length) CHARINDEX()函数从指定位置开始搜索字符串内的子字符串 CHARINDEX(substring, string [, start_location])，其中start_location是搜索开始的位置，可选 master..spt_values这个表主要用来保存一些枚举值 --0~2047 共2048个数字 SELECT number FROM MASTER..spt_values WHERE TYPE = 'p' ","date":"2022-11-26","objectID":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/:2:0","tags":["SQL"],"title":"SQLServer一些小技巧分享","uri":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/"},{"categories":["学习笔记"],"content":"通过PARSENAME拆分字符串 注意：PARSENAME最多只能拆分成4个字段 PARSENAME默认是根据’.‘进行拆分的，所以首先要做的是将字段中的其他分隔符（如‘-’）替换成’.’ DECLARE @ip NVARCHAR(200) = '192;168;1;2'; SELECT PARSENAME(REPLACE(@ip,';','.'), 1) AS col1, -- 2 PARSENAME(REPLACE(@ip,';','.'), 2) AS col2, -- 1 PARSENAME(REPLACE(@ip,';','.'), 3) AS col3, -- 168 PARSENAME(REPLACE(@ip,';','.'), 4) AS col4; -- 192 ","date":"2022-11-26","objectID":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/:3:0","tags":["SQL"],"title":"SQLServer一些小技巧分享","uri":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/"},{"categories":["学习笔记"],"content":"SQL Server 字符串拆分函数Split create function split( @string varchar(255),--待分割字符串 @separator varchar(255)--分割符 )returns @array table(item varchar(255) COLLATE Chinese_PRC_CI_AS) -- COLLATE分配排序规则 as begin declare @begin int,@end int,@item varchar(255) set @begin = 1 set @end=charindex(@separator,@string,@begin) while(@end\u003c\u003e0) begin set @item = substring(@string,@begin,@end-@begin) insert into @array(item) values(@item) set @begin = @end+1 set @end=charindex(@separator,@string,@begin) end set @item = substring(@string,@begin,len(@string)+1-@begin) if (len(@item)\u003e0) insert into @array(item) values(substring(@string,@begin,len(@string)+1-@begin)) return end ","date":"2022-11-26","objectID":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/:4:0","tags":["SQL"],"title":"SQLServer一些小技巧分享","uri":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/"},{"categories":["学习笔记"],"content":"SQL Server CROSS/OUTER APPLY 使用 APPLY 运算符(2005或以上版本)可以为实现查询操作的外部表表达式返回的每个行调用表值函数。表值函数作为右输入，外部表表达式作为左输入。通过对右输入求值来获得左输入每一行的计算结果，生成的行被组合起来作为最终输出。APPLY 运算符生成的列的列表是左输入中的列集，后跟右输入返回的列的列表。 APPLY 有两种形式： CROSS APPLY 和 OUTER APPLY。CROSS APPLY 仅返回外部表中通过表值函数生成结果集的行。OUTER APPLY 既返回生成结果集的行，也返回不生成结果集的行，其中表值函数生成的列中的值为 NULL。 看一下例子： select * from table1 join MyFunction(1) on 1=1 -- MyFunction 的参数是一个常量，可以返回一个表。 -- 但有时候我们希望以 table1 的字段作为参数，传进函数去计算，像： select * from table1 join MyFunction(id) on 1=1 -- 这样是会出错的。这个时候我们就可以用 apply 来实现了。例如： select * from table1 cross apply MyFunction(id) on 1=1 简单的说，apply 允许我们将前面结果集每一行的数据作为参数，传递到后面的表达式，后面的表达式可以是一个表值函数，或者select结果集。 so，当你在需要将某个字段的值作为参数使用时，或者用join实现起来比较复杂时，就可以考虑apply来实现。 简单实例： 获得语文第一名，数学前两名，英语前三名的name，学科，分数，用cross apply实现： SELECT b.* FROM ( select Subject='Chiness',num=1 union all select 'Math',2 union all select 'English',3 )a cross apply (select top(a.num) * from Students where Subject=a.Subject )b ","date":"2022-11-26","objectID":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/:5:0","tags":["SQL"],"title":"SQLServer一些小技巧分享","uri":"/sqlserver%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/"},{"categories":["学习笔记"],"content":"本篇文章主要是一些SQL优化的小技巧，为了提升SQL编写规范及性能 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:0:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"避免使用select * 在实际业务场景中，我们不一定需要查出整张表中的所有数据。如果查出了许多不必要的数据，这样会白白浪费了数据库的资源，如：内存或CPU。此外，多查出来的数据，通过网络IO传输的过程中，也会增加数据传输的时间。 还有一个最重要的问题是：select * 不会走覆盖索引，会出现大量的回表操作，而从导致查询sql的性能很低。 所以以后查表时，只查需要用到的字段！ select name,age from user where id=1; ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:1:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"用union all代替union union : 可以获取排重后的数据 union all : 可以获取所有数据，包含重复的数据 排重的过程需要遍历、排序和比较，它更耗时，更消耗cpu资源。所以如果能用union all的时候，尽量不用union。 (select * from user where id=1) union all (select * from user where id=2); ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:2:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"小表驱动大表 小表驱动大表：也就是说用小表的数据集驱动大表的数据集。 假如有order和user两张表，其中order表有10000条数据，而user表有100条数据。 这时如果想查一下，所有有效的用户下过的订单列表。 可以使用in关键字实现： select * from order where user_id in (select id from user where status=1) 也可以使用exists关键字实现： select * from order where exists (select 1 from user where order.user_id = user.id and status=1) 在in与exists中该如何抉择呢？ 因为如果SQL语句中包含了in关键字，则它会优先执行in里面的子查询语句，然后再执行in外面的语句。如果in里面的数据量很少，作为条件查询速度更快。 而如果sql语句中包含了exists关键字，它优先执行exists左边的语句（即主查询语句）。然后把它作为条件，去跟右边的语句匹配。如果匹配上，则可以查询出数据。如果匹配不上，数据就被过滤掉了。 这个需求中，order表有10000条数据，而user表有100条数据。order表是大表，user表是小表。如果order表在左边，则用in关键字性能更好。 总结一下： in 适用于左边大表，右边小表。 exists 适用于左边小表，右边大表。 不管是用in，还是exists关键字，其核心思想都是用小表驱动大表。 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:3:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"批量操作 在需要批量插入数据时，我们不应该使用for循环进行逐条插入数据，因为该操作需要多次请求数据库，才能完成批量数据插入。 但众所周知，我们在代码中，每次远程请求数据库，是会消耗一定性能的。而如果我们的代码需要请求多次数据库，才能完成本次业务功能，势必会消耗更多的性能。 这时候我们就需要创建一个批量插入数据的方法： -- orderMapper.insertBatch(list): insert into order(id,code,user_id) values(123,'001',100),(124,'002',100),(125,'003',101); 这样只需要远程请求一次数据库，sql性能会得到提升，数据量越多，提升越大。 但需要注意的是，不建议一次批量操作太多的数据，如果数据太多数据库响应也会很慢。批量操作需要把握一个度，建议每批数据尽量控制在500以内。如果数据多于500，则分多批次处理。 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:4:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"多用limit 有时候，我们需要查询某些数据中的第一条，比如：查询某个用户下的第一个订单，想看看他第一次的首单时间。 select id, create_date from order where user_id=123 order by create_date asc limit 1; 使用 limit 1，只返回该用户下单时间最小的那一条数据即可。 此外，在删除或者修改数据时，为了防止误操作，导致删除或修改了不相干的数据，也可以在sql语句最后加上limit update order set status=0,edit_time=now(3) where id\u003e=100 and id\u003c200 limit 100; -- 这样即使误操作，比如把id搞错了，也不会对太多的数据造成影响 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:5:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"增量查询 有时候，我们需要通过远程接口查询数据，然后同步到另外一个数据库。 如果直接获取所有的数据，然后同步过去。这样虽说非常方便，但是带来了一个非常大的问题，就是如果数据很多的话，查询性能会非常差。 select * from user where id\u003e#{lastId} and create_time \u003e= #{lastCreateTime} limit 100; 按id和时间升序，每次只同步一批数据，这一批数据只有100条记录。每次同步完成之后，保存这100条数据中最大的id和时间，给同步下一批数据的时候用。 通过这种增量查询的方式，能够提升单次查询的效率。 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:6:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"高效的分页 有时候，列表页在查询数据时，为了避免一次性返回过多的数据影响接口性能，我们一般会对查询接口做分页处理。 在MySQL中分页一般用limit关键字，如果表中数据量少，用limit关键字做分页，没啥问题。但如果表中数据量很多，用它就会出现性能问题。 例如： select id,name,age from user limit 1000000,20; -- MySQL会查到1000020条数据，然后丢弃前面的1000000条，只查后面的20条数据，这个是非常浪费资源的 这时候，海量数据该如何分页呢？ select id,name,age from user where id \u003e 1000000 limit 20; 先找到上次分页最大的id，然后利用id上的索引查询。不过该方案，要求id是连续的，并且有序的。 还能使用between优化分页： select id,name,age from user where id between 1000000 and 1000020; -- 需要注意的是between要在唯一索引上分页，不然会出现每页大小不一致的问题 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:7:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"用连接查询代替子查询 MySQL中如果需要从两张以上的表中查询出数据的话，一般有两种实现方式：子查询 和 连接查询。 子查询的例子如下： select * from order where user_id in (select id from user where status=1) 子查询语句可以通过in关键字实现，一个查询语句的条件落在另一个select语句的查询结果中。程序先运行在嵌套在最内层的语句，再运行外层的语句。 子查询语句的优点是简单，结构化，如果涉及的表数量不多的话。 但缺点是MySQL执行子查询时，需要创建临时表，查询完毕后，需要再删除这些临时表，有一些额外的性能消耗。 这时可以改成连接查询。具体例子如下： select o.* from order o inner join user u on o.user_id = u.id where u.status=1 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:8:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"join的表不宜过多 根据阿里巴巴开发者手册的规定，join表的数量不应该超过 3 个。 如果join太多，MySQL在选择索引的时候会非常复杂，很容易选错索引。并且如果没有命中中，nested loop join 就是分别从两个表读一行数据进行两两对比，复杂度是 n^2。 如果实现业务场景中需要查询出另外几张表中的数据，可以在a、b、c表中冗余专门的字段，比如：在表a中冗余d_name字段，保存需要查询出的数据。 不过有些ERP系统，并发量不大，但业务比较复杂，需要join十几张表才能查询出数据。 所以join表的数量要根据系统的实际情况决定，不能一概而论，尽量越少越好。 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:9:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"join时要注意 在涉及到多张表联合查询的时候，一般会使用join关键字。 而join使用最多的是left join和inner join。 left join：求两个表的交集外加左表剩下的数据。 inner join：求两个表交集的数据。 使用inner join的示例如下： select o.id,o.code,u.name from order o inner join user u on o.user_id = u.id where u.status=1; -- 如果两张表使用inner join关联，MySQL会自动选择两张表中的小表，去驱动大表，所以性能上不会有太大的问题 使用left join的示例如下： select o.id,o.code,u.name from order o left join user u on o.user_id = u.id where u.status=1; -- 如果两张表使用left join关联，MySQL会默认用left join关键字左边的表，去驱动它右边的表。如果左边的表数据很多时，就会出现性能问题 要特别注意的是在用left join关联查询时，左边要用小表，右边可以用大表。如果能用inner join的地方，尽量少用left join ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:10:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"控制索引的数量 众所周知，索引能够显著的提升查询SQL的性能，但索引数量并非越多越好。 因为表中新增数据时，需要同时为它创建索引，而索引是需要额外的存储空间的，而且还会有一定的性能消耗。 阿里巴巴的开发者手册中规定，单表的索引数量应该尽量控制在 5 个以内，并且单个索引中的字段数不超过 5 个。 MySQL使用的B+树的结构来保存索引的，在insert、update和delete操作时，需要更新B+树索引。如果索引过多，会消耗很多额外的性能。 那么，问题来了，如果表中的索引太多，超过了5个该怎么办？ 这个问题要辩证的看，如果你的系统并发量不高，表中的数据量也不多，其实超过5个也可以，只要不要超过太多就行。 但对于一些高并发的系统，请务必遵守单表索引数量不要超过5的限制。 那么，高并发系统如何优化索引数量？ 能够建联合索引，就别建单个索引，可以删除无用的单个索引。 将部分查询功能迁移到其他类型的数据库中，比如：Elastic Seach、HBase等，在业务表中只需要建几个关键索引即可。 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:11:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"选择合理的字段类型 char ：表示固定字符串类型，该类型的字段存储空间的固定的，会浪费存储空间。 varchar ：表示变长字符串类型，该类型的字段存储空间会根据实际数据的长度调整，不会浪费存储空间。 如果是长度固定的字段，比如用户手机号，一般都是11位的，可以定义成char类型，长度是11字节。 但如果是企业名称字段，假如定义成char类型，就有问题了。 如果长度定义得太长，比如定义成了200字节，而实际企业长度只有50字节，则会浪费150字节的存储空间。 如果长度定义得太短，比如定义成了50字节，但实际企业名称有100字节，就会存储不下，而抛出异常。 所以建议将企业名称改成varchar类型，变长字段存储空间小，可以节省存储空间，而且对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 我们在选择字段类型时，应该遵循这样的原则： 能用数字类型，就不用字符串，因为字符的处理往往比数字要慢。 尽可能使用小的类型，比如：用bit存布尔值，用tinyint存枚举值等。 长度固定的字符串字段，用char类型。 长度可变的字符串字段，用varchar类型。 金额字段用decimal，避免精度丢失问题。 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:12:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"提升group by的效率 我们有很多业务场景需要使用group by关键字，它主要的功能是去重和分组。 通常它会跟having一起配合使用，表示分组后再根据一定的条件过滤数据，使用它就会有一些性能上的隐患。 select user_id,user_name from order group by user_id having user_id \u003c= 200; -- 这种写法性能不好，它先把所有的订单根据用户id分组之后，再去过滤用户id大于等于200的用户 分组是一个相对耗时的操作，为什么我们不先缩小数据的范围之后，再分组呢？ select user_id,user_name from order where user_id \u003c= 200 group by user_id 使用where条件在分组前，就把多余的数据过滤掉了，这样分组时效率就会更高一些。 其实这是一种思路，不仅限于group by的优化。我们的sql语句在做一些耗时的操作之前，应尽可能缩小数据范围，这样能提升sql整体的性能 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:13:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"索引优化 很多时候SQL语句，走了索引，和没有走索引，执行效率差别很大。所以索引优化被作为SQL优化的首选。 索引优化的第一步是：检查sql语句有没有走索引。 可以使用explain命令，查看mysql的执行计划。 例如： explain select * from `order` where code='002'; 结果： 通过这几列可以判断索引使用情况，执行计划包含列的含义如下图所示： 说实话，sql语句没有走索引，排除没有建索引之外，最大的可能性是索引失效了。 下面说说索引失效的常见原因： 如果不是上面的这些原因，则需要再进一步排查一下其他原因。 此外，你有没有遇到过这样一种情况：明明是同一条sql，只有入参不同而已。有的时候走的索引a，有的时候却走的索引b？ 没错，有时候MySQL会选错索引。 必要时可以使用force index来强制查询sql走某个索引。 ","date":"2022-11-26","objectID":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/:14:0","tags":["SQL"],"title":"SQL优化小技巧","uri":"/sql%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"categories":["学习笔记"],"content":"简介 基于 SpringBoot 平台开发的项目数不胜数，与常规的基于Spring开发的项目最大的不同之处，SpringBoot 里面提供了大量的注解用于快速开发，而且非常简单，基本可以做到开箱即用！ ","date":"2022-11-26","objectID":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/:1:0","tags":["SpringBoot"],"title":"SpringBoot常用注解总结","uri":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"注解总结 ","date":"2022-11-26","objectID":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/:2:0","tags":["SpringBoot"],"title":"SpringBoot常用注解总结","uri":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"SpringMVC 相关注解 @Controller 通常用于修饰controller层的组件，由控制器负责将用户发来的URL请求转发到对应的服务接口，通常还需要配合注解@RequestMapping使用。 @RequestMapping 提供路由信息，负责URL到Controller中具体函数的映射，当用于方法上时，可以指定请求协议，比如GET、POST、PUT、DELETE等等。 @RequestBody 表示请求体的Content-Type必须为application/json格式的数据，接收到数据之后会自动将数据绑定到Java对象上去。 @ResponseBody 表示该方法的返回结果直接写入HTTP response body中，返回数据的格式为application/json。 比如，请求参数为json格式，返回参数也为json格式，示例代码如下： @Controller @RequestMapping(\"api\") public class LoginController { /** * 登录请求，post请求协议，请求参数数据格式为json * @param request */ @RequestMapping(value = \"login\", method = RequestMethod.POST) @ResponseBody public ResponseEntity login(@RequestBody UserLoginDTO request){ //...业务处理 return new ResponseEntity(HttpStatus.OK); } } @RestController 和@Controller一样，用于标注控制层组件，不同的地方在于：它是@ResponseBody和@Controller的合集，也就是说，在当@RestController用在类上时，表示当前类里面所有对外暴露的接口方法，返回数据的格式都为application/json。 @RequestParam 用于接收请求参数为表单类型的数据，通常用在方法的参数前面，示范代码如下： @RequestMapping(value = \"login\", method = RequestMethod.POST) @ResponseBody public ResponseEntity login(@RequestParam(value = \"userName\",required = true) String userName, @RequestParam(value = \"userPwd\",required = true) String userPwd){ //...业务处理 return new ResponseEntity(HttpStatus.OK); } @PathVariable 用于获取请求路径中的参数，通常用于restful风格的api上，示范代码如下： @RequestMapping(value = \"queryProduct/{id}\", method = RequestMethod.POST) @ResponseBody public ResponseEntity queryProduct(@PathVariable(\"id\") String id){ //...业务处理 return new ResponseEntity(HttpStatus.OK); } @GetMapping 除了@RequestMapping可以指定请求方式之外，还有一些其他的注解，可以用于标注接口路径请求，比如GetMapping用在方法上时，表示只支持get请求方法，等价于@RequestMapping(value=\"/get\",method=RequestMethod.GET)。 @PostMapping 用在方法上，表示只支持post方式的请求。 @PutMapping 用在方法上，表示只支持put方式的请求，通常表示更新某些资源的意思。 @DeleteMapping 用在方法上，表示只支持delete方式的请求，通常表示删除某些资源的意思。 ","date":"2022-11-26","objectID":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/:2:1","tags":["SpringBoot"],"title":"SpringBoot常用注解总结","uri":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"bean 相关注解 @Service 通常用于修饰service层的组件，声明一个对象，会将类对象实例化并注入到bean容器里面。 @Component 泛指组件，当组件不好归类的时候，可以使用这个注解进行标注，功能类似于于@Service。 @Repository 通常用于修饰dao层的组件，@Repository注解属于Spring里面最先引入的一批注解，它用于将数据访问层 (DAO层) 的类标识为Spring Bean，具体只需将该注解标注在DAO类上即可，示例代码如下： @Repository public interface RoleRepository extends JpaRepository\u003cRole,Long\u003e { //具体的方法 } 为什么现在使用的很少呢？ 主要是因为当我们配置服务启动自动扫描dao层包时，Spring会自动帮我们创建一个实现类，然后注入到bean容器里面。当某些类无法被扫描到时，我们可以显式的在数据持久类上标注@Repository注解，Spring会自动帮我们声明对象。 @Bean 相当于 xml 中配置 Bean，意思是产生一个 bean 对象，并交给spring管理，示例代码如下： @Configuration public class AppConfig { //相当于 xml 中配置 Bean @Bean public Uploader initFileUploader() { return new FileUploader(); } } @Autowired 自动导入依赖的bean对象，默认时按照byType方式导入对象，而且导入的对象必须存在，当需要导入的对象并不存在时，我们可以通过配置required = false来关闭强制验证。 @Resource 也是自动导入依赖的bean对象，由JDK提供，默认是按照byName方式导入依赖的对象；而@Autowired默认时按照byType方式导入对象，当然@Resource还可以配置成通过byType方式导入对象。 /** * 通过名称导入（默认通过名称导入依赖对象） */ @Resource(name = \"deptService\") private DeptService deptService; /** * 通过类型导入 */ @Resource(type = RoleRepository.class) private DeptService deptService; @Qualifier 当有多个同一类型的bean时，使用@Autowired导入会报错，提示当前对象并不是唯一，Spring不知道导入哪个依赖，这个时候，我们可以使用@Qualifier进行更细粒度的控制，选择其中一个候选者，一般于@Autowired搭配使用，示例如下： @Autowired @Qualifier(\"deptService\") private DeptService deptService; @Scope 用于生命一个spring bean的作用域，作用的范围一共有以下几种： singleton：唯一 bean 实例，Spring 中的 bean 默认都是单例的。 prototype：每次请求都会创建一个新的 bean 实例，对象多例。 request：每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。 session：每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。 /** * 单例对象 */ @RestController @Scope(\"singleton\") public class HelloController { } ","date":"2022-11-26","objectID":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/:2:2","tags":["SpringBoot"],"title":"SpringBoot常用注解总结","uri":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"配置相关注解 @Configuration 表示声明一个 Java 形式的配置类，Spring Boot 提倡基于 Java 的配置，相当于你之前在 xml 中配置 bean，比如声明一个配置类AppConfig，然后初始化一个Uploader对象。 @Configuration public class AppConfig { @Bean public Uploader initOSSUploader() { return new OSSUploader(); } } @EnableAutoConfiguration @EnableAutoConfiguration可以帮助Spring Boot应用将所有符合条件的@Configuration配置类，全部都加载到当前Spring Boot里，并创建对应配置类的Bean，并把该Bean实体交给IoC容器进行管理。 某些场景下，如果我们想要避开某些配置类的扫描（包括避开一些第三方jar包下面的配置，可以这样处理。 @Configuration @EnableAutoConfiguration(exclude = { org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration.class}) public class AppConfig { //具有业务方法 } @ComponentScan 标注哪些路径下的类需要被Spring扫描，用于自动发现和装配一些Bean对象，默认配置是扫描当前文件夹下和子目录下的所有类，如果我们想指定扫描某些包路径，可以这样处理。 @ComponentScan(basePackages = {\"com.xxx.a\", \"com.xxx.b\", \"com.xxx.c\"}) @SpringBootApplication 等价于使用@Configuration、@EnableAutoConfiguration、@ComponentScan这三个注解，通常用于全局启动类上，示例如下： @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 把@SpringBootApplication换成@Configuration、@EnableAutoConfiguration、@ComponentScan这三个注解，一样可以启动成功，@SpringBootApplication只是将这三个注解进行了简化！ @EnableTransactionManagement 表示开启事务支持，等同于 xml 配置方式的\u003ctx:annotation-driven /\u003e @Conditional 从 Spring4 开始，可以通过@Conditional注解实现按条件装载bean对象，目前 Spring Boot 源码中大量扩展了@Condition注解，用于实现智能的自动化配置，满足各种使用场景。下面我给大家列举几个常用的注解： @ConditionalOnBean：当某个特定的Bean存在时，配置生效 @ConditionalOnMissingBean：当某个特定的Bean不存在时，配置生效 @ConditionalOnClass：当Classpath里存在指定的类，配置生效 @ConditionalOnMissingClass：当Classpath里不存在指定的类，配置生效 @ConditionalOnExpression：当给定的SpEL表达式计算结果为true，配置生效 @ConditionalOnProperty：当指定的配置属性有一个明确的值并匹配，配置生效 具体的应用案例如下： @Configuration public class ConditionalConfig { /** * 当AppConfig对象存在时，创建一个A对象 */ @ConditionalOnBean(AppConfig.class) @Bean public A createA(){ return new A(); } /** * 当AppConfig对象不存在时，创建一个B对象 */ @ConditionalOnMissingBean(AppConfig.class) @Bean public B createB(){ return new B(); } /** * 当KafkaTemplate类存在时，创建一个C对象 */ @ConditionalOnClass(KafkaTemplate.class) @Bean public C createC(){ return new C(); } /** * 当KafkaTemplate类不存在时，创建一个D对象 */ @ConditionalOnMissingClass(KafkaTemplate.class) @Bean public D createD(){ return new D(); } /** * 当enableConfig的配置为true，创建一个E对象 */ @ConditionalOnExpression(\"${enableConfig:false}\") @Bean public E createE(){ return new E(); } /** * 当filter.loginFilter的配置为true，创建一个F对象 */ @ConditionalOnProperty(prefix = \"filter\",name = \"loginFilter\",havingValue = \"true\") @Bean public F createF(){ return new F(); } } @value 可以在任意 Spring 管理的 Bean 中通过这个注解获取任何来源配置的属性值，比如你在application.properties文件里，定义了一个参数变量！ config.name=zhangsan 在任意的bean容器里面，可以通过@Value注解注入参数，获取参数变量值。 @RestController public class HelloController { @Value(\"${config.name}\") private String config; @GetMapping(\"config\") public String config(){ return JSON.toJSONString(config); } } @ConfigurationProperties 上面@Value在每个类中获取属性配置值的做法，其实是不推荐的。 一般在企业项目开发中，不会使用那么杂乱无章的写法而且维护也麻烦，通常会一次性读取一个 Java 配置类，然后在需要使用的地方直接引用这个类就可以多次访问了，方便维护，示例如下： 首先，在application.properties文件里定义好参数变量。 config.name=demo_1 config.value=demo_value_1 然后，创建一个 Java 配置类，将参数变量注入即可！ @Component @ConfigurationProperties(prefix = \"config\") public class Config { public String name; public String value; //...get、set } 最后，在需要使用的地方，通过IOC注入Config对象即可！ @PropertySource 这个注解是用来读取我们自定义的配置文件的，比如导入test.properties和bussiness.properties两个配置文件，用法如下： @SpringBootApplication @PropertySource(value = {\"test.properties\",\"bussiness.properties\"}) public class PropertyApplication { public static void main(String[] args) { SpringApplication.run(PropertyApplication.class, args); } } @ImportResource 用来加载 xml 配置文件，比如导入自定义的aaa.xml文件，用法如下： @ImportResource(locations = \"classpath:aaa.xml\") @SpringBootApplication public class PropertyApplication { public static void main(String[] args) { SpringApplication.run(PropertyApplication.class, args); } } ","date":"2022-11-26","objectID":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/:2:3","tags":["SpringBoot"],"title":"SpringBoot常用注解总结","uri":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"异常处理相关注解 @ControllerAdvice 和 @ExceptionHandler 通常组合使用，用于处理全局异常，示例代码如下： @ControllerAdvice @Configuration @Slf4j public class GlobalExceptionConfig { private static final Integer GLOBAL_ERROR_CODE = 500; @ExceptionHandler(value = Exception.class) @ResponseBody public void exceptionHandler(HttpServletRequest request, HttpServletResponse response, Exception e) throws Exception { log.error(\"【统一异常处理器】\", e); ResultMsg\u003cObject\u003e resultMsg = new ResultMsg\u003c\u003e(); resultMsg.setCode(GLOBAL_ERROR_CODE); if (e instanceof CommonException) { CommonException ex = (CommonException) e; if(ex.getErrCode() != 0) { resultMsg.setCode(ex.getErrCode()); } resultMsg.setMsg(ex.getErrMsg()); }else { resultMsg.setMsg(CommonErrorMsg.SYSTEM_ERROR.getMessage()); } WebUtil.buildPrintWriter(response, resultMsg); } } ","date":"2022-11-26","objectID":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/:2:4","tags":["SpringBoot"],"title":"SpringBoot常用注解总结","uri":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"测试相关注解 @ActiveProfiles 一般作用于测试类上， 用于声明生效的 Spring 配置文件，比如指定application-dev.properties配置文件。 @RunWith 和 @SpringBootTest 一般作用于测试类上， 用于单元测试用，示例如下： @ActiveProfiles(\"dev\") @RunWith(SpringRunner.class) @SpringBootTest public class TestJunit { @Test public void executeTask() { //测试... } } ","date":"2022-11-26","objectID":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/:2:5","tags":["SpringBoot"],"title":"SpringBoot常用注解总结","uri":"/springboot%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%80%BB%E7%BB%93/"},{"categories":["实践笔记"],"content":"Redis 作为21世纪最流行的缓存中间件，它也能够实现接口限流的作用，本片文章主要记录个人实现过程。 在分布式高并发系统中，常常需要用到 缓存 、降级 、 限流。 缓存：缓存的目的是提升系统访问速度和增大系统处理容量 降级：降级是当服务出现问题或者影响到核心流程时，需要暂时屏蔽掉，待高峰或者问题解决后再打开 限流：限流的目的是通过对并发访问/请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理 ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:0:0","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"准备工作 ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:1:0","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"Maven 添加依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 方式2需要用到 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-aop\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:1:1","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"安装 Redis 本文就不多赘述这一部分了 QAQ ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:1:2","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"Spring Boot 中集成 Redis ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:2:0","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"1. 在application配置文件中配置Redis # Redis数据库索引（默认为0） spring.redis.database=0 # Redis服务器地址 spring.redis.host=127.0.0.1 # Redis服务器连接端口 spring.redis.port=6379 # Redis服务器连接密码（默认为空） spring.redis.password= # 连接超时时间（毫秒） spring.redis.timeout=1000 # 连接池最大连接数（使用负值表示没有限制） spring.redis.jedis.pool.max-active=20 # 连接池最大阻塞等待时间（使用负值表示没有限制） spring.redis.jedis.pool.max-wait=-1 # 连接池中的最大空闲连接 spring.redis.jedis.pool.max-idle=10 # 连接池中的最小空闲连接 spring.redis.jedis.pool.min-idle=0 ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:2:1","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"2. 配置RedisTemplate @Configuration @EnableCaching public class RedisConfig extends CachingConfigurerSupport { /** * RedisTemplate相关配置 * 使redis支持插入对象 */ @Bean public RedisTemplate\u003cString, Object\u003e redisTemplate(RedisConnectionFactory factory) { RedisTemplate\u003cString, Object\u003e template = new RedisTemplate\u003c\u003e(); // 配置连接工厂 template.setConnectionFactory(factory); // 设置key的序列化器 template.setKeySerializer(new StringRedisSerializer()); // 设置value的序列化器 //使用Jackson 2，将对象序列化为JSON Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); //Json转对象类，不设置默认的会将Json转成HashMap ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer); return template; } } 自此，Spring Boot 已完成集成Redis，可以通过依赖注入使用RedisTemplate，如下所示： @Autowired private RedisTemplate\u003cString, Object\u003e redisTemplate; ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:2:2","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"实现限流（方式1） ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:3:0","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"1. 限流思路 编写自定义注解，为后续过滤接口提供标识 通过IP+方法名作为key，访问次数作为value的方式对某一用户的请求进行标识 每次访问的时候判断key是否存在，count是否超过限制的次数 若访问超出限制，则通过拦截器直接返回错误信息：请求过于频繁 ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:3:1","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"2. 添加自定义注解 AccessLimit @Inherited @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface AccessLimit { /** * 请求次数的指定时间范围 : 秒数(redis数据过期时间) */ int second() default 60; /** * 指定second 时间内 : API请求次数 */ int maxCount() default 3; } ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:3:2","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"3. 编写拦截器 @Slf4j @Component public class AccessLimitInterceptor implements HandlerInterceptor { @Autowired private RedisTemplate\u003cString, Object\u003e redisTemplate; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // Handler 是否为 HandlerMethod 实例 if (handler instanceof HandlerMethod) { HandlerMethod handlerMethod = (HandlerMethod) handler; // 获取方法 Method method = handlerMethod.getMethod(); // 是否有AccessLimit注解 if (!method.isAnnotationPresent(AccessLimit.class)) { return true; } // 获取注解内容信息 AccessLimit accessLimit = method.getAnnotation(AccessLimit.class); if (accessLimit == null) { return true; } // 获取次数和超时 int seconds = accessLimit.second(); int maxCount = accessLimit.maxCount(); // 存储key String key = IpUtil.getIpAddr(request)+method.getName(); // 从Redis中获取用户已经访问的次数 try { Integer count = (Integer) redisTemplate.opsForValue().get(key); System.out.println(\"已经访问的次数:\" + count); // Redis不存在用户访问记录 if (null == count || -1 == count) { redisTemplate.opsForValue().set(key, 1, seconds, TimeUnit.SECONDS); return true; } if (count \u003c maxCount) { // 访问次数+1 redisTemplate.opsForValue().increment(key); return true; } if (count \u003e= maxCount) { // 超出访问限制 response.setContentType(\"application/json;charset=UTF-8\"); OutputStream out = response.getOutputStream(); out.write(\"请求过于频繁请稍后再试\".getBytes(\"UTF-8\")); out.flush(); out.close(); log.warn(\"请求过于频繁请稍后再试\"); return false; } }catch (RedisConnectionFailureException e){ log.error(\"redis error\" + e.getMessage().toString()); return true; } } return true; } } ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:3:3","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"4. 注册拦截器 @Configuration public class IntercepterConfig implements WebMvcConfigurer { @Autowired private AccessLimitInterceptor accessLimitInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(accessLimitInterceptor) .addPathPatterns(\"/**\") // 拦截路径 .excludePathPatterns(\"/user/login\"); // 不拦截路径 } } ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:3:4","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"5. 通过AccessLimit注解测试最终效果 @RestController public class TestController { @AccessLimit(second = 60,maxCount = 5) @GetMapping(\"test\") public String test(){ return \"TEST\"; } } ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:3:5","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"实现限流（方式2） ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:4:0","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"1. 限流注解 首先需要创建一个限流注解，限流将分为两种情况： 针对当前接口的全局性限流，例如该接口可以在 1 分钟内访问 100 次。 针对某一个 IP 地址的限流，例如某个 IP 地址可以在 1 分钟内访问 100 次。 针对这两种情况，我们创建一个枚举类： public enum LimitType { /** * 默认策略全局限流 */ DEFAULT, /** * 根据请求者IP进行限流 */ IP } 下一步，创建限流注解： @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RateLimiter { /** * 限流key前缀 */ String key() default \"rate_limit:\"; /** * 限流时间,单位秒 */ int time() default 60; /** * 限流次数 */ int count() default 100; /** * 限流类型 */ LimitType limitType() default LimitType.DEFAULT; } ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:4:1","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"2. 定制 RedisTemplate 在 Spring Boot 中，我们其实更习惯使用 Spring Data Redis 来操作 Redis，不过默认的 RedisTemplate 有一个小坑，就是序列化用的是 JdkSerializationRedisSerializer，不知道小伙伴们有没有注意过，直接用这个序列化工具将来存到 Redis 上的 key 和 value 都会莫名其妙多一些前缀，这就导致你用命令读取的时候可能会出错。 修改 RedisTemplate 序列化方案，代码如下： @Configuration public class RedisConfig { @Bean public RedisTemplate\u003cObject, Object\u003e redisTemplate(RedisConnectionFactory connectionFactory) { RedisTemplate\u003cObject, Object\u003e redisTemplate = new RedisTemplate\u003c\u003e(); redisTemplate.setConnectionFactory(connectionFactory); // 使用Jackson2JsonRedisSerialize 替换默认序列化(默认采用的是JDK序列化) Jackson2JsonRedisSerializer\u003cObject\u003e jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u003c\u003e(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); redisTemplate.setKeySerializer(jackson2JsonRedisSerializer); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.setHashKeySerializer(jackson2JsonRedisSerializer); redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); return redisTemplate; } } ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:4:2","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"3. 开发 Lua 脚本 Redis 中的一些原子操作我们可以借助 Lua 脚本来实现，想要调用 Lua 脚本，我们有两种不同的思路： 在 Redis 服务端定义好 Lua 脚本，然后计算出来一个散列值，在 Java 代码中，通过这个散列值锁定要执行哪个 Lua 脚本。 直接在 Java 代码中将 Lua 脚本定义好，然后发送到 Redis 服务端去执行。 Spring Data Redis 中也提供了操作 Lua 脚本的接口，还是比较方便的，所以我们这里就采用第二种方案。 在 resources 目录下新建 lua 文件夹专门用来存放 lua 脚本，脚本内容如下： local key = KEYS[1] local count = tonumber(ARGV[1]) local time = tonumber(ARGV[2]) local current = redis.call('get', key) if current and tonumber(current) \u003e count then return tonumber(current) end current = redis.call('incr', key) if tonumber(current) == 1 then redis.call('expire', key, time) end return tonumber(current) KEYS 和 ARGV 都是一会调用时候传进来的参数，tonumber 就是把字符串转为数字，redis.call 就是执行具体的 redis 指令，具体流程是这样： 首先获取到传进来的 key 以及 限流的 count 和时间 time。 通过 get 获取到这个 key 对应的值，这个值就是当前时间窗内这个接口可以访问多少次。 如果是第一次访问，此时拿到的结果为 nil，否则拿到的结果应该是一个数字，所以接下来就判断， 如果拿到的结果是一个数字，并且这个数字还大于 count，那就说明已经超过流量限制了，那么直接返回查询的结果即可。 如果拿到的结果为 nil，说明是第一次访问，此时就给当前 key 自增 1，然后设置一个过期时间。 最后把自增 1 后的值返回就可以了。 接下来我们在一个 Bean 中来加载这段 Lua 脚本，如下： @Bean public DefaultRedisScript\u003cLong\u003e limitScript() { DefaultRedisScript\u003cLong\u003e redisScript = new DefaultRedisScript\u003c\u003e(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(\"lua/limit.lua\"))); redisScript.setResultType(Long.class); return redisScript; } ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:4:3","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"4. 注解解析（通过AspectJ自定义切面） @Aspect @Component public class RateLimiterAspect { private static final Logger log = LoggerFactory.getLogger(RateLimiterAspect.class); @Autowired private RedisTemplate\u003cObject, Object\u003e redisTemplate; @Autowired private RedisScript\u003cLong\u003e limitScript; @Before(\"@annotation(rateLimiter)\") public void doBefore(JoinPoint point, RateLimiter rateLimiter) throws Throwable { String key = rateLimiter.key(); int time = rateLimiter.time(); int count = rateLimiter.count(); String combineKey = getCombineKey(rateLimiter, point); List\u003cObject\u003e keys = Collections.singletonList(combineKey); try { Long number = redisTemplate.execute(limitScript, keys, count, time); if (number==null || number.intValue() \u003e count) { throw new ServiceException(\"访问过于频繁，请稍候再试\"); } log.info(\"限制请求'{}',当前请求'{}',缓存key'{}'\", count, number.intValue(), key); } catch (ServiceException e) { throw e; } catch (Exception e) { throw new RuntimeException(\"服务器限流异常，请稍候再试\"); } } public String getCombineKey(RateLimiter rateLimiter, JoinPoint point) { StringBuffer stringBuffer = new StringBuffer(rateLimiter.key()); if (rateLimiter.limitType() == LimitType.IP) { stringBuffer.append(IpUtils.getIpAddr(((ServletRequestAttributes) RequestContextHolder.currentRequestAttributes()).getRequest())).append(\"-\"); } MethodSignature signature = (MethodSignature) point.getSignature(); Method method = signature.getMethod(); Class\u003c?\u003e targetClass = method.getDeclaringClass(); stringBuffer.append(targetClass.getName()).append(\"-\").append(method.getName()); return stringBuffer.toString(); } } 这个切面就是拦截所有加了 @RateLimiter 注解的方法，在前置通知中对注解进行处理。 首先获取到注解中的 key、time 以及 count 三个参数。 获取一个组合的 key，所谓的组合的 key，就是在注解的 key 属性基础上，再加上方法的完整路径，如果是 IP 模式的话，就再加上 IP 地址。以 IP 模式为例，最终生成的 key 类似这样：rate_limit:127.0.0.1-com.demo.ratelimiter.controller.HelloController-hello（如果不是 IP 模式，那么生成的 key 中就不包含 IP 地址）。 将生成的 key 放到集合中。 通过 redisTemplate.execute 方法取执行一个 Lua 脚本，第一个参数是脚本所封装的对象，第二个参数是 key，对应了脚本中的 KEYS，后面是可变长度的参数，对应了脚本中的 ARGV。 将 Lua 脚本执行的结果与 count 进行比较，如果大于 count，就说明过载了，抛异常就行了。 ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:4:4","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["实践笔记"],"content":"5. 接口测试 @RestController public class HelloController { @GetMapping(\"/hello\") @RateLimiter(time = 5,count = 3,limitType = LimitType.IP) public String hello() { return \"hello\u003e\u003e\u003e\"+new Date(); } } 每一个 IP 地址，在 5 秒内只能访问 3 次。 ","date":"2022-11-26","objectID":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/:4:5","tags":["SpringBoot","Redis"],"title":"SpringBoot+Redis实现接口限流","uri":"/springboot-redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/"},{"categories":["收藏分享"],"content":"Nginx配置http代理非常简单，网上教程也很多，但是无法很方便的配置https代理，本片文章将记录搭建可以同时代理http和https的服务器。 ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:0:0","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"准备工作 首先我们得需要下载Nginx及第三方模块ngx_http_proxy_connect_module wget http://nginx.org/download/nginx-1.18.0.tar.gz wget https://github.com/chobits/ngx_http_proxy_connect_module/archive/master.zip 值得注意的是，ngx_http_proxy_connect_module第三方模块与Nginx 有版本对应关系，需要在其官网确定版本对应关系。 ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:1:0","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"安装程序 将刚刚下好的程序进行解压安装 #解压Nginx tar -zxvf nginx-1.18.0.tar.gz #解压ngx_http_proxy_connect_module unzip master.zip cd nginx-1.18.0 #打补丁，版本需注意 patch -p1 \u003c /path/to/ngx_http_proxy_connect_module/patch/proxy_connect.patch #执行编译命令 ./configure --prefix=/usr/share/nginx --add-module=/path/to/ngx_http_proxy_connect_module make \u0026\u0026 make install ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:2:0","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"配置 Nginx 正向代理 配置nginx.conf，在http模块添加如下配置即可 server { resolver 114.114.114.114 ipv6=off; #DNS配置 resolver_timeout 10s; listen 8888; proxy_connect; #启用 CONNECT HTTP方法 proxy_connect_allow 443 80; #指定代理CONNECT方法可以连接的端口号或范围的列表 proxy_connect_connect_timeout 20s; #定义客户端与代理服务器建立连接的超时时间 proxy_connect_read_timeout 20s; #定义客户端从代理服务器读取响应的超时时间 proxy_connect_send_timeout 20s; #设置客户端将请求传输到代理服务器的超时时间 location / { proxy_pass $scheme://$http_host$request_uri; } } ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:3:0","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"配置客户端代理服务器 ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:4:0","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"Linux 打开/etc/profile文件，在最下面添加如下配置即可 #http代理，ip是nginx的ip，端口是nginx配置的监听端口 export http_proxy=\"http://ip:8888\" #https代理 export https_proxy=\"http://ip:8888\" #不需要代理的ip,访问这些ip，不会走代理 export no_proxy=\"127.0.0.1, localhost\" ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:4:1","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"为Nginx配置systemctl ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:5:0","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"创建一个nginx.service 在 /usr/lib/systemd/system/ 目录下面新建一个nginx.service文件，并赋予可执行的权限： chmod +x /usr/lib/systemd/system/nginx.service ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:5:1","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"编辑service内容 vim /usr/lib/systemd/system/nginx.service [Unit] //对服务的说明 Description=nginx - high performance web server //描述服务 After=network.target remote-fs.target nss-lookup.target //描述服务类别 [Service] //服务的一些具体运行参数的设置 Type=forking //后台运行的形式 PIDFile=/usr/local/nginx/logs/nginx.pid //PID文件的路径 ExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf //启动准备 ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf //启动命令 ExecReload=/usr/local/nginx/sbin/nginx -s reload //重启命令 ExecStop=/usr/local/nginx/sbin/nginx -s stop //停止命令 ExecQuit=/usr/local/nginx/sbin/nginx -s quit //快速停止 PrivateTmp=true //给服务分配临时空间 [Install] WantedBy=multi-user.target //服务用户的模式 ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:5:2","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"启动服务 在启动服务之前，需要先重载systemctl命令 systemctl daemon-reload systemctl start nginx.service ","date":"2022-11-26","objectID":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/:5:3","tags":["Nginx","网络代理"],"title":"Nginx配置Http和Https正向代理","uri":"/nginx%E9%85%8D%E7%BD%AEhttp%E5%92%8Chttps%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"},{"categories":["收藏分享"],"content":"本文章主要是一些简洁的JS代码片段，主要提升代码质量以及美观 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:0:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"从数组中删除重复项 const numbers = [1, 1, 20, 3, 3, 3, 9, 9]; const uniqueNumbers = [...new Set(numbers)]; // -\u003e [1, 20, 3, 9] 在 JavaScript 中，Set 是一个集合，它允许你仅存储唯一值。这意味着删除任何重复的值 展开运算符…将任何可迭代对象转换为数组 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:1:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"较短的 If-Else 的空合并 let maybeSomething; // LONG FORM if(maybeSomething){ console.log(maybeSomething) } else { console.log(\"Nothing found\") } //SHORTHAND console.log(maybeSomething ?? \"Nothing found\") nullish合并操作 ??，如果没有定义左侧返回右侧。如果是，则返回左侧 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:2:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"防止崩溃的可选链 const student = { name: \"Matt\", age: 27, address: { state: \"New York\" }, }; // LONG FORM console.log(student \u0026\u0026 student.address \u0026\u0026 student.address.ZIPCode); // Doesn't exist - Returns undefined // SHORTHAND console.log(student?.address?.ZIPCode); // Doesn't exist - Returns undefined 在未定义属性时使用可选链运算符，undefined将返回而不是错误。这可以防止你的代码崩溃 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:3:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"在没有第三个变量的情况下交换两个变量 let x = 1; let y = 2; // LONGER FORM let temp = x; x = y; y = temp; // SHORTHAND [x, y] = [y, x]; 在 JavaScript 中，你可以使用解构从数组中拆分值 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:4:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"将任何值转换为布尔值 !!true // true !!2 // true !![] // true !!\"Test\" // true !!false // false !!0 // false !!\"\" // false 在 JavaScript 中，你可以使用 !! 在 JS 中将任何内容转换为布尔值 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:5:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"扩展运算符 const nums1 = [1, 2, 3]; const nums2 = [4, 5, 6]; // LONG FORM let newArray = nums1.concat(nums2); // SHORTHAND newArray = [...nums1, ...nums2]; 使用扩展运算符组合两个数组 let numbers = [1, 2, 3]; // LONGER FORM numbers.push(4); numbers.push(5); // SHORTHAND numbers = [...numbers, 4, 5]; 也可以使用此语法代替将值推送到数组 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:6:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"传播解构 const student = { name: \"Matt\", age: 23, city: \"Helsinki\", state: \"Finland\", }; // LONGER FORM const name = student.name; const age = student.age; const address = { city: student.city, state: student.state }; // SHORTHAND const { name, age, ...address } = student; 使用扩展运算符将剩余元素分配给变量 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:7:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"使用 \u0026\u0026 进行短路评估 var isReady = true; function doSomething(){ console.log(\"Yay!\"); } // LONGER FORM if(isReady){ doSomething(); } // SHORTHAND isReady \u0026\u0026 doSomething(); 不必用if语句检查某事是否为真，你可以使用\u0026\u0026运算符 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:8:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"类固醇的字符串 const age = 41; const sentence = `I'm ${age} years old`; // result: I'm 41 years old 通过将字符串包装在反引号内并${}用于嵌入值，从而在字符串之间插入变量 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:9:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"从数组中查找特定元素 const fruits = [ { type: \"Banana\", color: \"Yellow\" }, { type: \"Apple\", color: \"Green\" } ]; // LONGER FORM let yellowFruit; for (let i = 0; i \u003c fruits.length; ++i) { if (fruits[i].color === \"Yellow\") { yellowFruit = fruits[i]; } } // SHORTHAND yellowFruit = fruits.find((fruit) =\u003e fruit.color === \"Yellow\"); 使用find()方法查找匹配特定条件的元素 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:10:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"对象属性赋值 const name = \"Luis\", city = \"Paris\", age = 43, favoriteFood = \"Spaghetti\"; // LONGER FORM const person = { name: name, city: city, age: age, favoriteFood: favoriteFood }; // SHORTHAND const person = { name, city, age, favoriteFood }; 你是否希望对象键与值具有相同的名称？你可以省略对象文字来执行此操作 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:11:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"压缩 For 循环 const numbers = [1, 2, 3, 4, 5]; // LONGER FORM for(let i = 0; i \u003c numbers.length; i++){ console.log(numbers[i]); } // SHORTHAND numbers.forEach(number =\u003e console.log(number)); 使用内置forEach()方法通过一行代码循环遍历数组 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:12:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"默认功能参数 // LONG FORM function pickUp(fruit) { if(fruit === undefined){ console.log(\"I picked up a Banana\"); } else { console.log(`I picked up a ${fruit}`); } } // SHORTHAND function pickUp(fruit = \"Banana\") { console.log(`I picked up a ${fruit}`) } pickUp(\"Mango\"); // -\u003e I picked up a Mango pickUp(); // -\u003e I picked up a Banana 可以为函数参数提供默认值 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:13:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"将对象的值收集到数组中 const info = { name: \"Matt\", country: \"Finland\", age: 35 }; // LONGER FORM let data = []; for (let key in info) { data.push(info[key]); } // SHORTHAND const data = Object.values(info); Object.values()将对象的所有值收集到一个新数组中 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:14:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"检查一个项目是否存在于数组中 let numbers = [1, 2, 3]; // LONGER FORM const hasNumber1 = numbers.indexOf(1) \u003e -1 // -\u003e True // SHORTHAND/CLEANER APPROACH const hasNumber1 = numbers.includes(1) // -\u003e True 可以使用 includes() 方法，而不是使用 indexOf() 方法来检查元素是否在数组中 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:15:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"压缩多个条件 const num = 1; // LONGER FORM if(num == 1 || num == 2 || num == 3){ console.log(\"Yay\"); } // SHORTHAND if([1,2,3].includes(num)){ console.log(\"Yay\"); } 避免使用长|| 检查多个条件链，你可以使用你刚刚在上一个技巧中学到的东西——即，使用 includes() 方法 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:16:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"指数运算符 // LONGER FORM Math.pow(4,2); // 16 Math.pow(2,3); // 8 // SHORTHAND 4**2 // 16 2**3 // 8 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:17:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"Math.floor() 简写 // LONG FORM Math.floor(5.25) // -\u003e 5.0 // SHORTHAND ~~5.25 // -\u003e 5.0 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:18:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"用一行代码分配多个值 let num1, num2; // LONGER FORM num1 = 10; num2 = 100; // SHORTHAND [num1, num2] = [10, 100]; student = { name: \"Matt\", age: 29, }; // LONGER FORM let name = student.name; let age = student.age; // SHORTHAND let { name, age } = student; ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:19:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"从url获取参数并转为对象 const getParameters = URL =\u003e JSON.parse(`{\"${decodeURI(URL.split(\"?\")[1]).replace(/\"/g, '\\\\\"').replace(/\u0026/g, '\",\"').replace(/=/g, '\":\"')}\"}` ) getParameters(\"https://www.google.com.hk/search?q=js+md\u0026newwindow=1\"); // {q: 'js+md', newwindow: '1'} ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:20:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"检查对象是否为空 const isEmpty = obj =\u003e Reflect.ownKeys(obj).length === 0 \u0026\u0026 obj.constructor === Object; isEmpty({}) // true isEmpty({a:\"not empty\"}) //false ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:21:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"反转字符串 const reverse = str =\u003e str.split('').reverse().join(''); reverse('this is reverse'); // esrever si siht ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:22:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"生成随机十六进制 const randomHexColor = () =\u003e `#${Math.floor(Math.random() * 0xffffff).toString(16).padEnd(6, \"0\")}` console.log(randomHexColor()); // #a2ce5b ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:23:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"检查当前选项卡是否在后台 const isTabActive = () =\u003e !document.hidden; isTabActive() // true|false ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:24:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"检测元素是否处于焦点 const elementIsInFocus = (el) =\u003e (el === document.activeElement); elementIsInFocus(anyElement) // 元素处于焦点返回true，反之返回false ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:25:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"检查设备类型 const judgeDeviceType = () =\u003e /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|OperaMini/i.test(navigator.userAgent) ? 'Mobile' : 'PC'; judgeDeviceType() // PC | Mobile ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:26:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"文字复制到剪贴板 const copyText = async (text) =\u003e await navigator.clipboard.writeText(text) copyText('单行代码 前端世界') ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:27:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"获取选定的文本 const getSelectedText = () =\u003e window.getSelection().toString(); getSelectedText(); ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:28:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"查询某天是否为工作日 const isWeekday = (date) =\u003e date.getDay() % 6 !== 0; isWeekday(new Date(2022, 03, 11)) ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:29:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"转换华氏/摄氏 // 华氏温度转换为摄氏温度 const fahrenheitToCelsius = (fahrenheit) =\u003e (fahrenheit - 32) * 5/9; fahrenheitToCelsius(50); // 10 // 摄氏温度转华氏温度 const celsiusToFahrenheit = (celsius) =\u003e celsius * 9/5 + 32; celsiusToFahrenheit(100) // 212 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:30:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"两日期之间相差的天数 const dayDiff = (date1, date2) =\u003e Math.ceil(Math.abs(date1.getTime() - date2.getTime()) / 86400000); dayDiff(new Date(\"2021-10-21\"), new Date(\"2022-02-12\")) // Result: 114 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:31:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"将 RGB 转换为十六进制 const rgbToHex = (r, g, b) =\u003e \"#\" + ((1 \u003c\u003c 24) + (r \u003c\u003c 16) + (g \u003c\u003c 8) + b).toString(16).slice(1); rgbToHex(255, 255, 255); // #ffffff ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:32:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"计算数组平均值 const average = (arr) =\u003e arr.reduce((a, b) =\u003e a + b) / arr.length; average([1,9,18,36]) //16 ","date":"2022-11-26","objectID":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/:33:0","tags":["JavaScript"],"title":"一些简洁的JS代码片段","uri":"/%E4%B8%80%E4%BA%9B%E7%AE%80%E6%B4%81%E7%9A%84js%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"},{"categories":["收藏分享"],"content":"在编写数据库文档时，我们常常需要写表结构文档，这时候就需要一些方法来节约我们写文档的时间 我通过网络上的资料，总结了 MySQL 及 SQL Server 的通过SQL语句导出数据库表结构的方法 ","date":"2022-11-26","objectID":"/%E9%80%9A%E8%BF%87sql%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84/:0:0","tags":["SQL"],"title":"通过SQL导出数据库表结构","uri":"/%E9%80%9A%E8%BF%87sql%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84/"},{"categories":["收藏分享"],"content":"MySQL SELECT COLUMN_NAME 列名, COLUMN_TYPE 数据类型, DATA_TYPE 字段类型, CHARACTER_MAXIMUM_LENGTH 长度, IS_NULLABLE 是否为空, COLUMN_DEFAULT 默认值, COLUMN_COMMENT 备注 FROM INFORMATION_SCHEMA.COLUMNS WHERE table_schema = '数据库名称' -- 数据库名称 AND table_name = '表名' -- 表名 -- 如果不写的话，默认会查询出所有表中的数据，这样可能就分不清到底哪些字段是哪张表中的了，所以还是建议写上要导出的名名称 ","date":"2022-11-26","objectID":"/%E9%80%9A%E8%BF%87sql%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84/:1:0","tags":["SQL"],"title":"通过SQL导出数据库表结构","uri":"/%E9%80%9A%E8%BF%87sql%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84/"},{"categories":["收藏分享"],"content":"SQL Server SELECT 表名 = Case When A.colorder=1 Then D.name Else '' End, 表说明 = Case When A.colorder=1 Then isnull(F.value,'') Else '' End, 字段序号 = A.colorder, 字段名 = A.name, 字段说明 = isnull(G.[value],''), 标识 = Case When COLUMNPROPERTY( A.id,A.name,'IsIdentity')=1 Then '√'Else '' End, 主键 = Case When exists(SELECT 1 FROM sysobjects Where xtype='PK' and parent_obj=A.id and name in ( SELECT name FROM sysindexes WHERE indid in( SELECT indid FROM sysindexkeys WHERE id = A.id AND colid=A.colid))) then '√' else '' end, 类型 = B.name, 占用字节数 = A.Length, 长度 = COLUMNPROPERTY(A.id,A.name,'PRECISION'), 小数位数 = isnull(COLUMNPROPERTY(A.id,A.name,'Scale'),0), 允许空 = Case When A.isnullable=1 Then '√'Else '' End, 默认值 = isnull(E.Text,'') FROM syscolumns A Left Join systypes B On A.xusertype=B.xusertype Inner Join sysobjects D On A.id=D.id and D.xtype='U' and D.name\u003c\u003e'dtproperties' Left Join syscomments E on A.cdefault=E.id Left Join sys.extended_properties G on A.id=G.major_id and A.colid=G.minor_id Left Join sys.extended_properties F On D.id=F.major_id and F.minor_id=0 where d.name='表名' --如果只查询指定表,加上此条件 Order By A.id,A.colorder ","date":"2022-11-26","objectID":"/%E9%80%9A%E8%BF%87sql%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84/:2:0","tags":["SQL"],"title":"通过SQL导出数据库表结构","uri":"/%E9%80%9A%E8%BF%87sql%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84/"},{"categories":["收藏分享"],"content":"如电脑设置了网络代理，会导致一些软件工具不能正常工作。查找了网上许多解决方案，总结如下。 ","date":"2022-11-26","objectID":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/:0:0","tags":["网络代理"],"title":"设置代理后需要注意的事","uri":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/"},{"categories":["收藏分享"],"content":"Git 设置全局Config代理 git config --global http.proxy http://server:port git config --global https.proxy http://server:port git config --global http.https://github.com.proxy http://server:port git config --global https.https://github.com.proxy http://server:port 去除代理设置 git config --global --unset http.proxy git config --global --unset https.proxy git config --global --unset http.https://github.com.proxy git config --global --unset https.https://github.com.proxy 当我使用这种方式时没有效果 使用clone时配置代理 git clone -c http.proxy=\"server:port\" https://github.com/LesanOuO/lesan-homepage.git ","date":"2022-11-26","objectID":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/:1:0","tags":["网络代理"],"title":"设置代理后需要注意的事","uri":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/"},{"categories":["收藏分享"],"content":"NPM 全局设置代理 npm config set proxy http://server:port 配置https代理（设置了proxy就不需要设置https-proxy） npm config set https-proxy http://server:port 如果需要代理用户名和密码 npm config set proxy http://username:password@server:port npm confit set https-proxy http://username:password@server:port 取消代理 npm config delete proxy npm config delete https-proxy npm config set proxy null npm config set https-proxy null ","date":"2022-11-26","objectID":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/:2:0","tags":["网络代理"],"title":"设置代理后需要注意的事","uri":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/"},{"categories":["收藏分享"],"content":"Maven 需要在settings.xml中配置proxies节点 ... \u003cproxies\u003e \u003cproxy\u003e \u003cid\u003eoptional\u003c/id\u003e \u003cactive\u003etrue\u003c/active\u003e \u003cprotocol\u003ehttp\u003c/protocol\u003e \u003chost\u003e127.0.0.1\u003c/host\u003e \u003cport\u003e8888\u003c/port\u003e \u003c/proxy\u003e \u003c/proxies\u003e ... ","date":"2022-11-26","objectID":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/:3:0","tags":["网络代理"],"title":"设置代理后需要注意的事","uri":"/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%90%8E%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%BA%8B/"},{"categories":["实践笔记"],"content":"本篇主要介绍的就是 controller 层的一些优雅技巧，一个完整的后端请求由4部分组成：1. 接口地址(也就是URL地址)、2. 请求方式(一般就是get、set，当然还有put、delete)、3. 请求数据(request，有head跟body)、4. 响应数据(response) 本篇将解决以下3个问题： 当接收到请求时，如何优雅的校验参数 返回响应数据该如何统一的进行处理 接收到请求，处理业务逻辑时抛出了异常又该如何处理 ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:0:0","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"统一返回格式 ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:1:0","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"封装ResultVo 首先先定义一个状态码的接口，所有状态码都需要实现它，有了标准才好做事 public interface StatusCode { public int getCode(); public String getMsg(); } 与前端规定好自定义状态码 @Getter @AllArgsConstructor @NoArgsConstructor public enum ResultCode implements StatusCode { SUCCESS(1000, \"请求成功\"), FAILED(1001, \"请求失败\"), VALIDATE_ERROR(1002, \"参数校验失败\"), RESPONSE_PACK_ERROR(1003, \"response返回包装失败\"); private int code; private String msg; } 定义 ResultVo 包装类 @Data public class ResultVo { // 状态码 private int code; // 状态信息 private String msg; // 返回对象 private Object data; // 手动设置返回vo public ResultVo(int code, String msg, Object data) { this.code = code; this.msg = msg; this.data = data; } // 默认返回成功状态码，数据对象 public ResultVo(Object data) { this.code = ResultCode.SUCCESS.getCode(); this.msg = ResultCode.SUCCESS.getMsg(); this.data = data; } // 返回指定状态码，数据对象 public ResultVo(StatusCode statusCode, Object data) { this.code = statusCode.getCode(); this.msg = statusCode.getMsg(); this.data = data; } // 只返回状态码 public ResultVo(StatusCode statusCode) { this.code = statusCode.getCode(); this.msg = statusCode.getMsg(); this.data = null; } } ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:1:1","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"统一校验 ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:2:0","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"引入依赖 由于新版 Spring Boot 已不内置校验模块，需自己引入相应的包 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-validation\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:2:1","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"通过@Validated实现参数校验 @Data public class AddUserVo { @NotNull(message = \"用户名不能为空\") private String userName; @Length(min = 8, message = \"密码最少需要8位\") private String password; private Integer age; } @PostMapping(\"/addUser\") public AddUserVo addUser(@Validated AddUserVo userVo) { return userVo; } 虽然成功校验了参数，也返回了异常，但是返回的异常不符合预期，与我们之前定义了的统一状态码不一致，所以我们要进行优化一下，每次出现异常的时候，自动把状态码写好。 ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:2:2","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"优化异常处理 我们可以通过控制台看出，校验参数抛出了什么异常 Resolved [org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors 我们看到代码抛出了org.springframework.validation.BindException的绑定异常，因此我们的思路就是AOP拦截所有controller，然后异常的时候统一拦截起来，进行封装！ 但是我们可以通过 Spring Boot 提供的@RestControllerAdvice来增强所有@RestController，然后使用@ExceptionHandler注解，就可以拦截到对应的异常。这样开发起来就方便很多。 这里我们就拦截BindException.class就好了。最后在返回之前，我们对异常信息进行包装一下，包装成ResultVo，当然要跟上ResultCode.VALIDATE_ERROR的异常状态码。 @RestControllerAdvice public class ControllerExceptionAdvice { @ExceptionHandler({BindException.class}) public ResultVo MethodArgumentNotValidExceptionHandler(BindException e){ // 从异常对象中拿到ObjectError对象 ObjectError objectError = e.getBindingResult().getAllErrors().get(0); return new ResultVo(ResultCode.VALIDATE_ERROR, objectError.getDefaultMessage()); } } ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:2:3","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"统一响应 ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:3:0","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"统一包装响应 前面写的ResultVo导致每一个接口都需要写new ResultVo(data)，这样开发小哥肯定不乐意了，所以我们要优化封装，让AOP拦截所有Controller，然后再自动包一层ResultVo。 但是 Spring Boot 中也有现成的供我们使用： @RestControllerAdvice public class ControllerResponseAdvice implements ResponseBodyAdvice\u003cObject\u003e { @Override public boolean supports(MethodParameter returnType, Class\u003c? extends HttpMessageConverter\u003c?\u003e\u003e converterType) { // response是ResultVo类型，或者注释了NotControllerResponseAdvice都不进行包装 return !(returnType.getParameterType().isAssignableFrom(ResultVo.class)); } @Override public Object beforeBodyWrite(Object body, MethodParameter returnType, MediaType selectedContentType, Class\u003c? extends HttpMessageConverter\u003c?\u003e\u003e selectedConverterType, ServerHttpRequest request, ServerHttpResponse response) { // String类型不能直接包装 if (returnType.getGenericParameterType().equals(String.class)){ ObjectMapper objectMapper = new ObjectMapper(); try { // 将数据包装在ResultVo里后转换为json串进行返回 return objectMapper.writeValueAsString(new ResultVo(body)); } catch (JsonProcessingException e) { throw new RuntimeException(e); } } // 否则直接包装成ResultVo返回 return new ResultVo(body); } } @RestControllerAdvice(basePackages = {\"com.example\"})自动扫描了所有指定包下的controller，在Response时进行统一处理 重写supports方法，也就是说，当返回类型已经是ResultVo了，那就不需要封装了，当不等与ResultVo时才进行调用beforeBodyWrite方法，跟过滤器的效果是一样的 最后重写我们的封装方法beforeBodyWrite，注意除了String的返回值有点特殊，无法直接封装成json，我们需要进行特殊处理，其他的直接new ResultVo(data);就ok了 ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:3:1","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"NOT统一响应 有的时候，我们的系统不需要包装一层统一响应，比如项目中集成了一个健康检测的功能，这个时候是不需要包装统一响应的，导致最后接口对应不上。 @GetMapping(\"/health\") public String health(Integer id) { return \"success\"; } 因为百分之99的请求还是需要包装的，只有个别不需要，写在包装的过滤器吧？又不是很好维护，那就加个注解好了。所有不需要包装的就加上这个注解。 @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) public @interface NotControllerResponseAdvice { } 然后在我们的增强过滤方法上过滤包含这个注解的方法 @RestControllerAdvice public class ControllerResponseAdvice implements ResponseBodyAdvice\u003cObject\u003e { @Override public boolean supports(MethodParameter returnType, Class\u003c? extends HttpMessageConverter\u003c?\u003e\u003e converterType) { // response是ResultVo类型，或者注释了NotControllerResponseAdvice都不进行包装 return !(returnType.getParameterType().isAssignableFrom(ResultVo.class) || returnType.hasMethodAnnotation(NotControllerResponseAdvice.class)); } ... 最后就在不需要包装的方法上加上注解 @GetMapping(\"/health\") @NotControllerResponseAdvice public String health(Integer id) { return \"success\"; } ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:3:2","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["实践笔记"],"content":"统一异常 每个系统都会有自己的业务异常，比如库存不能小于0子类的，这种异常并非程序异常，而是业务操作引发的异常，我们也需要进行规范的编排业务异常状态码，并且写一个专门处理的异常类，最后通过刚刚学习过的异常拦截统一进行处理，以及打日志。 异常状态码枚举，既然是状态码，那就肯定要实现我们的标准接口StatusCode @Getter @NoArgsConstructor @AllArgsConstructor public enum AppCode implements StatusCode { APP_ERROR(2000, \"业务异常\"); private int code; private String msg; } 异常类 @Getter public class APIException extends RuntimeException { private int code; private String msg; // 手动设置异常 public APIException(StatusCode statusCode, String message) { // message用于用户设置抛出错误详情，例如：当前价格-5，小于0 super(message); // 状态码 this.code = statusCode.getCode(); // 状态码配套的msg this.msg = statusCode.getMsg(); } // 默认异常使用APP_ERROR状态码 public APIException(String message) { super(message); this.code = AppCode.APP_ERROR.getCode(); this.msg = AppCode.APP_ERROR.getMsg(); } } 最后进行统一异常的拦截 @RestControllerAdvice public class ControllerExceptionAdvice { @ExceptionHandler({BindException.class}) public ResultVo MethodArgumentNotValidExceptionHandler(BindException e){ // 从异常对象中拿到ObjectError对象 ObjectError objectError = e.getBindingResult().getAllErrors().get(0); return new ResultVo(ResultCode.VALIDATE_ERROR, objectError.getDefaultMessage()); } @ExceptionHandler(APIException.class) public ResultVo APIExceptionHandler(APIException e) { // log.error(e.getMessage(), e); 由于还没集成日志框架，暂且放着，写上TODO return new ResultVo(e.getCode(), e.getMsg(), e.getMessage()); } } 最后使用，我们的代码只需要这么写 @GetMapping(\"/error\") public String error(Integer id) { if (id.equals(0)){ throw new APIException(\"用户不存在\"); } return \"error\"; } 就会自动抛出AppCode.APP_ERROR状态码的响应，并且带上异常详细信息用户不存在。 ","date":"2022-11-26","objectID":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/:4:0","tags":["SpringBoot"],"title":"让Controller层代码更优雅","uri":"/%E8%AE%A9controller%E5%B1%82%E4%BB%A3%E7%A0%81%E6%9B%B4%E4%BC%98%E9%9B%85/"},{"categories":["学习笔记"],"content":"单线程与多线程可以看作是： 单线程为在一个单向行驶的道路上，每辆汽车都遵守交通规则 多线程为多条车道，这样在同一时间内，通行的车辆数远远大于单车道 然而扩充了车道后问题就没那么简单了，车道一旦多起来加塞的场景就会越来越多，出现碰撞后也会影响整条马路的通行效率，这样多车道就不一定比单车道更快了 为了解决汽车频繁变道加塞的问题，可以通过在车道间增加护栏来规范管理 在程序中处理多线程带来的问题归纳起来就三类： 线程安全问题 活跃性问题 性能问题 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:0:0","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"线程安全问题 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:1:0","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"原子性 有一个非常经典的例子，比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元，两个操作都成功才意味着一次转账最终成功 试想一下，如果这两个操作不具备原子性，从A的账户扣减了1000元之后，操作突然终止了，账户B没有增加1000元，那问题就大了 银行转账这个例子有两个步骤，出现了意外后导致转账失败，说明没有原子性 原子性：即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行 原子操作：即不会被线程调度机制打断的操作，没有上下文切换 在并发编程中很多操作都不是原子操作，出个小题目： i = 0; // 操作1 i++; // 操作2 i = j; // 操作3 i = i + 1; // 操作4 上面这四个操作中有哪些是原子操作，哪些不是？不熟悉的人可能认为这些都是原子操作，其实只有操作1是原子操作 操作1：对基本数据类型变量的赋值是原子操作 操作2：包含三个操作，读取i的值，将i加1，将值赋给i 操作3：读取j的值，将j的值赋给i 操作4：包含三个操作，读取i的值，将i加1，将值赋给i 在单线程环境下上述四个操作都不会出现问题，但是在多线程环境下，如果不通过加锁操作，往往可能得到意料之外的值 在Java语言中通过可以使用synchronize或者lock来保证原子性 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:1:1","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"可见性 可见性：指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值 class Test { int i = 50; int j = 0; public void update() { // 线程1执行 i = 100; } public int get() { // 线程2执行 j = i; return j; } } 线程1执行update方法将 i 赋值为100，一般情况下线程1会在自己的工作内存中完成赋值操作，却没有及时将新值刷新到主内存中 这个时候线程2执行get方法，首先会从主内存中读取i的值，然后加载到自己的工作内存中，这个时候读取到i的值是50，再将50赋值给j，最后返回j的值就是50了。原本期望返回100，结果返回50，这就是可见性问题，线程1对变量i进行了修改，线程2没有立即看到i的新值 如上图每个线程都有属于自己的工作内存，工作内存和主内存间需要通过store和load等进行交互 为了解决多线程可见性问题，Java语言提供了volatile这个关键字。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通共享变量不能保证可见性，因为变量被修改后什么时候刷回到主存是不确定的，另外一个线程读的可能就是旧值 当然Java的锁机制如synchronize和lock也是可以保证可见性的，加锁可以保证在同一时刻只有一个线程在执行同步代码块，释放锁之前会将变量刷回至主存，这样也就保证了可见性 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:1:2","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"活跃性问题 上面讲到为了解决可见性问题，我们可以采取加锁方式解决，但是如果加锁使用不当也容易引入其他问题，比如死锁 活跃性是指某件正确的事情最终会发生，当某个操作无法继续下去的时候，就会发生活跃性问题 活跃性问题一般有这样几类：死锁，活锁，饥饿 问题 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:2:0","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"死锁 死锁是指多个线程因为环形的等待锁的关系而永远的阻塞下去 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:2:1","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"活锁 死锁是两个线程都在等待对方释放锁导致阻塞。而活锁的意思是线程没有阻塞，还活着呢。 当多个线程都在运行并且修改各自的状态，而其他线程彼此依赖这个状态，导致任何一个线程都无法继续执行，只能重复着自身的动作和修改自身的状态，这种场景就是发生了活锁 如果大家还有疑惑，那我再举一个生活中的例子，大家平时在走路的时候，迎面走来一个人，两个人互相让路，但是又同时走到了一个方向，如果一直这样重复着避让，这俩人就是发生了活锁 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:2:2","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"饥饿 如果一个线程无其他异常却迟迟不能继续运行，那基本是处于饥饿状态了 常见有几种场景: 高优先级的线程一直在运行消耗CPU，所有的低优先级线程一直处于等待 一些线程被永久堵塞在一个等待进入同步块的状态，而其他线程总是能在它之前持续地对该同步块进行访问 有一个非常经典的饥饿问题就是哲学家用餐问题，如下图所示，有五个哲学家在用餐，每个人必须要同时拿两把叉子才可以开始就餐，如果哲学家1和哲学家3同时开始就餐，那哲学家2、4、5就得饿肚子等待了 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:2:3","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"性能问题 前面讲到了线程安全和死锁、活锁这些问题会影响多线程执行过程，如果这些都没有发生，多线程并发一定比单线程串行执行快吗，答案是不一定，因为多线程有创建线程和线程上下文切换的开销 创建线程是直接向系统申请资源的，对操作系统来说创建一个线程的代价是十分昂贵的，需要给它分配内存、列入调度等 线程创建完之后，还会遇到线程上下文切换 CPU是很宝贵的资源，速度也非常快，为了保证雨露均沾，通常会给不同的线程分配时间片，当CPU从执行一个线程切换到执行另一个线程时，CPU需要保存当前线程的本地数据、程序指针等状态，并加载下一个要执行的线程的本地数据、程序指针等，这个开关被称为上下文切换 一般减少上下文切换的方法有：无锁并发编程、CAS 算法、使用协程等 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:3:0","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["学习笔记"],"content":"总结 多线程用好了可以让程序的效率成倍提升，用不好可能比单线程还要慢 ","date":"2022-11-26","objectID":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/:4:0","tags":["多线程"],"title":"多线程下的琐事","uri":"/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8B%E7%9A%84%E7%90%90%E4%BA%8B/"},{"categories":["实践笔记"],"content":"基本使用 静态文件（常见的有HTML，CSS，图片和JS等资源）可以通过 .NET Core 应用直接提供给客户端。还有一些比较常用的文件（PDF或者一些需要下载的文件）也是需要通过静态文件的方式提供下载的，如果没有搭建文件管理的服务器的话，通过静态文件的方式下载也是不错的选择。 静态文件一般位于网站根目录的 wwwroot 文件夹下，可以通过相对根的路径来访问文件夹中的文件，如 http://ip:port/filename 使用静态文件服务前，需要配置中间件，把静态文件中间件加入到管道中。静态文件一般会默认配置，在Configure方法中调用app.UseStaticFiles()。app.UseStaticFiles() 使得web root(默认为wwwroot)下的文件可以被访问。同时可以通过UseStaticFiles方法将其他目录下的内容也可以向外提供： // 假如wwwroot外面有一个MyStaticFiles文件夹，要访问文件夹里面的资源 app.UseStaticFiles(new StaticFileOptions() { FileProvider = new PhysicalFileProvider( Path.Combine(Directory.GetCurrentDirectory(), @\"MyStaticFiles\")), //用于定位资源的文件系统 RequestPath = new PathString(\"/StaticFiles\") //请求地址 }); // 现在可以通过http://ip:port/StaticFiles/filename 来访问文件夹下的内容 ","date":"2022-07-17","objectID":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/:1:0","tags":[".NET"],"title":".NET Core 中开启静态文件访问","uri":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/"},{"categories":["实践笔记"],"content":"静态文件授权 静态文件组件默认不提供授权检查。任何通过静态文件中间件访问的文件都是公开的。要想给文件授权，可以将文件保存在wwwroot之外，并将目录设置为可被静态文件中间件能够访问，同时通过一个controller action来访问文件，在action中授权后返回FileResult。 ","date":"2022-07-17","objectID":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/:2:0","tags":[".NET"],"title":".NET Core 中开启静态文件访问","uri":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/"},{"categories":["实践笔记"],"content":"目录浏览 目录浏览允许网站用户看到指定目录下的目录和文件列表。基于安全考虑，默认情况下是禁止目录访问功能。在Startup中Configure方法调用UseDirectoryBrowser扩展方法可以开启网络应用目录浏览： public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { app.UseStaticFiles(); app.UseDirectoryBrowser(new DirectoryBrowserOptions() { FileProvider = new PhysicalFileProvider( Path.Combine(Directory.GetCurrentDirectory(),@\"wwwroot\\images\")), RequestPath = new PathString(\"/MyImages\") //如果不指定RequestPath，会将PhysicalFileProvider中的路径参数作为默认文件夹，替换掉wwwroot }); } 然后在Startup中CongigureServices方法调用AddDirectoryBrowser扩展方法，这样就可以通过访问http://\u003capp\u003e/MyImages浏览wwwroot/images文件夹中的目录，但是不能访问文件： 要想访问具体文件需要调用UseStaticFiles配置： public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { app.UseStaticFiles(); app.UseStaticFiles(new StaticFileOptions() { FileProvider = new PhysicalFileProvider( Path.Combine(Directory.GetCurrentDirectory(), @\"wwwroot\\images\")), //用于定位资源的文件系统 RequestPath = new PathString(\"/MyImages\") }); app.UseDirectoryBrowser(new DirectoryBrowserOptions() { FileProvider = new PhysicalFileProvider( Path.Combine(Directory.GetCurrentDirectory(),@\"wwwroot\\images\")), RequestPath = new PathString(\"/MyImages\") }); } ","date":"2022-07-17","objectID":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/:3:0","tags":[".NET"],"title":".NET Core 中开启静态文件访问","uri":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/"},{"categories":["实践笔记"],"content":"UseFileServer 通过 UseFileServer 集合了UseStaticFiles,UseDefaultFiles,UseDirectoryBrowser。可以实现类似文件服务器的功能 调用app.UseFileServer(); 可以获得静态文件和默认文件，但不允许直接访问目录。需要调用app.UseFileServer(enableDirectoryBrowsing:true); 才能启用目录浏览功能。 如果想要访问wwwroot以外的文件，需要配置一个FileServerOptions对象 public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { app.UseStaticFiles();//如果不调用，将不会启动默认功能。 app.UseFileServer(new FileServerOptions() { FileProvider = new PhysicalFileProvider( Path.Combine(Directory.GetCurrentDirectory(), @\"MyStaticFiles\")), RequestPath = new PathString(\"/StaticFiles\"), EnableDirectoryBrowsing = true }); } 注意，如果将enableDirectoryBrowsing设置为true，需要在ConfigureServices中调用services.AddDirectoryBrowser();如果默认文件夹下有默认页面，将显示默认页面，而不是目录列表。 ","date":"2022-07-17","objectID":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/:4:0","tags":[".NET"],"title":".NET Core 中开启静态文件访问","uri":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/"},{"categories":["实践笔记"],"content":"FileExtensionContentTypeProvider FileExtensionContentTypeProvider类包含一个将文件扩展名映射到MIME内容类型的集合。 public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { var provider = new FileExtensionContentTypeProvider(); provider.Mappings[\".htm3\"] = \"text/html\"; provider.Mappings[\"images\"] = \"iamge/png\"; provider.Mappings.Remove(\".mp4\"); app.UseStaticFiles(new StaticFileOptions() { FileProvider = new PhysicalFileProvider( Path.Combine(Directory.GetCurrentDirectory(), @\"MyStaticFiles\")), RequestPath = new PathString(\"/StaticFiles\"), ContentTypeProvider = provider }); } ","date":"2022-07-17","objectID":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/:5:0","tags":[".NET"],"title":".NET Core 中开启静态文件访问","uri":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/"},{"categories":["实践笔记"],"content":"非标准的内容类型 如果用户请求了一个未知的文件类型，静态文件中间件将会返回HTTP 404响应。如果启用目录浏览，则该文件的链接将会被显示，但URL会返回一个HTTP404错误。 使用UseStaticFiles方法可以将未知类型作为指定类型处理： app.UseStaticFiles(new StaticFileOptions() { ServeUnknownFileTypes = true, DefaultContentType = \"application/x-msdownload\" }); 对于未识别的，默认为application/x-msdownload，浏览器将会下载这些文件。 本文参考自：https://www.jb51.net/article/244297.htm ","date":"2022-07-17","objectID":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/:6:0","tags":[".NET"],"title":".NET Core 中开启静态文件访问","uri":"/dotnetcore%E4%B8%AD%E5%BC%80%E5%90%AF%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE/"},{"categories":["实践笔记"],"content":"在维护服务器时，发现docker所在盘容量已满，导致mongodb插入数据失败从而崩溃。由此记录修改Linux中Dockder位置时遇到的问题 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:0:0","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"一些命令 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:0","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"df 命令 df命令来自于英文词组”Disk Free“的缩写，其功能是用于显示系统上磁盘空间的使用量情况。 常常使用 df -h 以容易阅读的方式显示 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:1","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"ln 命令 Linux ln（英文全拼：link files）命令是一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接。 Linux文件系统中，有所谓的链接(link)，我们可以将其视为档案的别名，而链接又可分为两种 : 硬链接(hard link)与软链接(symbolic link)，硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软链接却可以跨越不同的文件系统。 通常我们都使用 ln -s log2013.log link2013 来创建软链接 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:2","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"lsof netstat 命令 Linux 查看端口占用情况可以使用 lsof 和 netstat 命令。 可使用 lsof -i:端口号 netstat -tunlp | grep 端口号 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:3","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"kill 命令 Linux kill 命令用于删除执行中的程序或工作。 可使用 kill -9 PID 彻底杀死进程 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:4","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"top 命令 Linux top命令用于实时显示 process 的动态。 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:5","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"free 命令 Linux free命令用于显示内存状态。 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:6","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"du 命令 Linux du （英文全拼：disk usage）命令用于显示目录或文件的大小。 通常使用 du -h 提高信息的可读性 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:1:7","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"修改 Docker 存储位置 通过软链接 // 停止 docker 服务 systemctl stop Docker // 移动整个 /var/lib/docker 目录到目标路径(/data/docker) mv /var/lib/docker /data/docker // 创建软链接 ln -s /root/docker /var/lib/docker // 重启 docker systemctl start docker 修改 docker 配置文件 // 停止 docker 服务 systemctl stop docker // 移动整个 /var/lib/docker 目录到目标路径(/data/docker) mv /var/lib/docker /data/docker // 修改 docker.service 文件 vim /usr/lib/systemd/system/docker.service // 重启 docker 服务 systemctl daemon-reload systemctl start docker // 查看配置是否生效 docker info | grep \"Docker Root Dir\" 其中 docker.service 修改的内容为： 在 ExecStart=/usr/bin/dockerd 后面添加参数 --graph /data/docker 结果如下： ExecStart=/usr/bin/dockerd --graph /data/docker -H fd:// --containerd=/run/containerd/containerd.sock ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:2:0","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["实践笔记"],"content":"Docker 中 mongodb 出现错误 在更换了 docker 存储位置后， mongodb 启动后就一直报错 Failed to set up listener: SocketException: Permission denied ，原因是以为启动mongo时,无法写入mongo.socket文件到/tmp目录下 查阅了网络上的多个教程，最终有效的是下面的解决方案： 将本地的/tmp目录挂在到mongo容器中，如果是已启动的容器，可通过我的 docker为已启动容器添加挂载目录或端口映射 这篇文章进行挂载；如果是新启动的容器，只需要 -v /tmp:/tmp 即可 ","date":"2022-07-02","objectID":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/:3:0","tags":["Linux","Docker"],"title":"Linux中修改Docker存储位置","uri":"/linux%E4%B8%AD%E4%BF%AE%E6%94%B9docker%E5%AD%98%E5%82%A8%E4%BD%8D%E7%BD%AE/"},{"categories":["学习笔记"],"content":"概述 在代码中遇到了网络请求编程时，往往需要异步编程才能给用户带来良好的体验，不会导致程序完全阻塞。 其中的关键在于： 异步方法：再执行完成前就立刻返回调用方法，在调用方法执行过程中完成任务 async/await 结构主要分为三个部分： 调用方法：该方法调用异步方法，然后在异步方法回调后继续执行后续程序 异步方法：该方法异步执行程序，在被调用后立即返回到调用方法 await 表达式：用于异步等待，指出需要异步执行的任务，且需要等待其完成。一个方法可以包含多个await ","date":"2022-06-26","objectID":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/:1:0","tags":[".NET"],"title":"理解C#中async和await异步编程","uri":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"categories":["学习笔记"],"content":"什么是异步 启动程序时，系统会在内存中创建一个新的进程。进程是构成运行程序资源的集合。在进程内部，有称为线程的内核对象，它代表的是真正的执行程序。系统会在 Main 方法的第一行语句就开始线程的执行。 线程： 默认情况，一个进程只包含一个线程，从程序的开始到执行结束 线程可以派生自其它线程，所以一个进程可以包含不同状态的多个线程，来执行程序的不同部分 一个进程中的多个线程，将共享该进程的资源 系统为处理器执行所规划的单元是线程，而非进程 下面我们来看一个简单的例子 class Program { // 创建计时器 private static readonly Stopwatch Watch = new Stopwatch(); private static void Main(string[] args) { // 启动计时器 Watch.Start(); const string url1 = \"http://www.cnblogs.com/\"; const string url2 = \"http://www.cnblogs.com/liqingwen/\"; // 两次调用 CountCharactersAsync 方法（异步下载某网站内容，并统计字符的个数） Task\u003cint\u003e t1 = CountCharactersAsync(1, url1); Task\u003cint\u003e t2 = CountCharactersAsync(2, url2); // 三次调用 ExtraOperation 方法（主要是通过拼接字符串达到耗时操作） for (var i = 0; i \u003c 3; i++) { ExtraOperation(i + 1); } // 控制台输出 Console.WriteLine($\"{url1} 的字符个数：{t1.Result}\"); Console.WriteLine($\"{url2} 的字符个数：{t2.Result}\"); Console.Read(); } // 统计字符个数 private static async Task\u003cint\u003e CountCharactersAsync(int id, string address) { var wc = new WebClient(); Console.WriteLine($\"开始调用 id = {id}：{Watch.ElapsedMilliseconds} ms\"); var result = await wc.DownloadStringTaskAsync(address); Console.WriteLine($\"调用完成 id = {id}：{Watch.ElapsedMilliseconds} ms\"); return result.Length; } // 额外操作 private static void ExtraOperation(int id) { // 这里是通过拼接字符串进行一些相对耗时的操作，如果对字符串拼接有性能要求的话应该使用 StringBuilder var s = \"\"; for (var i = 0; i \u003c 6000; i++) { s += i; } Console.WriteLine($\"id = {id} 的 ExtraOperation 方法完成：{Watch.ElapsedMilliseconds} ms\"); } } 同步情况下的调用顺序为： 异步情况下的调用顺序为： 从上面两种情况可以看出异步编程优势，现在我们来分析一下程序的步骤： 从 Main 方法执行到 CountCharactersAsync(1, url1) 方法时，该方法会立即返回，然后才会调用它内部的方法开始下载内容。该方法返回的是一个 Task\u003cint\u003e 类型的占位符对象，表示计划进行的工作。这个占位符最终会返回 int 类型的值 这样就可以不必等 CountCharactersAsync(1, url1) 方法执行完成就可以继续进行下一步操作。到执行 CountCharactersAsync(2, url2) 方法时，跟 步骤① 一样返回 Task\u003cint\u003e 对象 然后，Main 方法继续执行三次 ExtraOperation 方法，同时两次 CountCharactersAsync 方法依然在持续工作 t1.Result 和 t2.Result 是指从 CountCharactersAsync 方法调用的 Task\u003cint\u003e 对象取结果，如果还没有结果的话，将阻塞，直有结果返回为止 ","date":"2022-06-26","objectID":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/:2:0","tags":[".NET"],"title":"理解C#中async和await异步编程","uri":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"categories":["学习笔记"],"content":"async/await 结构 async/await 结构主要分为三个部分： 调用方法：该方法调用异步方法，然后在异步方法回调后继续执行后续程序 异步方法：该方法异步执行程序，在被调用后立即返回到调用方法 await 表达式：用于异步等待，指出需要异步执行的任务，且需要等待其完成。一个方法可以包含多个await 示例结构分析如下： ","date":"2022-06-26","objectID":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/:3:0","tags":[".NET"],"title":"理解C#中async和await异步编程","uri":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"categories":["学习笔记"],"content":"await 都做了些什么 为了了解程序 await 时，C#都做了些什么工作，我们就必须了解以下内容 ","date":"2022-06-26","objectID":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/:4:0","tags":[".NET"],"title":"理解C#中async和await异步编程","uri":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"categories":["学习笔记"],"content":"方法的状态 首先，方法内所有的本地变量的值都会被记住，包括 方法的参数 在方法的作用域内定义的任何变量 任何其它变量，比如循环中使用到的计数变量 如果你的方法不是static的，则还要包括this变量。只有记住了this，当方法恢复执行(resume)时，才可以使用当前类的成员变量。 上述的这些都会被存储在.NET垃圾回收堆里的一个对象中。因此，当你使用await时，.NET就会创建这样一个对象，虽然它会占用一些资源，但在大多数情况下并不会导致性能问题。 C#还要记住在方法内部await执行到了哪里——可以通过使用一个数字来表示当前方法中执行到了哪一个await关键字。 具体如何使用await表达式？这其实没有限制，例如，await可以被用做一个大表达式的一部分，一个表达式也可能包含多个await. int myNum = await AlexsMethodAsync(await myTask, await StuffAsync()); 这样就对.NET运行时提出了额外的需求——当await一个表达式时，需要记住表达式剩余部分的状态。在上面的例子中，当程序执行await StuffAsync()时，await myTask的结果就需要被记录下来。.NET IL会将这类子表达式存储在栈上，因此当使用了await关键字时就需要把这个栈存储下来。 在这之上，当程序执行到第一个await时，当前方法会返回——除非方法是async void，否则这时就会返回一个Task，因此调用者可以通过某种方式等待任务完成。C# 还必须把操作该返回Task的方法存储下来，这样当我们的方法完成后，前面返回的Task才会变为完成的状态，这样程序才会向上返回一层，回到方法的异步链中去继续执行。我们会在第14章探讨这些额外的机制。 ","date":"2022-06-26","objectID":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/:4:1","tags":[".NET"],"title":"理解C#中async和await异步编程","uri":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"categories":["学习笔记"],"content":"上下文（Context） C#在使用await时会记录各种各样的上下文，目的是当要继续执行方法时能够恢复这个上下文，这样就尽可能地将await的处理过程变得透明。这些上下文中最重要的就是同步上下文（sychronization context），通过它的帮助可以在指定类型的线程上恢复方法的执行。 ","date":"2022-06-26","objectID":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/:4:2","tags":[".NET"],"title":"理解C#中async和await异步编程","uri":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"categories":["学习笔记"],"content":"异步方法的结构 关键字：方法头使用 async 修饰。 要求：包含 N（N\u003e0） 个 await 表达式（不存在 await 表达式的话 IDE 会发出警告），表示需要异步执行的任务。 返回类型：只能返回 3 种类型（void、Task 和 Task）。Task 和 Task 标识返回的对象会在将来完成工作，表示调用方法和异步方法可以继续执行。 参数：数量不限，但不能使用 out 和 ref 关键字。 命名约定：方法后缀名应以 Async 结尾。 其它：匿名方法和 Lambda 表达式也可以作为异步对象；async 是一个上下文关键字；关键字 async 必须在返回类型前。 本文参考自： https://www.cnblogs.com/tuyile006/p/12605523.html https://www.cnblogs.com/tuyile006/p/12605523.html ","date":"2022-06-26","objectID":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/:5:0","tags":[".NET"],"title":"理解C#中async和await异步编程","uri":"/%E7%90%86%E8%A7%A3csharp%E4%B8%ADasync%E5%92%8Cawait%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"},{"categories":["学习笔记"],"content":"什么是 Thread 当我们提及多线程的时候会想到 Thread 和 Threadpool，这都是异步操作，Threadpool 其实就是 Thread 的集合，具有很多优势，不过在任务多的时候全局队列会存在竞争而消耗资源。Thread 默认为前台线程，主程序必须等线程跑完才会关闭，而 Threadpool 相反。 总结：Threadpool 确实比 Thread 性能优，但是两者都没有很好的api区控制，如果线程执行无响应就只能等待结束，从而诞生了 Task 任务。 ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:1:0","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"什么是 Task Task 简单地看就是任务，那和 Thread 有什么区别呢？Task 的背后的实现也是使用了线程池线程，但它的性能优于ThreadPoll,因为它使用的不是线程池的全局队列，而是使用的本地队列，使线程之间的资源竞争减少。同时 Task 提供了丰富的API来管理线程、控制。但是相对前面的两种耗内存，Task 依赖于CPU对于多核的CPU性能远超前两者，单核的CPU三者的性能没什么差别。Task 有Wait、ContinueWith、Cancel等操作，有返回值。 ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:2:0","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"Task 与 Thread 的区别 Thread 类主要用于实现线程的创建以及执行。 Task 类表示以异步方式执行的单个操作。 ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:3:0","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"1. Task 是基于 Thread 的，是比较高层级的封装，Task 最终还是需要 Thread 来执行 ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:3:1","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"2. Task 默认使用后台线程执行，Thread 默认使用前台线程 public static void Main(string[] args) { Thread thread = new Thread(obj =\u003e { Thread.Sleep(3000); }); thread.Start(); } 上面代码，主程序在3秒后结束。 public static void Main(string[] args) { Task\u003cint\u003e task = new Task\u003cint\u003e(() =\u003e { Thread,Sleep(3000); return 1; }); task.Start(); } 而这段代码，会瞬间结束。 ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:3:2","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"3. Task 可以有返回值，Thread 没有返回值 虽然 Thread 可以通过 Start 方法参数来进行返回值处理，但十分不便。 public static void Main(string[] args) { Task task = new Task(LongRunningTask); task.Start(); Console.WriteLine(task.Result); } private static int LongRunningTask() { Thread.Sleep(3000); return 1; } ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:3:3","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"4. Task 可以执行后续操作，Thread 不能执行后续操作 static void Main(string[] args) { Task task = new Task(LongRunningTask); task.Start(); Task childTask = task.ContinueWith(SquareOfNumber); Console.WriteLine(\"Sqaure of number is :\"+ childTask.Result); Console.WriteLine(\"The number is :\" + task.Result); } private static int LongRunningTask() { Thread.Sleep(3000); return 2; } private static int SquareOfNumber(Task obj) { return obj.Result * obj.Result; } ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:3:4","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"5. Task 可取消任务执行，Thread 不行 static void Main(string[] args) { using (var cts = new CancellationTokenSource()) { Task task = new Task(() =\u003e { LongRunningTask(cts.Token); }); task.Start(); Console.WriteLine(\"Operation Performing...\"); if(Console.ReadKey().Key == ConsoleKey.C) { Console.WriteLine(\"Cancelling..\"); cts.Cancel(); } Console.Read(); } } private static void LongRunningTask(CancellationToken token) { for (int i = 0; i \u003c 10000000; i++) { if(token.IsCancellationRequested) { break; } else { Console.WriteLine(i); } } } ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:3:5","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"6. 异常传播 Thread 在父方法上获取不到异常，而 Task 可以 ","date":"2022-06-26","objectID":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/:3:6","tags":[".NET"],"title":"C#中Task与Thread区别","uri":"/csharp%E4%B8%ADtask%E4%B8%8Ethread%E5%8C%BA%E5%88%AB/"},{"categories":["实践笔记"],"content":"SignalR 简介 ASP.NET SignalR 是一个供 ASP.NET 开发人员使用的库，它简化了向应用程序添加实时 Web 功能的过程。实时 Web 功能是让服务器代码在内容可用时立即将内容推送到连接的客户端的能力，而不是让服务器等待客户端请求新数据。 官方网址 ","date":"2022-06-23","objectID":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/:1:0","tags":[".NET"],"title":"Vue中全局封装SignalR","uri":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/"},{"categories":["实践笔记"],"content":"实现步骤 ","date":"2022-06-23","objectID":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/:2:0","tags":[".NET"],"title":"Vue中全局封装SignalR","uri":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/"},{"categories":["实践笔记"],"content":"1. 引入SignalR官方库 npm install @microsoft/signalr ","date":"2022-06-23","objectID":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/:2:1","tags":[".NET"],"title":"Vue中全局封装SignalR","uri":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/"},{"categories":["实践笔记"],"content":"2. 创建一个signalR.js文件 const signalR = require(\"@microsoft/signalr\") export default { SR: {}, //初始化连接 initSR: function(domain) { let that = this; domain = domain === \"localhost\" ? \"内网IP\" : domain; let url = `http://${domain}:8000/chatHub`; that.SR = new signalR.HubConnectionBuilder() .withUrl(url) .configureLogging(signalR.LogLevel.Information) .build(); async function start() { try { await that.SR.start(); console.log(\"signaR连接成功\"); } catch (err) { console.log(\"err\", err); setTimeout(start, 5000); } } that.SR.onclose(async() =\u003e { await start(); }); start(); }, syncPage: function(func) { this.SR.on(\"ReceiveMessageFromGroup\", function(group, message) { func(); }); }, addToGroup: function(group) { this.SR.invoke(\"AddToGroup\", group).catch(function(err) { return console.error(err.toString()); }); }, removeFromGroup: function(group) { this.SR.off(\"ReceiveMessageFromGroup\") this.SR.invoke(\"RemoveFromGroup\", group).catch(function(err) { return console.error(err.toString()); }); }, // 停止连接 stopSR: function() { let that = this; async function stop() { try { await that.SR.stop(); console.log(\"signaR退出成功\"); } catch (err) {} } stop(); }, }; ","date":"2022-06-23","objectID":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/:2:2","tags":[".NET"],"title":"Vue中全局封装SignalR","uri":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/"},{"categories":["实践笔记"],"content":"3. 在main.js中引入并全局挂载 import signalr from \"signaR的路径\"; Vue.prototype.signalr = signalr; ","date":"2022-06-23","objectID":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/:2:3","tags":[".NET"],"title":"Vue中全局封装SignalR","uri":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/"},{"categories":["实践笔记"],"content":"4. 初始化连接 可在登录后进行初始化this.signalr.initSR(document.Domain); 由于页面刷新后，全局挂载的signalR会消失，所以需要在App.vue中再初始化一遍 mounted() {this.signalr.initSR(document.Domain);}, ","date":"2022-06-23","objectID":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/:2:4","tags":[".NET"],"title":"Vue中全局封装SignalR","uri":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/"},{"categories":["实践笔记"],"content":"5. 页面中使用 this.signalr.SR.on('方法', function (data) { // 接收后要做的事 console.log('方法', data) }) 特别提醒！！！ 当页面切换时，需要销毁注册的方法，不然会导致重复注册方法，会产生多次调用注册的方法，需要再离开页面时清空方法。 destroyed() { // 我使用的方法 this.signalr.SR.off(\"方法\") // 网上的方法，但是我使用无效 this.signalr.SR.methods.方法 = [] } 本文参考自： https://www.jianshu.com/p/5dc07c81f94d ","date":"2022-06-23","objectID":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/:2:5","tags":[".NET"],"title":"Vue中全局封装SignalR","uri":"/vue%E4%B8%AD%E5%85%A8%E5%B1%80%E5%B0%81%E8%A3%85signalr/"},{"categories":["实践笔记"],"content":"docker logs 是我们经常用来查看容器运行日志的命令，但是在长时间容器运行后，会产生大量的日志，会发现越来越慢，所以我们需要清理日志。 ","date":"2022-06-18","objectID":"/docker-%E6%B8%85%E7%90%86%E5%92%8C%E9%99%90%E5%88%B6%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%A4%A7%E5%B0%8F/:0:0","tags":["Docker"],"title":"Docker 清理和限制容器日志大小","uri":"/docker-%E6%B8%85%E7%90%86%E5%92%8C%E9%99%90%E5%88%B6%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%A4%A7%E5%B0%8F/"},{"categories":["实践笔记"],"content":"Docker 清理日志 通过命令 docker inspect --format='{{.LogPath}}' \u003c容器ID\u003e 查看容器的日志路径 通过命令 echo \u003e \u003c日志路径\u003e 或者 cat /dev/null \u003e \u003c日志路径\u003e 清空容器的日志 ","date":"2022-06-18","objectID":"/docker-%E6%B8%85%E7%90%86%E5%92%8C%E9%99%90%E5%88%B6%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%A4%A7%E5%B0%8F/:1:0","tags":["Docker"],"title":"Docker 清理和限制容器日志大小","uri":"/docker-%E6%B8%85%E7%90%86%E5%92%8C%E9%99%90%E5%88%B6%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%A4%A7%E5%B0%8F/"},{"categories":["实践笔记"],"content":"Docker 限制日志大小 新建或修改 /etc/docker/daemon.json 文件, 内容如下： { \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"500m\", // 日志文件最大大小 \"max-file\": \"3\" // 日志文件最大数量 } } 然后重启docker的守护线程 systemctl daemon-reload systemctl restart docker ","date":"2022-06-18","objectID":"/docker-%E6%B8%85%E7%90%86%E5%92%8C%E9%99%90%E5%88%B6%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%A4%A7%E5%B0%8F/:2:0","tags":["Docker"],"title":"Docker 清理和限制容器日志大小","uri":"/docker-%E6%B8%85%E7%90%86%E5%92%8C%E9%99%90%E5%88%B6%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%A4%A7%E5%B0%8F/"},{"categories":["学习笔记"],"content":"简介 使用正则表达式来处理搜索文本，能够提高灵活性。 通过使用正则表达式，可以做到： 测试字符串内的模式，例如，可以匹配字符串是否满足电话号码或信用卡号码的模式，进行数据验证 替换文本，使用正则表达式来识别文档中的特定文本，完全删除该文本或用其他文本替换它 基于模式匹配从字符串中提取子字符串，可以查找文档内或输入域内特定的文本 ","date":"2022-06-16","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/:1:0","tags":["正则表达式"],"title":"正则表达式总结","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"基本语法 ","date":"2022-06-16","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/:2:0","tags":["正则表达式"],"title":"正则表达式总结","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"修饰符 修饰符 含义 描述 i ignore - 不区分大小写 将匹配设置为不区分大小写，搜索时不区分大小写:A和a没有区别 g global - 全局匹配 查找所有的匹配项 m multi line - 多行匹配 使边界字符 ^ 和 $ 匹配每一行的开头和结尾，记住是多行，而不是整个字符串的开头和结尾 s 特殊字符圆点 . 中包含换行符 \\n 默认情况下的圆点 . 是匹配除换行符 \\n 之外的任何字符，加上 s 修饰符之后, . 中包含换行符 \\n ","date":"2022-06-16","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/:2:1","tags":["正则表达式"],"title":"正则表达式总结","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"元字符 普通字符 字符 描述 [ABC] 匹配 […] 中的所有字符 [^ABC] 匹配除了 […] 中字符的所有字符 [A-Z] [A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母 . 匹配除换行符（\\n、\\r）之外的任何单个字符，相等于 [^\\n\\r] [\\s\\S] 匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，不包括换行 \\w 匹配字母、数字、下划线。等价于 [A-Za-z0-9_] \\W 匹配非字母、数字、下划线。等价于 ‘[^A-Za-z0-9_]’ \\d 匹配一个数字字符。等价于 [0-9] \\D 匹配一个非数字字符。等价于 [^0-9] \\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，’\\x41’ 匹配 “A” \\num 匹配 num，其中 num 是一个正整数 非打印字符 字符 描述 \\cx 匹配由x指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符 \\f 匹配一个换页符 \\n 匹配一个换行符 \\r 匹配一个回车符 \\s 匹配任何空白字符，包括空格、制表符、换页符等等 \\S 匹配任何非空白字符 \\t 匹配一个制表符 \\v 匹配一个垂直制表符 特殊字符 字符 描述 $ 匹配输入字符串的结尾位置 () 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 . 匹配除换行符 \\n 之外的任何单字符 [ 标记一个中括号表达式的开始 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符(尽可能少的匹配所搜索的字符串) \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符 ^ 匹配输入字符串的开始位置；不接受该方括号表达式中的字符集合 { 标记限定符表达式的开始 | 指明两项之间的一个选择 限定符 字符 描述 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 ? 匹配前面的子表达式零次或一次 {n} n 是一个非负整数。匹配确定的 n 次 {n,} n 是一个非负整数。至少匹配n 次 {n,m} m 和 n 均为非负整数，其中n \u003c= m。最少匹配 n 次且最多匹配 m 次 定位符 字符 描述 ^ 匹配输入字符串开始的位置 $ 匹配输入字符串结尾的位置 \\b 匹配一个单词边界，即字与空格间的位置 \\B 非单词边界匹配 ?: ?= ?! ?\u003c= ?\u003e! 字符 描述 (?:pattern) 匹配 pattern 但不获取匹配结果 (?=pattern) 正向肯定预查 (?!pattern) 正向否定预查 (?\u003c=pattern) 反向肯定预查 (?\u003c!pattern) 反向否定预查 其他 字符 描述 \\d 匹配 pattern 但不获取匹配结果 \\D 正向肯定预查 (?!pattern) 正向否定预查 (?\u003c=pattern) 反向肯定预查 (?\u003c!pattern) 反向否定预查 ","date":"2022-06-16","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/:2:2","tags":["正则表达式"],"title":"正则表达式总结","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"运算符优先级 相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \\ 转义符 (), (?: ), (?=), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列 | 替换，“或\"操作 ","date":"2022-06-16","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/:2:3","tags":["正则表达式"],"title":"正则表达式总结","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/"},{"categories":["学习笔记"],"content":"示例 通过 /\\b[\\w.%+-]+@[\\w.-]+\\.[a-zA-Z]{2,6}\\b/g 匹配邮箱地址 ","date":"2022-06-16","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/:3:0","tags":["正则表达式"],"title":"正则表达式总结","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/"},{"categories":["实践笔记"],"content":"在使用docker时，常常需要对已启动的容器进行相应的配置修改，其中最常见的就是挂载目录或端口映射。其实配置也并不是非常复杂，可以通过修改docker中的json配置文件即可。 以下为详细修改步骤 ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:0:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"1. 先查看需要修改的容器的id号 首先通过 docker ps -a 查看 CONTAINER ID 再通过 docker inspect \u003ccontainer_id\u003e 查看 Id （一般在最开始的位置） ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:1:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"2. 关闭docker服务 在做相应配置前，一定要先停止docker服务，否则会修改不成功。 systemctl stop docker ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:2:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"3. 前往docker配置文件目录 通过以下命令即可进入到配置文件目录： cd /var/lib/docker/containers/\u003ccontainer_id\u003e ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:3:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"4. 修改hostconfig.json文件 通过 vim hostconfig.json 即可修改配置文件。 vim中可以通过 /字符串 快速定位字符串位置 修改以下内容配置端口映射 { ... \"PortBindings\": { \"80/tcp\": [ { \"HostIp\": \"\", \"HostPort\": \"8080\" } ] } ... } 修改以下内容配置挂载目录 { ... \"Binds\": [ \"/home/docker/www:/var/www\" ] ... // 其中 `/home/docker/www` 为宿主机目录，`/var/www` 为容器目录 } ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:4:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"4. 修改config.v2.json文件 通过 vim config.v2.json 即可修改配置文件。 修改以下内容配置端口映射 { ... \"ExposedPorts\": { \"80/tcp\": {}, } ... } 修改以下内容配置挂载目录 { ... \"MountPoints\": { \"/var/www\": { \"Source\": \"/home/docker/www\", \"Destination\": \"/var/www\", \"RW\": true, \"Name\": \"\", \"Driver\": \"\", \"Type\": \"bind\", \"Propagation\": \"rprivate\", \"Spec\": { \"Type\": \"bind\", \"Source\": \"/home/docker/www\", \"Target\": \"/var/www\", } \"SkipMountpointCreation\": false, } } ... // 其中 `/home/docker/www` 为宿主机目录，`/var/www` 为容器目录 } ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:5:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["实践笔记"],"content":"5. 重启docker服务 `systemctl start docker` ","date":"2022-06-14","objectID":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/:6:0","tags":["Docker"],"title":"docker为已启动容器添加挂载目录或端口映射","uri":"/docker%E4%B8%BA%E5%B7%B2%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%8C%82%E8%BD%BD%E7%9B%AE%E5%BD%95%E6%88%96%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"categories":["学习笔记"],"content":"索引 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:0:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"MySQL 索引 MySQL 的索引有两种分类方式：逻辑分类和物理分类 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"逻辑分类 主键索引：一张表只能有一个主键索引，不允许重复、不允许为 NULL 唯一索引：数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一 普通索引：一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插入 全文索引：它查找的是文本中的关键词，主要用于全文检索 单例索引：一个索引只包含一个列，一个表可以有多个单例索引 组合索引：一个组合索引包含两个或两个以上的列。查询的时候遵循 mysql 组合索引的 “最左前缀”原则，即使用 where 时条件要按照建立索引的时候字段的排列方式放置索引才会生效 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"物理分类 聚簇索引：不是单独的一种索引类型，而是一种数据存储方式。这种存储方式是依靠B+树来实现的，根据表的主键构造一棵B+树且B+树叶子节点存放的都是表的行记录数据时，方可称该主键索引为聚簇索引。聚簇索引也可理解为将数据存储与索引放到了一块，找到索引也就找到了数据。 非聚簇索引：数据和索引是分开的，B+树叶子节点存放的不是数据表的行记录 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"EXPLAIN 使用格式：EXPLAIN SQL...; 返回结果包含： id:选择标识符 select_type:表示查询的类型。 table:输出结果集的表 partitions:匹配的分区 type:表示表的连接类型 possible_keys:表示查询时，可能使用的索引 key:表示实际使用的索引 key_len:索引字段的长度 ref:列与索引的比较 rows:扫描出的行数(估算的行数) filtered:按表条件过滤的行百分比 Extra:执行情况的描述和说明 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:1:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"SQL Server 索引 唯一索引（UNIQUE）：唯一索引不允许两行具有相同的索引值 主键索引：为表定义一个主键将自动创建主键索引，主键索引是唯一索引的特殊类型。主键索引要求主键中的每个值是唯一的，并且不能为空 聚集索引(Clustered)：表中各行的物理顺序与键值的逻辑（索引）顺序相同，每个表最多只能有一个，设置某列为主键，该列就默认为聚集索引 非聚集索引(NonClustered)：非聚集索引指定表的逻辑顺序。数据存储在一个位置，索引存储在另一个位置，索引中包含指向数据存储位置的指针。可以有多个，小于249个 SQL 优化 总结SQL优化中，就三点: 最大化利用索引； 尽可能避免全表扫描； 减少无效数据的查询； ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:2:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"避免不走索引的场景 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫码 例如： SELECT * FROM user WHERE name LIKE '%李%' 优化方式：尽量在字段后面使用模糊查询，例如： SELECT * FROM user WHERE name LIKE '李%' 如果需要在前面使用模糊查询，可以使用以下方式： 使用MySQL内置函数INSTR(str, substr)，返回匹配子串的位置,类似Java中的str.indexOf(substr) 使用FullText全文索引，用match against检索 数据量较大的情况，使用ElasticSearch、solr，亿级数据量检索速度秒级 当数据量较少时（几千条），直接用LIKE '%李%' ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 尽量避免使用in和not in，会导致全表扫描 SELECT * FROM table WHERE id IN (2,3) 优化方式：如果是连续数值，可以使用between代替，例如: SELECT * FROM table WHERE id BETWEEN 2 AND 3 如果是子查询，可以使用EXISTS或NOT EXISTS代替，例如: SELECT * FROM table WHERE EXISTS (SELECT id FROM table2 WHERE table.id = table2.id) ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3. 尽量避免使用OR，会导致全表扫描 SELECT * FROM table WHERE id = 1 OR id = 2 优化方式：可以使用Union，例如: SELECT * FROM table WHERE id = 1 UNION SELECT * FROM table WHERE id = 2 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4. 尽量避免null值的判断 SELECT * FROM table WHERE id IS NULL 优化方式：可以给字段添加默认值，对默认值进行判断，例如： SELECT * FROM table WHERE id = 默认值 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"5. 尽量避免在where条件中等号左侧进行表达式、函数操作 可以将表达式、函数操作移动到等号右侧，例如： -- 全表扫码 SELECT * FROM table WHERE score/10 = 9 -- 走索引 SELECT * FROM table WHERE score = 10 * 9 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:5","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"6. 当数据量大时，避免使用where 1=1的条件 通常为了方便拼接查询条件，会使用它来作为条件 优化方式：用代码拼接sql时进行判断，没where条件就去掉where，有where条件就加and ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:6","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"7. 查询条件不能用\u003c\u003e或者!= 使用索引列作为条件进行查询时，需要避免使用\u003c\u003e或者!=等判断条件。如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:7","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"8. where条件仅包含复合索引非前置列 如下：复合（联合）索引包含key_part1，key_part2，key_part3三列，但SQL语句没有包含索引前置列\"key_part1\"，按照MySQL联合索引的最左匹配原则，不会走联合索引 select col1 from table where key_part2=1 and key_part3=2 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:8","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"9. 隐式类型转换造成不使用索引 如下SQL语句由于索引对列类型为varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引 select col1 from table where col_varchar=123; ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:9","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"10. order by 条件要与where中条件一致，否则order by不会利用索引进行排序 -- 不走age索引 SELECT * FROM t order by age; -- 走age索引 SELECT * FROM t where age \u003e 0 order by age; 当order by 中的字段出现在where条件中时，才会利用索引而不再二次排序，更准确的说，order by 中的字段在执行计划中利用了索引时，不用排序操作 这个结论不仅对order by有效，对其他需要排序的操作也有效。比如group by 、union 、distinct等 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:10","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"11. 正确使用hint优化语句 MySQL中可以使用hint指定优化器在执行时选择或忽略特定的索引。一般而言，处于版本变更带来的表结构索引变化，更建议避免使用hint，而是通过Analyze table多收集统计信息。但在特定场合下，指定hint可以排除其他索引干扰而指定更优的执行计划。 USE INDEX 在你查询语句中表名的后面，添加 USE INDEX 来提供希望 MySQL 去参考的索引列表，就可以让 MySQL 不再考虑其他可用的索引。例子: SELECT col1 FROM table USE INDEX (mod_time, name)… IGNORE INDEX 如果只是单纯的想让 MySQL 忽略一个或者多个索引，可以使用 IGNORE INDEX 作为 Hint。例子: SELECT col1 FROM table IGNORE INDEX (priority) … FORCE INDEX 为强制 MySQL 使用一个特定的索引，可在查询中使用FORCE INDEX 作为Hint。例子: SELECT col1 FROM table FORCE INDEX (mod_time) … 在查询的时候，数据库系统会自动分析查询语句，并选择一个最合适的索引。但是很多时候，数据库系统的查询优化器并不一定总是能使用最优索引。如果我们知道如何选择索引，可以使用FORCE INDEX强制查询使用指定的索引。 例如：SELECT * FROM students FORCE INDEX (idx_class_id) WHERE class_id = 1 ORDER BY id DESC; ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:3:11","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"SELECT语句其他优化 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 避免出现select * 首先，select * 操作在任何类型数据库中都不是一个好的SQL编写习惯。 使用select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的I/O,内存和CPU消耗。 建议提出业务实际需要的列数，将指定列名以取代select *。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 避免出现不确定结果的函数 特定针对主从复制这类业务场景。由于原理上从库复制的是主库执行的语句，使用如now()、rand()、sysdate()、current_user()等不确定结果的函数很容易导致主库与从库相应的数据不一致。另外不确定值的函数,产生的SQL语句无法利用query cache。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3.多表关联查询时，小表在前，大表在后。 在MySQL中，执行 from 后的表关联查询是从左往右执行的（Oracle相反），第一张表会涉及到全表扫描，所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前100行就符合返回条件并return了。 例如：表1有50条数据，表2有30亿条数据；如果全表扫描表2，你品，那就先去吃个饭再说吧是吧。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4. 使用表的别名 当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"5. 用where字句替换HAVING字句 避免使用HAVING字句，因为HAVING只会在检索出所有记录之后才对结果集进行过滤，而where则是在聚合前刷选记录，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在where字句中。 where和having的区别：where后面不能使用组函数 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:5","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"6.调整Where字句中的连接顺序 MySQL采用从左往右，自上而下的顺序解析where子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:4:6","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"增删改 DML 语句优化 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 大批量插入数据 如果同时执行大量的插入，建议使用多个值的INSERT语句(方法二)。这比使用分开INSERT语句快（方法一），一般情况下批量插入效率有几倍的差别。 方法一： insert into T values(1,2); insert into T values(1,3); insert into T values(1,4); 方法二： Insert into T values(1,2),(1,3),(1,4); 选择后一种方法的原因有三。 减少SQL语句解析的操作，MySQL没有类似Oracle的share pool，采用方法二，只需要解析一次就能进行数据的插入操作； 在特定场景可以减少对DB连接次数 SQL语句较短，可以减少网络传输的IO。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 适当使用commit 适当使用commit可以释放事务占用的资源而减少消耗，commit后能释放的资源如下： 事务占用的undo数据块； 事务在redo log中记录的数据块； 释放事务施加的，减少锁争用影响性能。特别是在需要使用delete删除大量数据的时候，必须分解删除量并定期commit。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3. 避免重复查询更新的数据 针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL并不支持PostgreSQL那样的UPDATE RETURNING语法，在MySQL中可以通过变量实现。 例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么，简单方法实现： Update t1 set time=now() where col1=1; Select time from t1 where id =1; 使用变量，可以重写为以下方式： Update t1 set time=now () where col1=1 and @now: = now (); Select @now; 前后二者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当t1表数据量较大时，后者比前者快很多。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4.查询优先还是更新（insert、update、delete）优先 MySQL 还允许改变语句调度的优先级，它可以使来自多个客户端的查询更好地协作，这样单个客户端就不会由于锁定而等待很长时间。改变优先级还可以确保特定类型的查询被处理得更快。我们首先应该确定应用的类型，判断应用是以查询为主还是以更新为主的，是确保查询效率还是确保更新的效率，决定是查询优先还是更新优先。下面我们提到的改变调度策略的方法主要是针对只存在表锁的存储引擎，比如 MyISAM 、MEMROY、MERGE，对于Innodb 存储引擎，语句的执行是由获得行锁的顺序决定的。MySQL 的默认的调度策略可用总结如下： 1）写入操作优先于读取操作。 2）对某张数据表的写入操作某一时刻只能发生一次，写入请求按照它们到达的次序来处理。 3）对某张数据表的多个读取操作可以同时地进行。MySQL 提供了几个语句调节符，允许你修改它的调度策略： LOW_PRIORITY关键字应用于DELETE、INSERT、LOAD DATA、REPLACE和UPDATE； HIGH_PRIORITY关键字应用于SELECT和INSERT语句； DELAYED关键字应用于INSERT和REPLACE语句。 如果写入操作是一个 LOW_PRIORITY（低优先级）请求，那么系统就不会认为它的优先级高于读取操作。在这种情况下，如果写入者在等待的时候，第二个读取者到达了，那么就允许第二个读取者插到写入者之前。只有在没有其它的读取者的时候，才允许写入者开始操作。这种调度修改可能存在 LOW_PRIORITY写入操作永远被阻塞的情况。 SELECT 查询的HIGH_PRIORITY（高优先级）关键字也类似。它允许SELECT 插入正在等待的写入操作之前，即使在正常情况下写入操作的优先级更高。另外一种影响是，高优先级的 SELECT 在正常的 SELECT 语句之前执行，因为这些语句会被写入操作阻塞。如果希望所有支持LOW_PRIORITY 选项的语句都默认地按照低优先级来处理，那么 请使用–low-priority-updates 选项来启动服务器。通过使用 INSERTHIGH_PRIORITY 来把 INSERT 语句提高到正常的写入优先级，可以消除该选项对单个INSERT语句的影响。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:5:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"查询条件优化 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"1. 对于复杂的查询，可以使用中间临时表暂存数据 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:1","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"2. 优化group by语句 默认情况下，MySQL 会对GROUP BY分组的所有值进行排序，如 “GROUP BY col1，col2，….;” 查询的方法如同在查询中指定 “ORDER BY col1，col2，…;” 如果显式包括一个包含相同的列的 ORDER BY子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。 因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL禁止排序。例如： SELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:2","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"3. 优化join语句 MySQL中可以通过子查询来使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接(JOIN)..替代。 例子：假设要将所有没有订单记录的用户取出来，可以用下面这个查询完成： SELECT col1 FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo ) 如果使用连接(JOIN).. 来完成这个查询工作，速度将会有所提升。尤其是当 salesinfo表中对 CustomerID 建有索引的话，性能将会更好，查询如下： SELECT col1 FROM customerinfo LEFT JOIN salesinfoON customerinfo.CustomerID=salesinfo.CustomerID WHERE salesinfo.CustomerID IS NULL ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:3","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"4. 优化union查询 MySQL通过创建并填充临时表的方式来执行union查询。除非确实要消除重复的行，否则建议使用union all。原因在于如果没有all这个关键词，MySQL会给临时表加上distinct选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高。 高效： SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION ALL SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= 'TEST'; 低效： SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= 'TEST'; ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:4","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"5. 拆分复杂SQL为多个小SQL，避免大事务 简单的SQL容易使用到MySQL的QUERY CACHE； 减少锁表时间特别是使用MyISAM存储引擎的表； 可以使用多核CPU。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:5","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"6. 使用truncate代替delete 当删除全表中记录时，使用delete语句的操作会被记录到undo块中，删除记录也记录binlog，当确认需要删除全表时，会产生很大量的binlog并占用大量的undo数据块，此时既没有很好的效率也占用了大量的资源。 使用truncate替代，不会记录可恢复的信息，数据不能被恢复。也因此使用truncate操作有其极少的资源占用与极快的时间。另外，使用truncate可以回收表的水位，使自增字段值归零。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:6","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"7. 使用合理的分页方式以提高分页效率 使用合理的分页方式以提高分页效率 针对展现等分页需求，合适的分页方式能够提高分页的效率。 案例1： select * from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15; 上述例子通过一次性根据过滤条件取出所有字段进行排序返回。数据访问开销=索引IO+索引全部记录结果对应的表数据IO。因此，该种写法越翻到后面执行效率越差，时间越长，尤其表数据量很大的时候。 适用场景：当中间结果集很小（10000行以下）或者查询条件复杂（指涉及多个不同查询字段或者多表连接）时适用。 案例2： select t.* from (select id from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15) a, t where a.id = t.id; 上述例子必须满足t表主键是id列，且有覆盖索引secondary key:(thread_id, deleted, gmt_create)。通过先根据过滤条件利用覆盖索引取出主键id进行排序，再进行join操作取出其他字段。数据访问开销=索引IO+索引分页后结果（例子中是15行）对应的表数据IO。因此，该写法每次翻页消耗的资源和时间都基本相同，就像翻第一页一样。 适用场景：当查询和排序字段（即where子句和order by子句涉及的字段）有对应覆盖索引时，且中间结果集很大的情况时适用。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:6:7","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["学习笔记"],"content":"建表优化 在表中建立索引，优先考虑where、order by使用到的字段 尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了 查询数据量大的表会造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段分页进行查询，循环遍历，将结果合并处理进行展示。要查询100000到100050的数据: SELECT * FROM (SELECT ROW_NUMBER() OVER(ORDER BY ID ASC) AS rowid,* FROM infoTab)t WHERE t.rowid \u003e 100000 AND t.rowid \u003c= 100050 用varchar/nvarchar 代替 char/nchar 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。 ","date":"2022-06-13","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/:7:0","tags":["数据库","SQL"],"title":"数据库优化","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"categories":["收藏分享"],"content":"简介 在大型企业中，服务器网络一般都会有各种各样的限制，常见的就会有堡垒机或者运维网关，以达到操作审计等目的。但对于开发者来讲，这些限制大大降低了效率，所以我们需要一个方便的方式来解决这个问题。 本篇文章主要通过为Linux增加SSH端口的方式来解决这个问题，通过增加SSH访问端口来绕开22端口的限制。 ","date":"2022-05-21","objectID":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/:1:0","tags":["Linux"],"title":"Linux增加SSH端口","uri":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/"},{"categories":["收藏分享"],"content":"实现 SSH配置文件 通过 vi /etc/ssh/sshd_config 来配置SSH端口，在Port 22后添加一行Port XX即可 配置SELinux 通过 semanage port -l | grep ssh 可以看到： ssh_port_t tcp 22 可以看到并没有我们添加的端口 可以执行semanage port -a -tssh_port_t -p tcp XX来添加 再次检查： ssh_port_t tcp XX, 22 重启SSH systemctl restart sshd.service 通过telnet可以验证 telnet IP地址 XX 通过以上操作后，就可以通过新开放的端口来实现对SHH服务的访问了 ","date":"2022-05-21","objectID":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/:2:0","tags":["Linux"],"title":"Linux增加SSH端口","uri":"/linux%E5%A2%9E%E5%8A%A0ssh%E7%AB%AF%E5%8F%A3/"},{"categories":["学习笔记"],"content":"Redis简介 Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis数据结构 String（字符串） string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。 string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。 string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。 127.0.0.1:6379\u003e set name Lesan OK 127.0.0.1:6379\u003e get name \"Lesan\" Hash（哈希） Redis hash 是一个键值(key=\u003evalue)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 127.0.0.1:6379\u003e hmset lesan field1 \"Hello\" field2 \"World\" OK 127.0.0.1:6379\u003e hget lesan field1 \"Hello\" 127.0.0.1:6379\u003e hget lesan field2 \"World\" List（列表） Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 127.0.0.1:6379\u003e del lesan (integer) 1 127.0.0.1:6379\u003e lpush lesan redis (integer) 1 127.0.0.1:6379\u003e lpush lesan mongodb (integer) 2 127.0.0.1:6379\u003e lpush lesan mysql (integer) 3 127.0.0.1:6379\u003e lrange lesan 0 10 1) \"mysql\" 2) \"mongodb\" 3) \"redis\" Set（集合） Redis 的 Set 是 string 类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 127.0.0.1:6379\u003e sadd lesan redis (integer) 1 127.0.0.1:6379\u003e sadd lesan redis (integer) 0 127.0.0.1:6379\u003e sadd lesan mongodb (integer) 1 127.0.0.1:6379\u003e sadd lesan mysql (integer) 1 127.0.0.1:6379\u003e smembers lesan 1) \"redis\" 2) \"mysql\" 3) \"mongodb\" zset（有序集合） Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 127.0.0.1:6379\u003e zadd lesan 0 redis (integer) 1 127.0.0.1:6379\u003e zadd lesan 0 mongodb (integer) 1 127.0.0.1:6379\u003e zadd lesan 0 mysql (integer) 1 127.0.0.1:6379\u003e zadd lesan 0 mysql (integer) 0 127.0.0.1:6379\u003e zrangebyscore lesan 0 100 1) \"mongodb\" 2) \"mysql\" 3) \"redis\" Stream Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。 而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:1","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis 命令 key Redis 键命令用于管理 redis 的键。 DEL KEY_NAME 用于删除已存在的键。不存在的 key 会被忽略 DUMP KEY_NAME 用于序列化给定 key ，并返回被序列化的值 EXISTS KEY_NAME 用于检查给定 key 是否存在 Expire KEY_NAME TIME_IN_SECONDS 用于设置 key 的过期时间，key 过期后将不再可用。单位以秒计 Expireat KEY_NAME TIME_IN_UNIX_TIMESTAMP 用于以 UNIX 时间戳(unix timestamp)格式设置 key 的过期时间。key 过期后将不再可用 PEXPIRE key milliseconds 以毫秒为单位设置 key 的生存时间 PEXPIREAT KEY_NAME TIME_IN_MILLISECONDS_IN_UNIX_TIMESTAMP 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计 KEYS PATTERN 用于查找所有符合给定模式 pattern 的 key MOVE KEY_NAME DESTINATION_DATABASE 用于将当前数据库的 key 移动到给定的数据库 db 当中 PERSIST KEY_NAME 用于移除给定 key 的过期时间，使得 key 永不过期 PTTL KEY_NAME 以毫秒为单位返回 key 的剩余过期时间 TTL KEY_NAME 以秒为单位返回 key 的剩余过期时间 RANDOMKEY 从当前数据库中随机返回一个 key RENAME OLD_KEY_NAME NEW_KEY_NAME 用于修改 key 的名称 RENAMENX OLD_KEY_NAME NEW_KEY_NAME 用于在新的 key 不存在时修改 key 的名称 SCAN cursor [MATCH pattern] [COUNT count] 用于迭代数据库中的数据库键 TYPE KEY_NAME 用于返回 key 所储存的值的类型 更多命令请参考菜鸟教程 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:2","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis 应用场景 缓存 作为Key-Value形态的内存数据库，Redis 最先会被想到的应用场景便是作为数据缓存。而使用 Redis 缓存数据非常简单，只需要通过string类型将序列化后的对象存起来即可，不过也有一些需要注意的地方： 必须保证不同对象的 key 不会重复，并且使 key 尽量短，一般使用类名（表名）加主键拼接而成。 选择一个优秀的序列化方式也很重要，目的是提高序列化的效率和减少内存占用。 缓存内容与数据库的一致性，这里一般有两种做法： 只在数据库查询后将对象放入缓存，如果对象发生了修改或删除操作，直接清除对应缓存（或设为过期）。 在数据库新增和查询后将对象放入缓存，修改后更新缓存，删除后清除对应缓存（或设为过期）。 数据共享分布式 String 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享 例如：分布式Session 分布式锁 在分布式环境下，单体锁已不在适用，Redis中string的set命令增加了一些参数： EX：设置键的过期时间（单位为秒） PX：设置键的过期时间（单位为毫秒） NX：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。 XX：只在键已经存在时，才对键进行设置操作。 由于这个操作是原子性的，可以简单地以此实现一个分布式的锁，例如： set lock_key locked NX EX 1 如果这个操作返回false，说明 key 的添加不成功，也就是当前有人在占用这把锁。而如果返回true，则说明得了锁，便可以继续进行操作，并且在操作后通过del命令释放掉锁。并且即使程序因为某些原因并没有释放锁，由于设置了过期时间，该锁也会在 1 秒后自动释放，不会影响到其他程序的运行。 推荐使用 redisson 第三方库实现分布式锁 全局ID int类型，incrby，利用原子性 incrby userid 1000 分库分表的场景，一次性拿一段 计数器 int类型，incr方法 例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库 计数功能应该是最适合 Redis 的使用场景之一了，因为它高频率读写的特征可以完全发挥 Redis 作为内存数据库的高效。在 Redis 的数据结构中，string、hash和sorted set都提供了incr方法用于原子性的自增操作，下面举例说明一下它们各自的使用场景： 如果应用需要显示每天的注册用户数，便可以使用string作为计数器，设定一个名为REGISTERED_COUNT_TODAY的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用incr命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。 每条微博都有点赞数、评论数、转发数和浏览数四条属性，这时用hash进行计数会更好，将该计数器的 key 设为weibo:weibo_id，hash的 field 为like_number、comment_number、forward_number和view_number，在对应操作后通过hincrby使hash 中的 field 自增。 如果应用有一个发帖排行榜的功能，便选择sorted set吧，将集合的 key 设为POST_RANK。当用户发帖后，使用zincrby将该用户 id 的 score 增长 1。sorted set会重新进行排序，用户所在排行榜的位置也就会得到实时的更新。 限流 int类型，incr方法 以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false 位统计 String类型的bitcount，字符是以8位二进制存储的 set k1 a setbit k1 6 1 setbit k1 7 0 get k1 其中6 7 代表的a的二进制位的修改 a-\u003e01100001 b-\u003e01100010 因为bit非常节省空间，可以用来做大数据量的统计 时间轴 list作为双向链表，不光可以作为队列使用。如果将它用作栈便可以成为一个公用的时间轴。当用户发完微博后，都通过lpush将它存放在一个 key 为LATEST_WEIBO的list中，之后便可以通过lrange取出当前最新的微博。 消息队列 Redis 中list的数据结构实现是双向链表，所以可以非常便捷的应用于消息队列（生产者 / 消费者模型）。消息的生产者只需要通过lpush将消息放入 list，消费者便可以通过rpop取出该消息，并且可以保证消息的有序性。如果需要实现带有优先级的消息队列也可以选择sorted set。而pub/sub功能也可以用作发布者 / 订阅者模型的消息。无论使用何种方式，由于 Redis 拥有持久化功能，也不需要担心由于服务器故障导致消息丢失的情况。 List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间 blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低 队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列 栈：先进后出：rpush brpop 抽奖 利用set结构的无序性,通过 Spop（ Redis Spop 命令用于移除集合中的指定 key 的一个或多个随机元素，移除后会返回移除的元素 ） 随机获得值 点赞、签到、打卡 假如微博ID是t1001，用户ID是u3001 用 like:t1001 来维护 t1001 这条微博的所有点赞用户 点赞了这条微博：sadd like:t1001 u3001 取消点赞：srem like:t1001 u3001 是否点赞：sismember like:t1001 u3001 点赞的所有用户：smembers like:t1001 点赞数：scard like:t1001 是不是比数据库简单多了。 好友关系、用户关注、推荐模型 这个场景最开始是是一篇介绍微博 Redis 应用的 PPT 中看到的，其中提到微博的 Redis 主要是用在在计数和好友关系两方面上，当时对好友关系方面的用法不太了解，后来看到《Redis 设计与实现》中介绍到作者最开始去使用 Redis 便是希望能通过set解决传统数据库无法快速计算集合中交集这个功能。后来联想到微博当前的业务场景，确实能够以这种方式实现，所以姑且猜测一下： 对于一个用户 A，将它的关注和粉丝的用户 id 都存放在两个 set 中： A:follow：存放 A 所有关注的用户 id A:follower：存放 A 所有粉丝的用户 id 那么通过sinter命令便可以根据A:follow和A:follower的交集得到与 A 互相关注的用户。当 A 进入另一个用户 B 的主页后，A:follow和B:follow的交集便是 A 和 B 的共同专注，A:follow和B:follower的交集便是 A 关注的人也关注了 B；通过sdiff命令便可得到差集，就可以得到用户间可能认识的人 排行榜 使用sorted set(有序set)和一个计算热度的算法便可以轻松打造一个热度排行榜，zrevrangebyscore可以得到以分数倒序排列的序列，zrank可以得到一个成员在该排行榜的位置（是分数正序排列时的位置，如果要获取倒序排列时的位置需要用zcard-zrank）。 id 为 6001 的新闻点击数加1：zincrby hotNews:20190926 1 n6001 获取今天点击最多的15条：zrevrange hotNews:20190926 0 15 withscores 更多应用案例可以查看本篇文章、或本篇文章 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Redis集群部署 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"主从复制 部署简单，分为一主一从，或一主N从。数据分布是在所有节点通过replication复制全量的数据。如果主节点挂掉，需要手动把其中的一个从节点设置为主节点 实践： 只需要在从库中执行slaveof ip port ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:1","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"哨兵模式 稍微比第一种复杂点，引入哨兵，此集群的原理还是主从复制。但是此集群中必须至少3个sentinel节点，来对一主两从的节点进行监控。因为sentinel里面存在一个Leader选举机制。必须是单数。此时sentinel(哨兵)其实就是一个Redis的特殊实例。此时的三个sentinel实例又组成了一个集群，两两互相监控，且这三个sentinel实例又分别都监控了所有的Redis节点。当一个主节点（Master）挂掉时，此集群方式会通过配置自动由对应的从节点（slave）变为主节点。如果一个主节点下有N个从节点，则进行选举机制来确定哪一个从节点变为主节点。此时所有节点的数据也都是全量的 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:2","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"分片模式 此集群是Redis从3.0版本开始支持，自带的一种集群方式。它的原理使用了分布的思想，其数据会均分到所有的主节点上。且有一个虚拟槽的概念。此部署方式，当数据量过大时，会让服务器均摊压力。在各个主节点上分配的数据都不是全量的。是分片存储的。目前此种部署方式在生产环境的较多 参考自： https://blog.csdn.net/u014659211/article/details/119805443 https://blog.csdn.net/qq_42815754/article/details/82912130 ","date":"2022-05-20","objectID":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:3","tags":["Redis"],"title":"Redis学习","uri":"/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"通过SpringCloud了解微服务 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:0:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"什么是微服务？ 微服务是一种开发软件的架构和组织方法，其中软件由通过明确定义的 API 进行通信的小型独立服务组成。 使用微服务架构，将应用程序构建为独立的组件，并将每个应用程序进程作为一项服务运行。这些服务使用轻量级 API 通过明确定义的接口进行通信。这些服务是围绕业务功能构建的，每项服务执行一项功能。由于它们是独立运行的，因此可以针对各项服务进行更新、部署和扩展，以满足对应用程序特定功能的需求。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"微服务的特性 自主性 可以对微服务架构中的每个组件服务进行开发、部署、运营和扩展，而不影响其他服务的功能。这些服务不需要与其他服务共享任何代码或实施。各个组件之间的任何通信都是通过明确定义的 API 进行的。 专用性 每项服务都是针对一组功能而设计的，并专注于解决特定的问题。如果开发人员逐渐将更多代码增加到一项服务中并且这项服务变得复杂，那么可以将其拆分成多项更小的服务。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:1","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"微服务的优势 敏捷性 微服务促进若干小型独立团队形成一个组织，这些团队负责自己的服务。各团队在小型且易于理解的环境中行事，并且可以更独立、更快速地工作。这缩短了开发周期时间。您可以从组织的总吞吐量中显著获益。 灵活扩展 通过微服务，您可以独立扩展各项服务以满足其支持的应用程序功能的需求。这使团队能够适当调整基础设施需求，准确衡量功能成本，并在服务需求激增时保持可用性。 轻松部署 微服务支持持续集成和持续交付，可以轻松尝试新想法，并可以在无法正常运行时回滚。由于故障成本较低，因此可以大胆试验，更轻松地更新代码，并缩短新功能的上市时间。 技术自由 微服务架构不遵循“一刀切”的方法。团队可以自由选择最佳工具来解决他们的具体问题。因此，构建微服务的团队可以为每项作业选择最佳工具。 可重复使用的代码 将软件划分为小型且明确定义的模块，让团队可以将功能用于多种目的。专为某项功能编写的服务可以用作另一项功能的构建块。这样应用程序就可以自行引导，因为开发人员可以创建新功能，而无需从头开始编写代码。 弹性 服务独立性增加了应用程序应对故障的弹性。在整体式架构中，如果一个组件出现故障，可能导致整个应用程序无法运行。通过微服务，应用程序可以通过降低功能而不导致整个应用程序崩溃来处理总体服务故障。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:2","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"SpringCloud框架 Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发， 如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来， 通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 它有以下优点： 把模块拆分，使用接口通信，降低模块之间的耦合度。 把项目拆分成若干个子项目，不同的团队负责不同的子项目。 增加功能时只需要再增加一个子项目，调用其他系统的接口就可以。 可以灵活的进行分布式部署。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"SpringCloud微服务模块分析 通过RuoYi-Cloud来接触微服务的项目 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:0","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"服务网关 API Gateway（APIGW / API 网关），顾名思义，是系统对外的唯一入口。API网关封装了系统内部架构，为每个客户端提供定制的API。 近几年来移动应用与企业间互联需求的兴起。从以前单一的Web应用，扩展到多种使用场景，且每种使用场景对后台服务的要求都不尽相同。 这不仅增加了后台服务的响应量，还增加了后台服务的复杂性。随着微服务架构概念的提出，API网关成为了微服务架构的一个标配组件。 路由（Route）：路由是网关最基础的部分，路由信息由 ID、目标 URI、一组断言和一组过滤器组成。如果断言 路由为真，则说明请求的 URI 和配置匹配。 断言（Predicate）：Java8 中的断言函数。Spring Cloud Gateway 中的断言函数输入类型是 Spring 5.0 框架中 的 ServerWebExchange。Spring Cloud Gateway 中的断言函数允许开发者去定义匹配来自于 Http Request 中的任 何信息，比如请求头和参数等。 过滤器（Filter）：一个标准的 Spring Web Filter。Spring Cloud Gateway 中的 Filter 分为两种类型，分别是 Gateway Filter 和 Global Filter。过滤器将会对请求和响应进行处理。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:1","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"认证中心 身份认证，就是判断一个用户是否为合法用户的处理过程。最常用的简单身份认证方式是系统通过核对用户输入的用户名和口令，看其是否与系统中存储的该用户的用户名和口令一致，来判断用户身份是否正确。 登录请求后台接口，为了安全认证，所有请求都携带token信息进行安全认证，比如使用vue、react后者h5开发的app，用于控制可访问系统的资源。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:2","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"注册中心 注册中心在微服务项目中扮演着非常重要的角色，是微服务架构中的纽带，类似于通讯录，它记录了服务和服务地址的映射关系。在分布式架构中，服务会注册到这里，当服务需要调用其它服务时，就到这里找到服务的地址，进行调用。 注册中心解决了服务发现的问题。在没有注册中心时候，服务间调用需要知道被调方的地址或者代理地址。当服务更换部署地址，就不得不修改调用当中指定的地址或者修改代理配置。而有了注册中心之后，每个服务在调用别人的时候只需要知道服务名称就好，继续地址都会通过注册中心同步过来。 RuoYi-Cloud使用的是Nacos ，阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:3","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"配置中心 在微服务架构中，当系统从一个单体应用，被拆分成分布式系统上一个个服务节点后，配置文件也必须跟着迁移（分割），这样配置就分散了，不仅如此，分散中还包含着冗余，总得来说，配置中心就是一种统一管理各种应用配置的基础服务组件。 Nacos是阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 配置中心的服务流程如下： 用户在配置中心更新配置信息。 服务A和服务B及时得到配置更新通知，从配置中心获取配置。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:4","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"服务调用 Feign Feign 是Spring Cloud Netflix组件中的一量级Restful的 HTTP 服务客户端，实现了负载均衡和 Rest 调用的开源框架，封装了Ribbon和RestTemplate, 实现了WebService的面向接口编程，进一步降低了项目的耦合度。 什么是服务调用 顾名思义，就是服务之间的接口互相调用，在微服务架构中很多功能都需要调用多个服务才能完成某一项功能。 ","date":"2022-05-11","objectID":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/:3:5","tags":["微服务","SpringCloud"],"title":"通过SpringCloud了解微服务","uri":"/%E9%80%9A%E8%BF%87springcloud%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["学习笔记"],"content":"简介 生产者消费者问题（Producer-consumer problem），也称有限缓冲问题（Bounded-buffer problem），是一个多线程同步问题的经典案例。生产者生成一定量的数据放到缓冲区中，然后重复此过程；与此同时，消费者也在缓冲区消耗这些数据。生产者和消费者之间必须保持同步，要保证生产者不会在缓冲区满时放入数据，消费者也不会在缓冲区空时消耗数据。不够完善的解决方法容易出现死锁的情况，此时进程都在等待唤醒。 下图为生产者和消费者的示意图： ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:1:0","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"解决思想 保证同一资源被多个线程并发访问时的完整性。常用的同步方法是采用信号或加锁机制，保证资源在任意时刻至多被一个线程访问 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:2:0","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"Java实现的几种方式 wait() / notify() 方法 await() / signal() 方法(可重入锁ReentrantLock) BlockingQueue 阻塞队列方法 信号量方法 管道方法 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:2:1","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"代码实现 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:0","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"wait() / notify() 方法 首先，先介绍一下Thread.sleep()和Object.wait()、Object.notify()的区别。 sleep()是Thread类的方法；而wait()，notify()，notifyAll()是Object类中定义的方法；尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的 Thread.sleep()不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep()不会让线程释放锁。如果能够帮助你记忆的话，可以简单认为和锁相关的方法都定义在Object类中，因此调用Thread.sleep()是不会影响锁的相关行为 Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间 Thread.sleep()让线程从 【running】 -\u003e 【阻塞态】 时间结束/interrupt -\u003e 【runnable】;Object.wait()让线程从 【running】 -\u003e 【等待队列】notify -\u003e 【锁池】 -\u003e 【runnable】 wait()和notify()方法的实现，缓冲区满和为空时都调用wait()方法等待，当生产者生产了一个数据或者消费者消费了一个数据之后会通过notify()唤醒所有线程。 import java.util.*; public class Test { // 缓冲区最大容量 private static final int MAX_SIZE = 100; // 计数 private static int count = 0; // 缓冲区 private static LinkedList\u003cInteger\u003e list = new LinkedList\u003cInteger\u003e(); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } // 生产者 public static class Producer implements Runnable { @Override public void run() { while (true) { // 为list上锁 synchronized (list) { // 缓冲区满时，等待 while (list.size() == MAX_SIZE) { try { System.out.println(\"list is full, Producer waiting\"); list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } // 生产数据 count++; System.out.println(\"Producer produce \" + count); list.add(count); // 唤醒消费者 list.notifyAll(); // 等待一段时间再生产 try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } } // 当生产100个数就结束 if (count == 100) { break; } } } } // 消费者 public static class Consumer implements Runnable { @Override public void run() { while (true) { // 为list上锁 synchronized (list) { // 缓冲区空时，等待 while (list.isEmpty()) { try { System.out.println(\"list is empty, Consumer waiting\"); list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } // 消费数据 int temp = list.poll(); System.out.println(\"Consumer consume \" + temp); // 唤醒生产者 list.notifyAll(); } // 当消费100个数就结束 if (count == 100 \u0026\u0026 list.isEmpty()) { break; } } } } } 执行结果如下： 注意： notifyAll()方法可使所有正在等待队列中等待同一共享资源的“全部”线程从等待状态退出，进入可运行状态。此时，优先级最高的那个线程最先执行，但也有可能是随机执行的，这要取决于JVM虚拟机的实现。即最终也只有一个线程能被运行，上述线程优先级都相同，每次运行的线程都不确定是哪个，后来给线程设置优先级后也跟预期不一样，还是要看JVM的具体实现吧。 ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:1","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"await() / signal() 方法(可重入锁ReentrantLock) 在JDK5.0之后，Java提供了更加健壮的线程处理机制，包括同步、锁定、线程池等，它们可以实现更细粒度的线程控制。用ReentrantLock和Condition可以实现等待/通知模型，具有更大的灵活性。通过在Lock对象上调用newCondition()方法，将条件变量和一个锁对象进行绑定，进而控制并发程序访问竞争资源的安全。 Condition接口的await()和signal()就是其中用来做同步的两种方法，它们的功能基本上和Object的wait()/ nofity()相同，完全可以取代它们，但是它们和新引入的锁定机制Lock直接挂钩，具有更大的灵活性。通过在Lock对象上调用newCondition()方法，将条件变量和一个锁对象进行绑定，进而控制并发程序访问竞争资源的安全。 import java.util.*; import java.util.concurrent.locks.*; public class Test1 { private static final int MAX_SIZE = 100; private static int count = 0; private static LinkedList\u003cInteger\u003e list = new LinkedList\u003cInteger\u003e(); // 创建锁及其条件 private static final Lock lock = new ReentrantLock(); private static final Condition fullCondition = lock.newCondition(); private static final Condition emptyCondition = lock.newCondition(); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { while (true) { // 上锁 lock.lock(); try { // 缓冲区满时，等待 while (list.size() == MAX_SIZE) { try { System.out.println(\"list is full, Producer waiting\"); fullCondition.await(); } catch (InterruptedException e) { e.printStackTrace(); } } // 生产数据 count++; System.out.println(\"Producer produce \" + count); list.add(count); // 唤醒消费者 emptyCondition.signalAll(); } finally { lock.unlock(); } try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100) { break; } } } } public static class Consumer implements Runnable { @Override public void run() { while (true) { // 上锁 lock.lock(); try { // 缓冲区空时，等待 while (list.isEmpty()) { try { System.out.println(\"list is empty, Consumer waiting\"); emptyCondition.await(); } catch (InterruptedException e) { e.printStackTrace(); } } // 消费数据 int temp = list.poll(); System.out.println(\"Consumer consume \" + temp); // 唤醒生产者 fullCondition.signalAll(); } finally { lock.unlock(); } if (count == 100 \u0026\u0026 list.isEmpty()) { break; } } } } } 运行结果如下：（与第一种方法类似） ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:2","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"BlockingQueue 阻塞队列方法 JDK 1.5 以后新增的 java.util.concurrent包新增了 BlockingQueue 接口。并提供了如下几种阻塞队列实现： java.util.concurrent.ArrayBlockingQueue java.util.concurrent.LinkedBlockingQueue java.util.concurrent.SynchronousQueue java.util.concurrent.PriorityBlockingQueue 实现生产者-消费者模型使用 ArrayBlockingQueue或者 LinkedBlockingQueue即可。 我们这里使用LinkedBlockingQueue，它是一个已经在内部实现了同步的队列，实现方式采用的是我们第2种await()/ signal()方法。它可以在生成对象时指定容量大小。它用于阻塞操作的是put()和take()方法。 put()方法：类似于我们上面的生产者线程，容量达到最大时，自动阻塞。 take()方法：类似于我们上面的消费者线程，容量为0时，自动阻塞。 import java.util.*; import java.util.concurrent.LinkedBlockingQueue; public class Test2 { private static final int MAX_SIZE = 100; private static int count = 0; // 创建阻塞队列 private static LinkedBlockingQueue\u003cInteger\u003e blockingQueue = new LinkedBlockingQueue\u003cInteger\u003e(MAX_SIZE); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { while (true) { try { count++; // 生产数据到阻塞队列 blockingQueue.put(count); System.out.println(\"Producer produce \" + count); } catch (InterruptedException e) { e.printStackTrace(); } try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100) { break; } } } } public static class Consumer implements Runnable { @Override public void run() { while (true) { try { // 从阻塞队列消费数据 int value = blockingQueue.take(); System.out.println(\"Consumer consume \" + value); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100 \u0026\u0026 blockingQueue.isEmpty()) { break; } } } } } ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:3","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"信号量方法 Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源，在操作系统中是一个非常重要的问题，可以用来解决哲学家就餐问题。Java中的Semaphore维护了一个许可集，一开始先设定这个许可集的数量，可以使用acquire()方法获得一个许可，当许可不足时会被阻塞，release()添加一个许可。 Semaphore可以用来构建一些对象池，资源池之类的，比如数据库连接池，我们也可以创建计数为1的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。 在下列代码中，还加入了另外一个mutex信号量，维护生产者消费者之间的同步关系，保证生产者和消费者之间的交替进行 import java.util.*; import java.util.concurrent.Semaphore; public class Test3 { private static final int MAX_SIZE = 100; private static int count = 0; private static LinkedList\u003cInteger\u003e list = new LinkedList\u003cInteger\u003e(); // 创建信号量 final static Semaphore notFull = new Semaphore(MAX_SIZE); final static Semaphore notEmpty = new Semaphore(0); final static Semaphore mutex = new Semaphore(1); public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { while (true) { try { // 获取许可 notFull.acquire(); mutex.acquire(); // 生产数据 count++; list.add(count); System.out.println(\"Producer produce \" + count); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 释放许可 mutex.release(); notEmpty.release(); } try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } if (count == 100) { break; } } } } public static class Consumer implements Runnable { @Override public void run() { while (true) { try { // 获取许可 notEmpty.acquire(); mutex.acquire(); // 消费数据 int value = list.poll(); System.out.println(\"Consumer consume \" + value); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 释放许可 mutex.release(); notFull.release(); } if (count == 100 \u0026\u0026 list.isEmpty()) { break; } } } } } ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:4","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"管道方法 在java的io包下，PipedOutputStream和PipedInputStream分别是管道输出流和管道输入流。 它们的作用是让多线程可以通过管道进行线程间的通讯。在使用管道通信时，必须将PipedOutputStream和PipedInputStream配套使用。 使用方法：先创建一个管道输入流和管道输出流，然后将输入流和输出流进行连接，用生产者线程往管道输出流中写入数据，消费者在管道输入流中读取数据，这样就可以实现了不同线程间的相互通讯。 但是这种方式在生产者和生产者、消费者和消费者之间不能保证同步，也就是说在一个生产者和一个消费者的情况下是可以生产者和消费者之间交替运行的，多个生成者和多个消费者者之间则不行。 这种方式只适用于两个线程之间通信，不适合多个线程之间通信。 import java.io.IOException; import java.io.PipedInputStream; import java.io.PipedOutputStream; import java.util.*; public class Test4 { // 控制生产和消费个100次 private static int countP = 0; private static int countS = 0; // 创建管道输入流和管道输出流 final static PipedInputStream pis = new PipedInputStream(); final static PipedOutputStream pos = new PipedOutputStream(); // 将输入流和输出流进行连接 static { try { pis.connect(pos); } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { Thread producer = new Thread(new Producer()); Thread consumer = new Thread(new Consumer()); producer.start(); consumer.start(); } public static class Producer implements Runnable { @Override public void run() { try { while (true) { // 写入数据 countP++; pos.write(countP); pos.flush(); System.out.println(\"Producer produce \" + countP); Thread.sleep(new Random().nextInt(1000)); if (countP == 100) { break; } } } catch (Exception e) { e.printStackTrace(); } finally { try { // 关闭输出流 pos.close(); } catch (IOException e) { e.printStackTrace(); } } } } public static class Consumer implements Runnable { @Override public void run() { try { while (true) { // 读取数据 countS++; int value = pis.read(); System.out.println(\"Consumer consume \" + value); if (countS == 100) { break; } } } catch (IOException e) { e.printStackTrace(); } finally { try { // 关闭输入流 pis.close(); } catch (IOException e) { e.printStackTrace(); } } } } } ","date":"2022-05-08","objectID":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/:3:5","tags":["多线程"],"title":"生产者与消费者问题","uri":"/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/"},{"categories":["学习笔记"],"content":"在进行华为机试时遇到了报数游戏的编程题（约瑟夫环），但是看了很多网上的解题都非常长，于是经过不断的学习参考，有了下面这个解题方法，也不知道是不是最好的😭 题目： 100个人围成一圈，每个人有一个编码，编号从1开始到100.他们从1开始依次报数，报到为M的人自动退出圈圈，然后下一个人接着从1开始报数，直到剩余的人数小于M。请问最后剩余的人在原先的编号为多少？ 例如：输入M=3时，输出为：“58，91”；输入M=4时，输出为： “34，45， 97” 解答： import java.util.*; public class test { public static void main(String[] args) { Scanner in = new Scanner(System.in); int n = in.nextInt(); List list = new ArrayList\u003cInteger\u003e(100); for (int i = 1; i \u003c= 100; i++) { list.add(i); } int i = 0; while (list.size() \u003e= n) { i = (i + n - 1) % list.size(); list.remove(i); } list.stream().forEach(System.out::println); } } ","date":"2022-04-17","objectID":"/%E5%8D%8E%E4%B8%BA%E6%9C%BA%E8%AF%95%E9%A2%98-%E6%8A%A5%E6%95%B0%E6%B8%B8%E6%88%8F/:0:0","tags":["面试"],"title":"华为机试题：报数游戏","uri":"/%E5%8D%8E%E4%B8%BA%E6%9C%BA%E8%AF%95%E9%A2%98-%E6%8A%A5%E6%95%B0%E6%B8%B8%E6%88%8F/"},{"categories":["学习笔记"],"content":"本篇笔记主要记录我在学习Java的stream流中记录的笔记 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:0:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"stream是什么 流是从支持数据处理操作的源生成的元素序列，源可以是数组、文件、集合、函数。流不是集合元素，它不是数据结构并不保存数据，它的主要目的在于计算 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:1:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"生成stream的方法 生成流的方式主要有五种 通过集合生成，应用中最常用的一种 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5, 6); Stream\u003cInteger\u003e stream = integerList.stream(); 通过数组生成 int[] intArr = {1, 2, 3, 4, 5, 6}; IntStream stream = Arrays.stream(intArr); 通过Arrays.stream方法生成流，并且该方法生成的流是数值流【即IntStream】而不是 Stream。补充一点使用数值流可以避免计算过程中拆箱装箱，提高性能。Stream API提供了mapToInt、mapToDouble、mapToLong三种方式将对象流【即Stream 】转换成对应的数值流，同时提供了boxed方法将数值流转换为对象流 通过值生成 // 通过Stream的of方法生成流，通过Stream的empty方法可以生成一个空流 Stream\u003cInteger\u003e stream = Stream.of(1, 2, 3, 4, 5, 6); 通过文件生成 // 通过Files.line方法得到一个流，并且得到的每个流是给定文件中的一行 Stream\u003cString\u003e lines = Files.lines(Paths.get(\"data.txt\"), Charset.defaultCharset()); 通过函数生成 // 1.iterator // terate方法接受两个参数，第一个为初始化值，第二个为进行的函数操作，因为iterator生成的流为无限流，通过limit方法对流进行了截断，只生成5个偶数 Stream\u003cInteger\u003e stream = Stream.iterate(0, n -\u003e n + 2).limit(5); // 2.generator // generate方法接受一个参数，方法参数类型为Supplier ，由它为流提供值。generate生成的流也是无限流，因此通过limit对流进行了截断 Stream\u003cDouble\u003e stream = Stream.generate(Math::random).limit(5); ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:2:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"stream的操作类型 中间操作 一个流可以后面跟随零个或多个中间操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的，仅仅调用到这类方法，并没有真正开始流的遍历，真正的遍历需等到终端操作时，常见的中间操作有下面即将介绍的 filter、map 等。 终端操作 一个流有且只能有一个终端操作，当这个操作执行后，流就被关闭了，无法再被操作，因此一个流只能被遍历一次，若想在遍历需要通过源数据在生成流。终端操作的执行，才会真正开始流的遍历。如下面即将介绍的 count、collect 等。 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:3:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"stream的使用 ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:4:0","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"中间操作 filter 筛选 // 通过使用filter方法进行条件筛选，filter的方法参数为一个条件（过滤保留函数返回值为 true 的元素） List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5, 6); Stream\u003cInteger\u003e stream = integerList.stream().filter(i -\u003e i \u003e 3); // 结果为：4,5,6 distinct 去重 // 通过distinct方法快速去除重复的元素 List\u003cInteger\u003e integerList = Arrays.asList(1, 1, 2, 3, 4, 5); Stream\u003cInteger\u003e stream = integerList.stream().distinct(); // 结果为：1,2,3,4,5 limit 返回指定流个数 // 通过limit方法指定返回流的个数，limit的参数值必须 \u003e=0，否则将会抛出异常。 List\u003cInteger\u003e integerList = Arrays.asList(1, 1, 2, 3, 4, 5); Stream\u003cInteger\u003e stream = integerList.stream().limit(3); 结果为： 1,1,2 skip 跳过流中的元素 // 通过skip方法跳过流中的元素，skip的参数值必须\u003e=0，否则将会抛出异常 List\u003cInteger\u003e integerList = Arrays.asList(1, 1, 2, 3, 4, 5); Stream\u003cInteger\u003e stream = integerList.stream().skip(2); // 结果为： 2,3,4,5 map 流映射 // 所谓流映射就是将接受的元素映射成另外一个元素 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); List\u003cInteger\u003e collect = stringList.stream() .map(String::length) .collect(Collectors.toList()); // 通过map方法可以完成映射，该例子完成中 String -\u003e Integer 的映射 // 结果为：[6, 7, 2, 6] flatMap 流转换 // 将一个流中的每个值都转换为另一个流 List\u003cString\u003e wordList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); List\u003cString\u003e strList = wordList.stream() .map(w -\u003e w.split(\" \")) .flatMap(Arrays::stream) .distinct() .collect(Collectors.toList()); // map(w -\u003e w.split(\" \")) 的返回值为 Stream\u003cString[]\u003e，想获取 Stream，可以通过flatMap方法完成 Stream -\u003eStream 的转换 // 结果为：[Java, 8, Lambdas, In, Action] allMatch 匹配所有元素 // 匹配流中所有元素是否满足条件 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); if (integerList.stream().allMatch(i -\u003e i \u003e 3)) { System.out.println(\"所有元素值都大于3\"); } else { System.out.println(\"并非所有元素值都大于3\"); } // 结果为：并非所有元素值都大于3 anyMatch匹配其中一个 // 匹配流中是否存在一个满足条件的元素 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); if (integerList.stream().anyMatch(i -\u003e i \u003e 3)) { System.out.println(\"存在值大于3的元素\"); } else { System.out.println(\"不存在值大于3的元素\"); } // 结果为：存在值大于3的元素 // 上述代码等同于： for (Integer i : integerList) { if (i \u003e 3) { System.out.println(\"存在大于3的值\"); break; } } noneMatch全部不匹配 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); if (integerList.stream().noneMatch(i -\u003e i \u003e 3)) { System.out.println(\"值都小于3的元素\"); } else { System.out.println(\"值不都小于3的元素\"); } ","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:4:1","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"终端操作 count 统计流中元素个数 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); Long result = integerList.stream().count(); // 结果为：5 findFirst 查找第一个 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); Optional\u003cInteger\u003e result = integerList.stream().filter(i -\u003e i \u003e 3).findFirst(); System.out.println(result.orElse(-1)); // 结果为：4 findAny 随机查找一个 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); Optional\u003cInteger\u003e result = integerList.stream().filter(i -\u003e i \u003e 3).findAny(); System.out.println(result.orElse(-1)); // 结果为：4 // 通过findAny方法查找到其中一个大于三的元素并打印，因为内部进行优化的原因，当找到第一个满足大于三的元素时就结束，该方法结果和findFirst方法结果一样。提供findAny方法是为了更好的利用并行流，findFirst方法在并行上限制更多【本篇文章将不介绍并行流】 reduce 将流中的元素组合 用于求和 List\u003cInteger\u003e integerList = Arrays.asList(1, 2, 3, 4, 5); int sum = integerList.stream() .reduce(0, Integer::sum); // 结果为：15 // reduce接受两个参数，一个初始值这里是0，一个 BinaryOperatoraccumulator 来将两个元素结合起来产生一个新值，另外reduce方法还有一个没有初始化值的重载方法 用于取得最大和最小值 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); Optional\u003cInteger\u003e min = stringList.stream() .map(String::length) .reduce(Integer::min); Optional\u003cInteger\u003e max = stringList.stream() .map(String::length) .reduce(Integer::max); // 结果为：Optional[2] 和 Optional[7] min/max 获取最小最大值 // 写法1 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); Optional\u003cInteger\u003e min = stringList.stream() .map(String::length) .min(Integer::compareTo); Optional\u003cInteger\u003e max = stringList.stream() .map(String::length) .max(Integer::compareTo); // 写法2 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); OptionalInt min = stringList.stream() .mapToInt(String::length) .min(); OptionalInt max = stringList.stream() .mapToInt(String::length) .max(); // 使用reduce List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); Optional\u003cInteger\u003e min = stringList.stream() .map(String::length) .reduce(Integer::min); Optional\u003cInteger\u003e max = stringList.stream() .map(String::length) .reduce(Integer::max); sum / summingxxx / reduce 求和 // 方式1：sum List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); int sum = stringList.stream() .mapToInt(String::length) .sum(); // 方式2：summingInt List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); // 如果数据类型为double、long，则通过summingDouble、summingLong方法进行求和 int sum = stringList.stream() .collect(summingInt(String::length)); // 方式3：reduce List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); int sum = stringList.stream() .map(String::length) .reduce(0, Integer::sum); 在上面求和、求最大值、最小值的时候，对于相同操作有不同的方法可以选择执行。可以选择collect、reduce、min/max/sum方法，推荐使用min、max、sum方法。因为它最简洁易读，同时通过mapToInt将对象流转换为数值流，避免了装箱和拆箱操作 averagingxxx 求平均值 // averagingxxx List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); double average = stringList.stream() .collect(averagingInt(String::length)); summarizingxxx 同时求总和、平均值、最大值、最小值 // 如果数据类型为double、long，则通过summarizingDouble、summarizingLong方法 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); IntSummaryStatistics intSummaryStatistics = stringList.stream() .collect(summarizingInt(String::length)); double average = intSummaryStatistics.getAverage(); // 获取平均值 int min = intSummaryStatistics.getMin(); // 获取最小值 int max = intSummaryStatistics.getMax(); // 获取最大值 long sum = intSummaryStatistics.getSum(); // 获取总和 foreach 遍历 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); stringList.stream().forEach(System.out::println); collect 返回集合 List\u003cString\u003e stringList = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\"); List\u003cInteger\u003e intList = stringList.stream() .map(String::length) .collect(toList()); Set\u003cInteger\u003e intSet = stringList.stream() .map(String::length) .collect(toSet()); // 等价 List\u003cInteger\u003e intList = new ArrayList\u003c\u003e(); Set\u003cInteger\u003e intSet = new HashSet\u003c\u003e(); for (String item : stringList) { intList.add(item.length()); intSet.add(item.length()); } 通过遍历和返回集合的使用发现流只是把原来的外部迭代放到了内部进行，这也是流的主要特点之一。内部迭代可以减","date":"2022-04-17","objectID":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/:4:2","tags":["Java"],"title":"Java Stream流学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0stream%E6%B5%81%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"SQL 行转列，列转行 行列转换在做报表分析时还是经常会遇到的，今天就说一下如何实现行列转换吧。 行列转换就是如下图所示两种展示形式的互相转换 ","date":"2022-04-03","objectID":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/:0:0","tags":["SQL"],"title":"数据库Tip:行转列、列转行","uri":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/"},{"categories":["学习笔记"],"content":"行转列 假如我们有下表： 使用PIVOT实现 SELECT * FROM student PIVOT ( SUM(score) FOR subject IN (语文, 数学, 英语) ) 通过上面 SQL 语句即可得到下面的结果 PIVOT 后跟一个聚合函数来拿到结果，FOR 后面跟的科目是我们要转换的列，这样的话科目中的语文、数学、英语就就被转换为列。IN 后面跟的就是具体的科目值。 分组后使用case进行条件判断处理 当然我们也可以用 CASE WHEN 得到同样的结果，就是写起来麻烦一点。 SELECT name, MAX( CASE WHEN subject='语文' THEN score ELSE 0 END) AS \"语文\", MAX( CASE WHEN subject='数学' THEN score ELSE 0 END) AS \"数学\", MAX( CASE WHEN subject='英语' THEN score ELSE 0 END) AS \"英语\" FROM student GROUP BY name 使用 CASE WHEN 可以得到和 PIVOT 同样的结果，没有 PIVOT 简单直观。 ","date":"2022-04-03","objectID":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/:1:0","tags":["SQL"],"title":"数据库Tip:行转列、列转行","uri":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/"},{"categories":["学习笔记"],"content":"列转行 假设我们有下表 student1 使用UNPIVOT实现 SELECT * FROM student1 UNPIVOT ( score FOR subject IN (\"语文\",\"数学\",\"英语\") ) 通过 UNPIVOT 即可得到如下结果： 分组后使用case进行条件判断处理 我们也可以使用下面方法得到同样结果 SELECT NAME, '语文' AS subject , MAX(\"语文\") AS score FROM student1 GROUP BY NAME UNION SELECT NAME, '数学' AS subject , MAX(\"数学\") AS score FROM student1 GROUP BY NAME UNION SELECT NAME, '英语' AS subject , MAX(\"英语\") AS score FROM student1 GROUP BY NAME UNION \u0026 UNION ALL UNION 操作符用于合并两个或多个 SELECT 语句的结果集。 请注意，UNION 内部的 SELECT 语句必须拥有相同数量的列。列也必须拥有相似的数据类型。同时，每条 SELECT 语句中的列的顺序必须相同。 SQL UNION 语法 SELECT column_name(s) FROM table_name1 UNION SELECT column_name(s) FROM table_name2 **注释：**默认地，UNION 操作符选取不同的值。如果允许重复的值，请使用 UNION ALL。 SQL UNION ALL 语法 SELECT column_name(s) FROM table_name1 UNION ALL SELECT column_name(s) FROM table_name2 另外，UNION 结果集中的列名总是等于 UNION 中第一个 SELECT 语句中的列名。 ","date":"2022-04-03","objectID":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/:2:0","tags":["SQL"],"title":"数据库Tip:行转列、列转行","uri":"/%E8%A1%8C%E8%BD%AC%E5%88%97%E5%88%97%E8%BD%AC%E8%A1%8C/"},{"categories":["收藏分享"],"content":"Yapi简介 Yapi 由 YMFE 开源，旨在为开发、产品、测试人员提供更优雅的接口管理服务，可以帮助开发者轻松创建、发布、维护 API 权限管理 YApi 成熟的团队管理扁平化项目权限配置满足各类企业的需求 可视化接口管理 基于 websocket 的多人协作接口编辑功能和类 postman 测试工具，让多人协作成倍提升开发效率 Mock Server 易用的 Mock Server，再也不用担心 mock 数据的生成了 自动化测试 完善的接口自动化测试,保证数据的正确性 数据导入 支持导入 swagger, postman, har 数据格式，方便迁移旧项目 插件机制 强大的插件机制，满足各类业务需求 ","date":"2022-04-03","objectID":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/:1:0","tags":["收藏分享"],"title":"分享一个可以私有部署的接口管理系统Yapi","uri":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/"},{"categories":["收藏分享"],"content":"Yapi使用Docker安装 由于内网开发环境，导致安装各种环境或者系统非常不方便，所以个人比较推荐通过docker来安装 拉取镜像 docker pull registry.cn-hangzhou.aliyuncs.com/anoy/yapi 创建挂载目录 mkdir -p /data/yapi/mongodata 运行专用mongo（也可以放在已有的mongo） docker run -d --name yapimongo --restart always -v /data/yapi/mongodata:/data/db mongo 初始化 Yapi 数据库索引及管理员账号 docker run -it --rm --link yapimongo:mongo --entrypoint npm --workdir /api/vendors registry.cn-hangzhou.aliyuncs.com/anoy/yapi run install-server --rm：在 Docker 容器退出时，默认容器内部的文件系统仍然被保留，以方便调试并保留用户数据。但是，对于 foreground 容器，由于其只是在开发调试过程中短期运行，其用户数据并无保留的必要，因而可以在容器启动时设置 –rm 选项，这样在容器退出时就能够自动清理容器内部的文件系统 --entrypoint：类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。但是, 如果运行 docker run 时使用了 –entrypoint 选项，将覆盖 ENTRYPOINT 指令指定的程序 --workdir：指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在 run：用于执行后面跟着的命令行命令 创建Yapi容器并启动 docker run -d --name yapi --restart=always --link yapimongo:mongo --workdir /api/vendors -p 3001:3000 registry.cn-hangzhou.aliyuncs.com/anoy/yapi server/app.js --link：用于容器直接的互通 使用Yapi 访问 http://localhost:3000 登录账号admin@admin.com，密码ymfe.org Yapi配置 # 进入Yapi容器中 docker exec -it yapi /bin/bash # 修改配置文件 vi ../config.json # 修改内容如下 { \"port\": \"3000\", \"adminAccount\": \"admin@admin.com\", \"closeRegister\":true, # 配置禁用注册，主要是添加这句配置 \"db\": { # 配置MongoDB \"servername\": \"mongo\", \"DATABASE\": \"yapi\", \"port\": 27017 } } # 退出 exit # 重启容器 docker restart yapi 本文参考至： docker安装yapi 具体使用可参考官方教程 ","date":"2022-04-03","objectID":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/:2:0","tags":["收藏分享"],"title":"分享一个可以私有部署的接口管理系统Yapi","uri":"/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%A7%81%E6%9C%89%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8E%A5%E5%8F%A3%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Fyapi/"},{"categories":["实践笔记"],"content":"本篇文章记录本人搭建CI\u0026CD实现持续集成和持续部署 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:0:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"1.使用docker安装gitlab ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"下载镜像 （使用中文社区版） docker pull twang2218/gitlab-ce-zh ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:1","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"创建所需目录为后续挂载文件 进入所需目录后，打开PowerShell，通过以下命令进行目录创建 mkdir -p gitlab/etc 、 mkdir -p gitlab/etc 、 mkdir -p gitlab/etc 目录结构如下图所示 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:2","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"启动容器 镜像下载完成后可通过docker images查看下载结果，再通过镜像启动为容器 docker run -d -p 9443:443 -p 9080:80 -p 9022:22 --restart always --name testgitlab -v D:\\testgitlab\\gitlab\\etc:/etc/gitlab -v D:\\testgitlab\\gitlab\\log:/var/log/gitlab -v D:\\testgitlab\\gitlab\\data:/var/opt/gitlab --privileged=true twang2218/gitlab-ce-zh # 执行完成后会返回一串字符串 其中： -d：后台执行 -p：端口映射 --restart：重启机制 --name：容器名称 -v：挂载文件，使得容器内文件在宿主机内有映射 --privileged：使得容器获取宿主机root权限 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:3","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"进入容器，修改配置 输入命令 docker exec -it testgitlab bash 即可进入刚刚创建好的容器 修改gitlab.rb配置的两种方式：1. 进入挂载好的etc目录下找到gitlab.rb文件进行修改；2. 通过进入容器内进行命令行vi /etc/gitlab/gitlab.rb 修改 # 整个gitlab.rb都是注释了的，我们可以按需加入我们的配置 # 1. gitlab访问地址，可以写域名。如果端口不写的话默认为80端口 eaxternal_url 'http://192.168.3.12:9080' # 2. ssh主机ip gitlab_rails['gitlab_ssh_host'] = '192.168.3.12' # 3. ssh连接端口 gitlab_rails['gitlab_shell_ssh_port'] = 9022 # 4. 防止内存占用过大，限制线程数 unicorn['worker_processes'] = 2 修改gitlab.yml配置（这一步原本不是必须的，因为gitlab.rb内配置会覆盖这个，为了防止没有成功覆盖所以我在这里进行配置，当然你也可以选择不修改gitlab.rb直接修改这里） 通过命令行vi /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml修改，或者找到挂载文件修改 修改上图红框配置 让修改后的配置生效，并重启 gitlab-ctl reconfigure 、 gitlab-ctl restart 、 exit（退出容器命令行） 或者重启容器docker restart testgitlab ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:4","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"访问gitlab 输入http://192.168.3.12:9080打开页面（ip请输入前面设置的），默认账户root，密码需要重新设置至少8位 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:1:5","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"2.使用docker安装jenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"下载镜像 docker pull jenkins/jenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:1","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"创建所需目录为后续挂载文件 在服务器上先创建一个jenkins工作目录 /var/jenkins_mount，赋予相应权限，稍后我们将jenkins容器目录挂载到这个目录上，这样我们就可以很方便地对容器内的配置文件进行修改。如何后续在容器内修改的话会非常麻烦，由于容器中无vi命令。 mkdir -p /var/jenkins_mount 、 chmod 777 /var/jenkins_mount ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:2","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"启动容器 docker run -d -p 10240:8080 -p 10241:50000 -v D:\\testjenkins\\jenkins_mount:/var/jenkins_home -v /etc/localtime:/etc/localtime --name testjenkins jenkins/jenkins # 其中-v /etc/localtime:/etc/localtime让容器使用和服务器同样的时间设置 可以通过docker ps来查看启动情况 可以通过docker logs testjenkins来查看容器日志 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:3","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"修改配置 进入刚刚挂载的文件，修改hudson.model.UpdateCenter.xml文件 将 url 修改为 清华大学官方镜像：https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json ，配置镜像加速 还需要修改default.json文件，位置为cd /var/jenkins_home/updates 使用sed命令修改default.json linux下： sed -i 's/http:\\/\\/updates.jenkins-ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' default.json \u0026\u0026 sed -i 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' default.json mac下： sed -i \"\" 's/http:\\/\\/updates.jenkins-ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' default.json \u0026\u0026 sed -i \"\" 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' default.json 重启容器 docker restart testjenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:4","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"访问jenkins 输入http://localhost:10240打开页面 选择默认插件安装即可 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:2:5","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"3.gitlab + jenkins 为了实现自动持续构建, 不需要人工操作 ( 留人工操作用于处理特殊情况 )，通过gitlab+jenkins实现CI\u0026CD，具体流程如下 开发提交代码 开发对需要发布的版本打上 Tag 触发 GitLab 的 tag push 事件, 调用 Webhook Webhook 触发 Jenkins 的构建任务 Jenkins 构建完项目可以按版本号上传到仓库、部署、通知相关人员等等 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:0","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"配置gitlab 建一个测试项目 test ，随便 commit 一些内容，比如通过网页添加README.md 创建账号的 access token ，用于 Jenkins 调用 GitLab 的 API 记下生成的 access token , 后面需要用到！！！且它只会展示一次，请记录好！！！ ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:1","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"配置jenkins 安装环境所需插件 Git Parameter ( 用于参数化构建中动态获取项目分支 ) Generic Webhook Trigger ( 用于解析 Webhook 传过来的参数 ) GitLab ( 用于推送构建结果给 GitLab ) 添加 GitLab 凭据 在系统配置中配置gitlab 创建新的FreeStyle任务 General 勾选 参数化构建过程, 添加 Git Parameter 类型的参数 ref , 这样构建的时候就可以指定分支进行构建 源码管理 选择 Git , 添加项目地址和授权方式 ( 帐号密码 或者 ssh key ) , 分支填写构建参数 $ref 构建触发器 选择 Generic Webhook Trigger 方式用于解析 GitLab 推过来的详细参数 ( jsonpath 在线测试 ) 。其他触发方式中: Trigger builds remotely 是 Jenkins 自带的, Build when a change is pushed to GitLab 是 GitLab 插件 提供的, 都属于简单的触发构建, 无法做复杂的处理 Optional filter 虽然 Generic Webhook Trigger 提供了 Token 参数进行鉴权, 但为了避免不同项目进行混调 ( 比如 A 项目提交代码却触发了 B 项目的构建) , 还要对请求做下过滤。Optional filter 中 Text 填写需要校验的内容 ( 可使用变量 ) , Expression 使用正则表达式对 Text 进行匹配, 匹配成功才允许触发构建 构建 构建内容按自己实际的项目类型进行调整, 使用 Maven 插件 或 脚本 等等 构建后操作 构建后操作添加 Publish build status to GitLab 动作, 实现构建结束后通知构建结果给 GitLab 在GitLab的项目页面中, 添加一个Webhook 添加一个 Webhook ( http://JENKINS_URL/generic-webhook-trigger/invoke?token=\u003c上面 Jenkins 项目配置中的 token\u003e ) , 触发器选择 标签推送事件。因为日常开发中 push 操作比较频繁而且不是每个版本都需要构建, 所以只针对需要构建的版本打上 Tag 就好了 http://172.20.10.7:10240//generic-webhook-trigger/invoke?token=d63ad84eb18cb04d4459ec347a196dce 创建完使用 test 按钮 先测试下, 可能会出现下面的错误 Requests to the local network are not allowed 通过下面方法解决 ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:2","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"测试效果 将代码拉下来在本地操作通过IDEA进行操作 然后使用快捷键 Cmd + Shift + K 调出 Push 窗口 , 把 Tag 推送到 GitLab 中 回到 GitLab 页面可以看到触发了 Webhook , View details 查看请求详情, Response body 中 triggered 字段值为 true 则表示成功触发了 Jenkins 进行构建 注意: 每添加一个 Tag 就会触发一次事件, 不管是不是一起 push 的。所以一次 push 多个 Tag 会触发 Jenkins 进行多次构建。不过 Jenkins 已经做了处理, 默认串行执行任务 ( 一个任务结束再执行下一个 ) , 而且在构建前有一个 pending 状态, 此时被多次触发会进行合并, 并取首次触发的参数, 如下图所示: ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:3","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"关于 Tag 的几点说明 推送 Tag 到远端的时候, 远端已存在 ( 同名 ) 的 Tag 不会被添加到远端 拉取远端的 Tag 时, 本地已存在 ( 同名 ) 的 Tag 不会添加到本地 拉取远端的 Tag 时, 本地不会删除远端已删除的 Tag , 需要同步远端的 Tag 可以先删除本地所有 Tag 再 pull 删除 Tag 也会推送事件, 要做好过滤 ( 上面配置中已使用 commitsId 字段进行过滤 ) 本篇文章产考下列文章： docker安装gitlab docker安装jenkins docker中jenkins插件加速 整合gitlab+jenkins ","date":"2022-04-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/:3:4","tags":["Docker","gitlab","jenkins"],"title":"记一次搭建gitlab+jenkins实现CI\u0026CD","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BAgitlab-jenkins%E5%AE%9E%E7%8E%B0cicd/"},{"categories":["实践笔记"],"content":"Docker 简介 Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker 的应用场景： Web 应用的自动化打包和发布。 自动化测试和持续集成、发布。 在服务型环境中部署和调整数据库或其他的后台应用。 从头编译或者扩展现有的 OpenShift 或 Cloud Foundry 平台来搭建自己的 PaaS 环境。 Docker 的优点： Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 快速，一致地交付您的应用程序 响应式部署和扩展 在同一硬件上运行更多工作负载 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:1:0","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"Docker 命令 详细命令可以查看Docker 命令大全 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:0","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"常用镜像命令 1. 查看服务器中 Docker 镜像列表 docker images 2. 搜索镜像 docker search 镜像名 3. 拉取镜像（不加tag(版本号)就默认拉取Docker仓库中该镜像的最新版本latest; 加:tag则是拉取指定版本） docker pull 镜像名 docker pull 镜像名:v1 4. 运行镜像 docker run -itd --name=\"nginx\" --restart=always -p 80:80 -v /data:/data nginx:latest 5. 删除镜像 docker rmi -f 镜像名/镜像ID 6. 保存镜像 docker save nginx -o /nginx.tar 7. 加载镜像 docker load -i 镜像文件位置 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:1","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"常用容器命令 1. 查看正在运行容器列表 docker ps 2. 查看所有容器 docker ps -a 3. 停止容器 docker stop 容器名/容器ID 4. 删除容器 docker rm -f 容器名/容器ID 5. 进入容器方式 docker exec -it 容器名/容器ID /bin/bash exit/ctl+p+q #退出 6. 重启容器 docker restart 容器名/容器ID 7. 启动容器 docker start 容器名/容器ID 8. kill 容器 docker kill 容器名/容器ID 9. 容器文件拷贝 docker cp 容器名/ID:容器内路径 容器外路径 #容器内拷出 docker cp 容器外路径 容器名/ID:容器内路径 #容器外拷入 10. 查看容器日志 docker logs -f --tail=100 容器 #tail查看末尾多少行 默认all 11. 修改存在容器的启动配置 docker update --restart=always 容器 12. 更换容器名 docker rename 容器 容器新名字 13. 通过容器提交镜像！！！### docker commit -a=\"提交作者\" -m=\"提交信息\" 容器 提交镜像:tag ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:2","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"Docker 运维命令 1. 查看Docker工作目录 sudo docker info | grep \"Docker Root Dir\" 2. 查看Docker磁盘占用总体情况 du -hs /var/lib/docker/ 3. 查看Docker的磁盘使用具体情况 docker system df 4. 删除无用的容器和镜像 docker rm `docker ps -a | grep Exited | awk '{print $1}'` docker rmi -f `docker images | grep '\u003cnone\u003e' | awk '{print $3}'` 5. 清除所有无容器使用的镜像 docker system prune -a 6. 查找大文件 find / -type f -size +100M -print0 | xargs -0 du -h | sort -nr 7. 查找指定Docker使用目录下大于指定大小文件 find / -type f -size +100M -print0 | xargs -0 du -h | sort -nr | grep '/var/lib/docker/overlap2/*' ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:2:3","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"构建一个带libgdiplus的DotNetCore基础镜像 通过Docker拉取一个.netcore3.1基础镜像：docker pull mcr.microsoft.com/dotnet/aspnet:3.1 进入容器：docker run -it mcr.microsoft.com/dotnet/aspnet:3.1 /bin/bash 安装libgdiplus： apt-get update -y apt-get install -y libgdiplus apt-get clean ln -s /usr/lib/libgdiplus.so /usr/lib/gdiplus.dll 提交为新镜像：docker commit -a=\"Lesan\" -m=\"added libgdiplus based on .netcore3.1\" 28a66ebccd55 dotnetcore-with-libgdiplus:v3.1 修改项目Dockerfile基础镜像为刚刚构建的自定义镜像dotnetcore-with-libgdiplus:v3.1 借鉴参考以下文章： https://blog.csdn.net/leilei1366615/article/details/106267225 https://www.runoob.com/docker/docker-command-manual.html https://blog.csdn.net/u014374975/article/details/115436174 ","date":"2022-03-27","objectID":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/:3:0","tags":["Docker",".NET","Linux"],"title":"构建一个带libgdiplus的DotNetCore基础Docker镜像","uri":"/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6libgdiplus%E7%9A%84dotnetcore%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/"},{"categories":["实践笔记"],"content":"本笔记为Docker与Kubernetes的实践笔记 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:0:0","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"将.NET Core的项目发布为Docker镜像 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:0","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"通过VS支持创建Docker镜像 第一步，创建一个空的.NET Core项目，用来测试 第二步，为项目添加Docker支持 添加成功后会在项目根目录创建Dockerfile，以及在Docker Desktop中创建对应的image及container，如下图所示 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:1","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"通过已发布的文件包创建Docker镜像 第一步，将项目发布到文件夹 第二步，去到发布的文件夹下，添加Dockerfile来构建镜像 FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base # 配置工作目录 WORKDIR /app # 暴露容器端口 EXPOSE 80 EXPOSE 443 # 设置时区 ENV TZ = Asia/shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026\u0026 $TZ \u003e /etc/timezone #执行命令 # 复制文件到工作目录 COPY . . #指定执行程序 ENTRYPOINT [\"dotnet\", \"DockerAndK8s.dll\"] 第三步，通过Docker命令进行构建镜像 第五步，启动镜像 最后，在浏览器中访问可以发现成功部署 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:2","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"将镜像发布到Docker Hub 通过命令行进行 F:\\Visual Studio\\repos\\DockerAndK8s\\output\u003edocker tag dockerandk8s:v1 lesan0u0/dockerandk8s:v1 F:\\Visual Studio\\repos\\DockerAndK8s\\output\u003edocker push lesan0u0/dockerandk8s:v1 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:1:3","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["实践笔记"],"content":"添加Kubernetes支持 Kubernetes的安装与使用通过本篇文章 ASP.NET Core on K8S学习初探（1）K8S单节点环境搭建 第一步，打开控制面板 kubectl create -f kubernetes-dashboard.yaml // 部署Kubernetes dashboard kubectl get pod -n kubernetes-dashboard // 检查 kubernetes-dashboard 应用状态 kubectl proxy // 开启 API Server 访问代理 //dashboard地址 http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ // 控制台访问令牌 $TOKEN=((kubectl -n kube-system describe secret default | Select-String \"token:\") -split \" +\")[1] kubectl config set-credentials docker-desktop --token=\"${TOKEN}\" echo $TOKEN 第二步，准备Department YAML apiVersion: apps/v1 kind: Deployment metadata: name: dockerandk8s namespace: test labels: name: dockerandk8s spec: replicas: 2 selector: matchLabels: name: dockerandk8s template: metadata: labels: name: dockerandk8s spec: containers: - name: dockerandk8s image: lesan0u0/dockerandk8s:v1 ports: - containerPort: 80 imagePullPolicy: Always --- kind: Service apiVersion: v1 metadata: name: dockerandk8s namespace: test spec: type: NodePort ports: - port: 80 targetPort: 80 selector: name: dockerandk8s 第三步，通过kubectl部署到K8S kubectl create -f deploy.yaml //部署 kubectl get svc -n aspnetcore //验证 可以通过Dashboard来查看部署情况 最后，大功告成 ","date":"2022-03-27","objectID":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/:2:0","tags":["Docker","K8S",".NET"],"title":"学习使用Docker与Kubernetes","uri":"/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8docker%E4%B8%8Ekubernetes/"},{"categories":["学习笔记"],"content":"简介 Java集合框架为程序员提供了预先包装的数据结构和算法来操纵他们。这使得我们使用复杂的数据结构变得非常的方便，并且这些集合框架是高性能的，基本集合（动态数组，链表，树，哈希表）的实现也必须是高效的；允许不同类型的集合，以类似的方式工作，具有高度的互操作性。 从上面的集合框架图可以看到，Java 集合框架主要包括两种类型的容器，一种是集合（Collection），存储一个元素集合，另一种是图（Map），存储键/值对映射。Collection 接口又有 3 种子类型，List、Set 和 Queue，再下面是一些抽象类，最后是具体实现类，常用的有 ArrayList、LinkedList、HashSet、LinkedHashSet、HashMap、LinkedHashMap 等等。 集合框架是一个用来代表和操纵集合的统一架构。所有的集合框架都包含如下内容： 接口：是代表集合的抽象数据类型。例如 Collection、List、Set、Map 等。之所以定义多个接口，是为了以不同的方式操作集合对象 实现（类）：是集合接口的具体实现。从本质上讲，它们是可重复使用的数据结构，例如：ArrayList、LinkedList、HashSet、HashMap。 算法：是实现集合接口的对象里的方法执行的一些有用的计算，例如：搜索和排序。这些算法被称为多态，那是因为相同的方法可以在相似的接口上有着不同的实现。 除了集合，该框架也定义了几个 Map 接口和类。Map 里存储的是键/值对。尽管 Map 不是集合，但是它们完全整合在集合中。 Java 集合框架提供了一套性能优良，使用方便的接口和类，java集合框架位于java.util包中， 所以当使用集合框架的时候需要进行导包。 下面我们就分别详细介绍集合框架中的每个数据结构！ ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:1:0","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"List接口 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:0","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"简介 List集合代表一个有序、可重复集合，集合中每个元素都有其对应的顺序索引。List集合默认按照元素的添加顺序设置元素的索引，可以通过索引（类似数组的下标）来访问指定位置的集合元素。 实现List接口的集合主要有：ArrayList、LinkedList、Vector、Stack。 List:元素是有序的(怎么存的就怎么取出来，顺序不会乱)，元素可以重复（角标1上有个3，角标2上也可以有个3）因为该集合体系有索引 ArrayList：底层的数据结构使用的是数组结构（数组长度是可变的百分之五十延长）（特点是查询很快，但增删较慢）线程不同步 LinkedList：底层的数据结构是链表结构（特点是查询较慢，增删较快） 线程不同步 Vector：底层是数组数据结构 线程同步（数组长度是可变的百分之百延长）（无论查询还是增删都很慢，被ArrayList替代了） List排序通用方法 Collections.sort(list, new Comparator() { public int compare(Student s1, Student s2) { //先按成绩 降序 排序，如果成绩一样的话按id 升序 排序 if(s1.getScore()\u003es2.getScore()){ //greater return -1; }else if(s1.getScore()==s2.getScore()){ //equals if(s1.getId()\u003es2.getId()){ return 1; }else if(s1.getId()==s2.getId()){ return 0; }else{ return -1; } }else{ //less return 1; }　} }); List通用方法 List list = new ArrayList(); // 向列表的尾部追加指定的元素 list.add(\"lwc\"); // 在列表的指定位置插入指定元素 list.add(1, \"nxj\"); // 追加指定 collection 中的所有元素到此列表的结尾 list.addAll(new ArrayList()); // 从列表中移除所有元素 list.clear(); // 如果列表包含指定的元素,则返回true list.contains(\"nxj\"); // 如果列表包含指定 collection 的所有元素,则返回 true list.containsAll(new ArrayList()); // 比较指定的对象与列表是否相等 list.equals(new ArrayList()); // 返回列表中指定位置的元素 list.get(0); // 返回列表的哈希码值 list.hashCode(); // 返回列表中首次出现指定元素的索引,如果列表不包含此元素,则返回 -1 list.indexOf(\"lwc\"); // 返回列表中最后出现指定元素的索引,如果列表不包含此元素,则返回 -1 list.lastIndexOf(\"lwc\"); // 如果列表不包含元素,则返回 true list.isEmpty(); // 移除列表中指定位置的元素 list.remove(0); // 移除列表中出现的首个指定元素 list.remove(\"lwc\"); // 从列表中移除指定 collection 中包含的所有元素 list.removeAll(new ArrayList()); // 用指定元素替换列表中指定位置的元素 list.set(0, \"lp\"); // 返回列表中的元素数 list.size(); // 返回列表中指定的fromIndex(包括)和toIndex(不包括)之间的部分视图 list.subList(1, 2); // 返回以正确顺序包含列表中的所有元素的数组 list.toArray(); // 返回以正确顺序包含列表中所有元素的数组 list.toArray(new String[] { \"a\", \"b\" }); List通用遍历 // 迭代方式 // 第一种for-size循环 for (int i = 0; i \u003c sites.size(); i++) { System.out.println(sites.get(i)); } // 第二种for-each循环 for (String i : sites) { System.out.println(i); } // 第三种Iterator循环 for(Iterator\u003cString\u003e it = sites.iterator(); it.hasNext();){ String value=it.next(); } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:1","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"ArrayList类 ArrayList是一个动态数组，也是我们最常用的集合，是List类的典型实现。它允许任何符合规则的元素插入甚至包括null。每一个ArrayList都有一个初始容量（10），该容量代表了数组的大小。随着容器中的元素不断增加，容器的大小也会随着增加。在每次向容器中增加元素的同时都会进行容量检查，当快溢出时，就会进行扩容操作。所以如果我们明确所插入元素的多少，最好指定一个初始容量值，避免过多的进行扩容操作而浪费时间、效率。 示例： import java.util.ArrayList; public class Test { public static void main(String[] args) { ArrayList\u003cString\u003e sites = new ArrayList\u003cString\u003e(); // 创建ArrayList sites.add(\"Google\"); // 添加元素 sites.add(\"Runoob\"); sites.add(\"Taobao\"); sites.add(\"Weibo\"); sites.set(2, \"Wiki\"); // 修改元素 sites.remove(3); // 删除元素，下标为3的元素，就是第四个元素 System.out.println(sites.get(1)); // 访问元素 System.out.println(sites.size()); // 获取大小 // 将 lambda 表达式传递给 forEach numbers.forEach((e) -\u003e { e = e * 10; System.out.print(e + \" \"); }); } } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:2","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"LinkedList类 链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的地址。链表可分为单向链表和双向链表。Java LinkedList（链表） 类似于 ArrayList，是一种常用的数据容器。与 ArrayList 相比，LinkedList 的增加和删除的操作效率更高，而查找和修改的操作效率较低。 以下情况使用 ArrayList : 频繁访问列表中的某一个元素。 只需要在列表末尾进行添加和删除元素操作。 以下情况使用 LinkedList : 你需要通过循环迭代来访问列表中的某些元素。 需要频繁的在列表开头、中间、末尾等位置进行添加和删除元素操作。 LinkedList 继承了 AbstractSequentialList 类。 LinkedList 实现了 Queue 接口，可作为队列使用。 LinkedList 实现了 List 接口，可进行列表的相关操作。 LinkedList 实现了 Deque 接口，可作为队列使用。 LinkedList 实现了 Cloneable 接口，可实现克隆。 LinkedList 实现了 java.io.Serializable 接口，即可支持序列化，能通过序列化去传输。 示例： import java.util.LinkedList; public class Test { public static void main(String[] args) { LinkedList\u003cString\u003e sites = new LinkedList\u003cString\u003e(); //创建LinkedList sites.add(\"Google\"); //添加元素 sites.add(\"Runoob\"); sites.add(\"Taobao\"); sites.addFirst(\"Wiki\"); //头部添加元素 sites.addLast(\"Weibo\"); //尾部添加元素 sites.removeFirst(); //移除头部元素 sites.removeLast(); //移除尾部元素 System.out.println(sites.getFirst()); //获取头部元素 System.out.println(sites.getLast()); //获取尾部元素 } } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:2:3","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Set接口 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:0","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"简介 Set体系集合可以知道某物是否已近存在于集合中,不会存储重复的元素。加入Set的每个元素必须是唯一的，否则，Set是不会把它加进去的。要想加进Set，Object必须定义equals()，这样才能标明对象的唯一性。Set的接口和Collection的一摸一样。Set的接口不保证它会用哪种顺序来存储元素。 Set HashSet : 为快速查找设计的Set。存入HashSet的对象必须定义hashCode()。 TreeSet : 保存次序的Set, 底层为树结构。使用它可以从Set中提取有序的序列。 LinkedHashSet : 具有HashSet的查询速度，且内部使用链表维护元素的顺序(插入的次序)。于是在使用迭代器遍历Set时，结果会按元素插入的次序显示。 Set排序 //把HashSet保存在ArrayList里，再用Collections.sort()方法比较 final HashSet\u003cInteger\u003e va = new HashSet\u003cInteger\u003e(); va.add(2007111315); va.add(2007111314); va.add(2007111318); va.add(2007111313); final List\u003cInteger\u003e list = new ArrayList\u003cInteger\u003e(); for(final Integer value : va){ list.add(value); } Collections.sort(list); System.out.println(list); //把这个HashSet做为构造参数放到TreeSet中就可以排序了 final TreeSet ts = new TreeSet(va); ts.comparator(); System.out.println(ts); Set遍历 //Iterator迭代遍历 Set\u003cString\u003e set = new HashSet\u003cString\u003e(); Iterator\u003cString\u003e it = set.iterator(); while (it.hasNext()) { String str = it.next(); System.out.println(str); } //for-each循环遍历 for (String str : set) { System.out.println(str); } Set转List //通过ArrayList进行转换 List\u003cString\u003e list1 = new ArrayList\u003cString\u003e(set); //List实现类进行转换 List\u003cString\u003e list2 = new ArrayList\u003cString\u003e (); list2.addAll(set); ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:1","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"HashSet类 HashSet使用的是相当复杂的方式来存储元素的，使用HashSet能够最快的获取集合中的元素，效率非常高（以空间换时间）。它会根据hashcode和equals来判断是否是同一个对象，如果hashcode一样，并且equals返回true，则是同一个对象，不能重复存放。 |–HashSet 底层是由HashMap实现的，通过对象的hashCode方法与equals方法来保证插入元素的唯一性，无序(存储顺序和取出顺序不一致)，。 ​ |–LinkedHashSet 底层数据结构由哈希表和链表组成。哈希表保证元素的唯一性，链表保证元素有序。(存储和取出是一致) LinkedHashSet类 LinkedHashSet是HashSet的一个子类，具有HashSet的特性，也是根据元素的hashCode值来决定元素的存储位置。但它使用链表维护元素的次序，元素的顺序与添加顺序一致。由于LinkedHashSet需要维护元素的插入顺序，因此性能略低于HashSet，但在迭代访问Set里的全部元素时由很好的性能。 (1)HashSet是Set接口的实现。HashSet按Hash算法来存储集合中的元素，具有很好的存取和查找性能。 (2)HashSet不是同步的，多个线程访问是需要通过代码保证同步 (3)HashSet集合元素值可以使null。 (4)HashSet不能保证元素的排列顺序，顺序可能与添加顺序不同，顺序也有可能发生变化。 (5)当向HashSet集合中存入一个元素时，HashSet会调用该对象的hashCode()方法来得到该对象的hashCode值，然后根据该HashCode值决定该对象在HashSet中的存储位置。如果有两个元素通过equals()方法比较返回true，但它们的hashCode()方法返回值不相等，HashSet将会把它们存储在不同的位置，依然可以添加成功。即，HashSet集合判断两个元素相等的标准是两个对象通过equals()方法比较相等，并且两个对象的hashCode()方法返回值也相等。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:2","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"TreeSet类 TreeSet时SortedSet接口的实现类，TreeSet可以保证元素处于排序状态，它采用红黑树的数据结构来存储集合元素。TreeSet支持两种排序方法：自然排序和定制排序，默认采用自然排序。 自然排序 TreeSet会调用集合元素的compareTo(Object obj)方法来比较元素的大小关系，然后将元素按照升序排列，这就是自然排序。如果试图将一个对象添加到TreeSet集合中，则该对象必须实现Comparable接口，否则会抛出异常。当一个对象调用方法与另一个对象比较时，例如obj1.compareTo(obj2)，如果该方法返回0，则两个对象相等；如果返回一个正数，则obj1大于obj2；如果返回一个负数，则obj1小于obj2。 Java常用类中已经实现了Comparable接口的类有以下几个： ♦ BigDecimal、BigDecimal以及所有数值型对应的包装类：按照它们对应的数值大小进行比较。 ♦ Charchter：按照字符的unicode值进行比较。 ♦ Boolean：true对应的包装类实例大于false对应的包装类实例。 ♦ String：按照字符串中的字符的unicode值进行比较。 ♦ Date、Time：后面的时间、日期比前面的时间、日期大。 对于TreeSet集合而言，它判断两个对象是否相等的标准是：两个对象通过compareTo(Object obj)方法比较是否返回0，如果返回0则相等。 定制排序 想要实现定制排序，需要在创建TreeSet集合对象时，提供一个Comparator对象与该TreeSet集合关联，由Comparator对象负责集合元素的排序逻辑。 综上：自然排序实现的是Comparable接口，定制排序实现的是Comparator接口。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:3:3","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Map接口 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:0","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"简介 Map 提供了一个更通用的元素存储方法。Map 集合类用于存储元素对（称作“键”和“值”），其中每个键映射到一个值。从概念上而言，您可以将 List 看作是具有数值键的 Map。 Map 是映射接口，Map中存储的内容是键值对(key-value)。 TreeMap 继承于AbstractMap，且实现了NavigableMap接口；因此，TreeMap中的内容是“有序的键值对” HashMap 继承于AbstractMap，但没实现NavigableMap接口；因此，HashMap的内容是“键值对，但不保证次序” Hashtable 虽然不是继承于AbstractMap，但它继承于Dictionary(Dictionary也是键值对的接口)，而且也实现Map接口；因此，Hashtable的内容也是“键值对，也不保证次序”。但和HashMap相比，Hashtable是线程安全的，而且它支持通过Enumeration去遍历。 Map通用方法 abstract void clear() abstract boolean containsKey(Object key) abstract boolean containsValue(Object value) abstract Set\u003cEntry\u003cK, V\u003e\u003e entrySet() abstract boolean equals(Object object) abstract V get(Object key) abstract int hashCode() abstract boolean isEmpty() abstract Set\u003cK\u003e keySet() abstract V put(K key, V value) abstract void putAll(Map\u003c? extends K, ? extends V\u003e map) abstract V remove(Object key) abstract int size() abstract Collection\u003cV\u003e values() Map提供接口分别用于返回 键集、值集或键-值映射关系集。entrySet()用于返回键-值集的Set集合;keySet()用于返回键集的Set集合;values()用户返回值集的Collection集合,因为Map中不能包含重复的键；每个键最多只能映射到一个值。所以，键-值集、键集都是Set，值集时Collection。 Map提供了“键-值对”、“根据键获取值”、“删除键”、“获取容量大小”等方法。 Map遍历 //用for循环遍历 for(Map.Entry\u003cString, String\u003e entry:map.entrySet()){ System.out.println(entry.getKey()+\"---\u003e\"+entry.getValue()); } //用Iterator迭代遍历 Set set = map.entrySet(); Iterator i = set.iterator(); while(i.hasNext()){ Map.Entry\u003cString, String\u003e entry1=(Map.Entry\u003cString, String\u003e)i.next(); System.out.println(entry1.getKey()+\"==\"+entry1.getValue()); } //用keySet()迭代遍历 Iterator it=map.keySet().iterator(); while(it.hasNext()){ String key; String value; key=it.next().toString(); value=map.get(key); System.out.println(key+\"--\"+value); } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:1","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"HashMap类 HashMap是我们使用非常多的Collection，它是基于哈希表的 Map 接口的实现，以key-value的形式存在。 HashMap实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了不同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap不是线程安全的，如果想要线程安全的HashMap，可以通过Collections类的静态方法synchronizedMap获得线程安全的HashMap,例如：Map map = Collections.synchronizedMap(new HashMap()); 归纳起来简单地说，HashMap 在底层将 key-value 当成一个整体进行处理，这个整体就是一个 Entry 对象。HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据 Hash 算法来决定其存储位置；当需要取出一个 Entry 时，也会根据 Hash 算法找到其存储位置，直接取出该 Entry。由此可见：HashMap 之所以能快速存、取它所包含的 Entry，完全类似于现实生活中母亲从小教我们的：不同的东西要放在不同的位置，需要时才能快速找到它。 当创建 HashMap 时，有一个默认的负载因子（load factor），其默认值为 0.75，这是时间和空间成本上一种折衷：增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。 LinkedHashMap实现类 LinkedHashMap使用双向链表来维护key-value对的次序（其实只需要考虑key的次序即可），该链表负责维护Map的迭代顺序，与插入顺序一致，因此性能比HashMap低，但在迭代访问Map里的全部元素时有较好的性能。 HashMap按照key进行排序 HashMap本身就是升序排列,如果要获取集合数据，见如下代码： Map\u003cString, Integer\u003e map = new HashMap\u003cString, Integer\u003e(); map.put(\"d\", 3); map.put(\"c\", 1); Set keySet = map.keySet(); Collections.sort(keySet); for(Iterator ite = keySet.iterator(); ite.hasNext();) { String temp = ite.next(); System.out.println(\"key-value: \"+temp+\",\"+map.getValue(temp); } 但是如果想要通过key进行降序排列，则需要重写sort方法，见如下代码： Collections.sort(keySet, new Comparator() { public int compare(Object o1, Object o2) { //如果map里面是其他类型直接更改sort里面的比较方法。 if (Integer.parseInt(o1.toString()) \u003e Integer.parseInt(o2.toString()) return 1; if (Integer.parseInt(o1.toString()) == Integer.parseInt(o2.toString()) return 0; else return - 1; } }); HashMap按照value值排序的方法 HashMap的value值没有排序功能，若要进行较轻松的排序，可改写Comparator接口方法compare进行排序，代码如下： Map\u003cString, Integer\u003e map = new HashMap\u003cString, Integer\u003e(); map.put(\"d\", 2); map.put(\"c\", 1); map.put(\"b\", 1); map.put(\"a\", 3); List\u003cMap.Entry\u003cString, Integer\u003e\u003e infoIds = new ArrayList\u003cMap.Entry\u003cString, Integer\u003e\u003e(map.entrySet()); //排序前 for (int i = 0; i \u003c infoIds.size(); i++) { String id = infoIds.get(i).toString(); System.out.println(id); } //根据value排序 Collections.sort(infoIds, new Comparator\u003cMap.Entry\u003cString, Integer\u003e\u003e() { public int compare(Map.Entry\u003cString, Integer\u003e o1, Map.Entry\u003cString, Integer\u003e o2) { return (o2.getValue() - o1.getValue()); //return (o1.getKey()).toString().compareTo(o2.getKey()); } }); //排序后 for (int i = 0; i \u003c infoIds.size(); i++) { String id = infoIds.get(i).toString(); System.out.println(id); } ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:2","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"TreeMap类 TreeMap继承了NavigableMap，而NavigableMap继承自SortedMap，为SortedMap添加了搜索选项，NavigableMap有几种方法，分别是不同的比较要求：floorKey是小于等于，ceilingKey是大于等于，lowerKey是小于，higherKey是大于。TreeMap的本质是R-B Tree(红黑树)，它包含几个重要的成员变量： root, size, comparator。 TreeMap 是一个有序的key-value集合，它是通过红黑树实现的。 TreeMap 继承于AbstractMap，所以它是一个Map，即一个key-value集合。 TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合。 TreeMap 实现了Cloneable接口，意味着它能被克隆。 TreeMap 实现了java.io.Serializable接口，意味着它支持序列化。 TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。 TreeMap的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n) 。 TreeMap是非同步的。 它的iterator 方法返回的迭代器是fail-fastl的。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:3","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"HashTable类 hashTable将key和value结合起来构成键值对通过put(key,value)方法保存起来，然后通过get(key)方法获取相对应的value值。它是线程安全的哈希映射表，内部采用Entry[]数组，每个Entry均可作为链表的头，用来解决冲突（碰撞）。同时Hashtables提供了一个很有用的方法可以使应用程序的性能达到最佳。 线程安全。 Key、Value均不能为null。 包含了一个Entry[]数组，而Entry又是一个链表，用来处理冲突。 每个Key对应了Entry数组中固定的位置（记为index），称为槽位（Slot）。槽位计算公式为： (key.hashCode() \u0026 0x7FFFFFFF) % Entry[].length() 。 当Entry[]的实际元素数量（Count）超过了分配容量（Capacity）的75%时，新建一个Entry[]是原先的2倍，并重新Hash（rehash）。 rehash的核心思路是，将旧Entry[]数组的元素重新计算槽位，散列到新Entry[]中。 HashTable与HashMap的区别 HashTable和HashMap存在很多的相同点，但是他们还是有几个比较重要的不同点。 第一：我们从他们的定义就可以看出他们的不同，HashTable基于Dictionary类，而HashMap是基于AbstractMap。Dictionary是什么？它是任何可将键映射到相应值的类的抽象父类，而AbstractMap是基于Map接口的骨干实现，它以最大限度地减少实现此接口所需的工作。 第二：HashMap可以允许存在一个为null的key和任意个为null的value，但是HashTable中的key和value都不允许为null。当HashMap遇到为null的key时，它会调用putForNullKey方法来进行处理。对于value没有进行任何处理，只要是对象都可以。 而当HashTable遇到null时，他会直接抛出NullPointerException异常信息。 第三：Hashtable的方法是同步的，而HashMap的方法不是。所以有人一般都建议如果是涉及到多线程同步时采用HashTable，没有涉及就采用HashMap，但是在Collections类中存在一个静态方法：synchronizedMap()，该方法创建了一个线程安全的Map对象，并把它作为一个封装的对象来返回，所以通过Collections类的synchronizedMap方法是可以我们你同步访问潜在的HashMap。 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:4:4","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Queue接口 Queue，java中模拟队列的一种数据结构，先进先出（FIFO）,不支持随机访问数据，通过offer（）方法增加数据到队列尾部，poll（）获取队列头部元素，可以将Queue看成一个通道，最先走进的通道的也是最先走出通道的，最后走进去的，在通道里面呆的时间最久。 常用方法： add 增加一个元索如果队列已满，则抛出一个IIIegaISlabEepeplian异常 remove 移除并返回队列头部的元素，如果队列为空，则抛出一个NoSuchElementException异常 element 返回队列头部的元素，如果队列为空，则抛出一个NoSuchElementException异常 offer 添加一个元素并返回true，如果队列已满，则返回false poll 移除并返问队列头部的元素，如果队列为空，则返回null peek 返回队列头部的元素，如果队列为空，则返回null put 添加一个元素，如果队列满，则阻塞 take 移除并返回队列头部的元素，如果队列为空，则阻塞 drainTo(list) 一次性取出队列所有元素 ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:5:0","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"PriorityQueue类 优先队列PriorityQueue是Queue接口的实现，可以对其中元素进行排序，可以放基本数据类型的包装类（如：Integer，Long等）或自定义的类对于基本数据类型的包装器类，优先队列中元素默认排列顺序是升序排列，但对于自己定义的类来说，需要自己定义比较器。 常用方法： peek()//返回队首元素 poll()//返回队首元素，队首元素出队列 add()//添加元素 size()//返回队列元素个数 isEmpty()//判断队列是否为空，为空返回true,不空返回false 示例： public static void main(String[] args) { //不用比较器，默认升序排列 Queue\u003cInteger\u003e q = new PriorityQueue\u003c\u003e(); q.add(3); q.add(2); q.add(4); while(!q.isEmpty()) { System.out.print(q.poll()+\" \"); //2 3 4 } //使用自定义比较器，降序排列 Queue\u003cInteger\u003e qq = new PriorityQueue\u003c\u003e(new Comparator\u003cInteger\u003e() { public int compare(Integer e1, Integer e2) { return e2 - e1; //升序:e1-e2,降序:e2-e1 } }); qq.add(3); qq.add(2); qq.add(4); while(!qq.isEmpty()) { System.out.print(qq.poll()+\" \"); //4 3 2 } } 本文参考至，如需更多详情，请查阅以下网站 菜鸟教程 Java School ","date":"2022-03-20","objectID":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/:5:1","tags":["Java集合"],"title":"Java集合学习","uri":"/java%E9%9B%86%E5%90%88%E5%AD%A6%E4%B9%A0/"},{"categories":["实践笔记"],"content":"消息推送是大部分系统都需要做到的功能，在.NET中我分别通过RabbitMQ、MQTT、SignalR实现消息推送功能，本篇文章将通过它们实现简单的推送功能，手把手带大家完成编程。本文环境为.NET Core 3.1下 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:0:0","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"SignalR实现 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:1:0","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"简介 SignalR是一个开源的库，跨平台；让Web应用与其他应用通讯变得很简单，Web服务端可以实时的将内容推送给对应的客户端，客户端发送的信息也可以实时到其他客户端。 SignalR提供了一种远程过程调用(RPC)的方式，使得客户端可以调用服务器的方法，同样在服务器端的方法中也能调用客户端的方法。 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:1:1","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"示例 Nuget包为： \u003cPackageReference Include=\"Microsoft.AspNetCore.SignalR.Core\" Version=\"1.1.0\" /\u003e 首先我们需要创建一个自己的SignalR Hub using Microsoft.AspNetCore.SignalR; using System.Threading.Tasks; namespace KBEAM.Hubs { public class ChatHub : Hub // 继承自SignalR Hub库 { public async Task SendMessage(string user, string message) { await Clients.All.SendAsync(\"ReceiveMessage\", user, message); } public async Task SendMessageToGroup(string group, string message) { await Clients.Group(group).SendAsync(\"ReceiveMessageFromGroup\", group, message); } public async Task AddToGroup(string groupName) { await Groups.AddToGroupAsync(Context.ConnectionId, groupName); await Clients.Group(groupName).SendAsync(\"ReceiveMessage\", $\"{Context.ConnectionId} has joined the group {groupName}.\"); } public async Task RemoveFromGroup(string groupName) { await Groups.RemoveFromGroupAsync(Context.ConnectionId, groupName); //await Clients.Group(groupName).SendAsync(\"ReceiveMessage\", $\"{Context.ConnectionId} has left the group {groupName}.\"); } } } 在Startup.cs文件中注册相关服务及管道 // 1.在ConfigureServices函数中添加以下语句，注册相关服务 services.AddSignalR(); // 2.在Configure函数中添加以下语句，配置管道终结点 app.UseEndpoints(endpoints =\u003e { // ... endpoints.MapHub\u003cChatHub\u003e(\"/chatHub\"); // ... }); 编写服务端业务，推送消息 // 定义一个上下文 private readonly IHubContext\u003cChatHub\u003e hubContext; // 通过构造函数注入依赖 public MonitorService(IHubContext\u003cChatHub\u003e hub) { hubContext = hub; } //在需要的地方调用方法，进行消息推送 await hubContext.Clients.Group(group).SendAsync(\"ReceiveMessageFromGroup\",group, \"需要发送的消息\"); JS客户端程序编写 首先，需要通过npm来安装SignalR封装好的JS文件，npm install @microsoft/signalr // 1.首先进行SignalR客户端连接 const signalR = require(\"@microsoft/signalr\") let conn = new signalR.HubConnectionBuilder() .withUrl(\"http://localhost:8988/chatHub\") .withAutomaticReconnect() .configureLogging(signalR.LogLevel.Error) .build() export default conn import signalR from \"@/utils/signalR\"; // 2.客户端调用服务端方法（RPC） signalR.invoke(\"AddToGroup\", \"groupName\").catch(function (err) { // 加入用户组 return console.error(err.toString()); }); signalR.invoke(\"RemoveFromGroup\", \"大屏\").catch(function (err) { // 移除用户组 return console.error(err.toString()); }); // 3.客户端监听服务器消息 signalR.on(\"ReceiveMessageFromGroup\", function (group, message) { console.log(group + \" \" + message); that.lineChartData = JSON.parse(message); }); ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:1:2","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"RabbitMQ实现 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:2:0","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"简介 RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件），由以高性能、健壮以及可伸缩性出名的 Erlang 写成。 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:2:1","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"示例 首先您需要在电脑上安装好 Erlang及RabbitMQ服务器，这一步大家就自行搜索解决吧，网上应该有很多的解决方法 RabbitMQ准备 首先开启Stomp插件 rabbitmq-plugins enable rabbitmq_management # 开启此插件后有管理界面http://localhost:15672/ rabbitmq-plugins enable rabbitmq_web_stomp rabbitmq-plugins enable rabbitmq_web_stomp_examples 服务端发送消息 所需Nuget包： \u003cPackageReference Include=\"RabbitMQ.Client\" Version=\"6.2.4\" /\u003e // 建立RabbitMQ连接 private static readonly ConnectionFactory rabbitMqFactory = new ConnectionFactory() { HostName = \"localhost\", UserName = \"用户名\", Password = \"密码\", Port = 5672, VirtualHost = \"虚拟主机配置\" }; // 发送消息 using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { channel.ExchangeDeclare(\"monitor\", ExchangeType.Direct, durable: true, autoDelete: false, arguments: null); channel.QueueDeclare(\"message\", durable: true, autoDelete: false, exclusive: false, arguments: null); channel.QueueBind(\"message\", \"monitor\", routingKey: \"message\"); var props = channel.CreateBasicProperties(); props.Persistent = true; channel.BasicPublish(exchange: \"monitor\", routingKey: \"message\", basicProperties: props, body: Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(new { expectedData, actualData }))); } } 具体RabbitMQ使用可以看我的RabbitMQ学习笔记 客户端接受消息 首先需要安装npm库文件，npm install stompjs import Stomp from \"stompjs\"; // 定义一个RabbitMQ客户端 data() { return { client: Stomp.client(\"ws://localhost:15674/ws\"), }; }, // 初始化连接操作 created() { this.client.connect( \"用户名\", \"密码\", this.onConnected, this.onFailed, \"虚拟主机名称\" ); } methods: { onConnected: function () { //订阅频道 // const topic = localStorage.getItem(\"Lesan\"); console.log(\"连接成功\"); this.client.subscribe( \"/exchange/monitor/message\", this.responseCallback, this.onFailed ); }, onFailed: function (frame) { console.log(\"MQ Failed: \" + frame); this.$message.error(\"连接失败\"); }, // 回传消息 responseCallback: function (frame) { console.log(\"MQ msg=\u003e\" + frame.body); this.lineChartData = JSON.parse(frame.body); //接收消息处理 }, // 断开相应的连接 close: function () { this.client.disconnect(function () { console.log(\"已退出账号\"); }); }, }, ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:2:2","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"MQTT实现 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:3:0","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"简介 MQTT是IBM开发的一个即时通讯协议，该协议支持所有的平台，几乎可以把所有联网的物品和外部连接起来。 使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合。这一点很类似于XMPP，但是MQTT的信息冗余远小于XMPP。 使用TCP/IP提供网络连接。主流的MQTT是基于TCP连接进行数据推送的，但是同样有基于UDP的版本，叫做MQTT-SN。这两种版本由于基于不同的连接方式，优缺点自然也就各有不同了。 三种消息传输方式QoS： 0代表“至多一次”，消息发布完全依赖底层 TCP/IP 协议。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送 1代表“至少一次”，确保消息到达，但消息重复可能会发生 2代表“只有一次”，确保消息到达一次。这一级别可用于如下情况，在计费系统中，消息重复或丢失会导致不正确的结果 ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:3:1","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"示例 服务端开发 所需Nuget包：\u003cPackageReference Include=\"MQTTnet.AspNetCore\" Version=\"3.1.2\" /\u003e 对Program.cs修改： public static IHostBuilder CreateHostBuilder(string[] args) =\u003e Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =\u003e { webBuilder.UseKestrel(o =\u003e { o.ListenAnyIP(8988); o.ListenAnyIP(1884, t =\u003e t.UseMqtt()); }); webBuilder.UseStartup\u003cStartup\u003e(); //webBuilder.UseUrls(\"http://0.0.0.0:8988\"); }); 对Startup.cs修改： // 在ConfigureServices函数中添加 services.AddHostedMqttServer(mqttServer =\u003e mqttServer.WithoutDefaultEndpoint().WithConnectionValidator(c =\u003e { if (c.Username != \"admin\" || c.Password != \"123456\") { c.ReasonCode = MqttConnectReasonCode.BadUserNameOrPassword; return; } c.ReasonCode = MqttConnectReasonCode.Success; })) .AddMqttConnectionHandler() .AddConnections(); // 在Configure函数中添加 app.UseEndpoints(endpoints =\u003e { endpoints.MapConnectionHandler\u003cMqttConnectionHandler\u003e( \"/mqtt\", httpConnectionDispatcherOptions =\u003e httpConnectionDispatcherOptions.WebSockets.SubProtocolSelector = protocolList =\u003e protocolList.FirstOrDefault() ?? string.Empty); }); app.UseMqttServer(S =\u003e { MqttHelper.Server = S; S.ClientConnectedHandler = new MqttServerClientConnectedHandlerDelegate(OnConnected); S.StartedHandler = new MqttServerStartedHandlerDelegate(OnStarted); }); // 添加事件处理函数 private void OnStarted(EventArgs obj) { RecurringJob.AddOrUpdate\u003cMonitorService\u003e(\"MonitorData\", p =\u003e p.UpdateDataAsync(\"大屏\"), \"0/15 * * * * *\"); } private void OnConnected(MqttServerClientConnectedEventArgs args) { Console.WriteLine(args.ClientId); } // 消息推送方法 MqttHelper.PublishAsync(\"monitor\", JsonConvert.SerializeObject(new { expectedData, actualData })); 添加MqttHelper类： using MQTTnet.Server; using System.Text; namespace Common { public class MqttHelper { public static IMqttServer Server { get; set; } public static void PublishAsync(string topic, byte[] payload) { if (Server != null) { Server.PublishAsync(new MQTTnet.MqttApplicationMessage() { Topic = topic, Payload = payload }, new System.Threading.CancellationToken(false)); } } public static void PublishAsync(string topic, string payload) { if (Server != null) { Server.PublishAsync(new MQTTnet.MqttApplicationMessage() { Topic = topic, Payload = Encoding.UTF8.GetBytes(payload) }, new System.Threading.CancellationToken(false)); ; } } } } 客服端开发 首先需要引入npm包：npm install mqtt import mqtt from \"mqtt\"; // 连接Mqtt服务器，并订阅消息 mounted() { let that = this; let mqttClient = mqtt.connect(\"ws://localhost:8988/mqtt\", { username: \"用户名\", password: \"密码\", clientId: \"客户端ID\", }); mqttClient.on(\"connect\", (e) =\u003e { console.log(\"connected\", e); mqttClient.subscribe(\"monitor\", { qos: 1 }, (err) =\u003e { if (!err) { console.log(\"subscribed\"); } }); }); mqttClient.on(\"message\", (topic, message) =\u003e { console.log(topic, message.toString()); that.lineChartData = JSON.parse(message.toString()); }); }, ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:3:2","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["实践笔记"],"content":"其他 Vue前端测试客户端全部代码，通过Vue-cli搭建的项目，修改App.vue即可 \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cimg alt=\"Vue logo\" src=\"./assets/logo.png\" /\u003e \u003cHelloWorld msg=\"Welcome to Your Vue.js App\" /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import HelloWorld from \"./components/HelloWorld.vue\"; import mqtt from \"mqtt\"; import Stomp from \"stompjs\"; export default { name: \"App\", components: { HelloWorld, }, data() { return { rabbitClient: Stomp.client(\"ws://172.21.30.233:15674/ws\"), }; }, created() {}, mounted() { // this.useMqtt(); // this.useRabbitMQ(); this.useSignalR(); }, methods: { useSignalR() { const signalR = require(\"@microsoft/signalr\"); const conn = new signalR.HubConnectionBuilder() .withUrl(\"http://172.21.30.233:8988/chatHub\") .withAutomaticReconnect() .configureLogging(signalR.LogLevel.Error) .build(); conn .start() .then(() =\u003e { console.log(\"conneted\"); conn.invoke(\"AddToGroup\", \"大屏\").catch(function (err) { return console.error(err.toString()); }); conn.on(\"ReceiveMessageFromGroup\", function (group, message) { console.log(group + \" \" + message); }); }) .catch((err) =\u003e { return console.error(err.toString()); }); }, useMqtt() { let mqttClient = mqtt.connect(\"ws://172.21.30.233:8988/mqtt\", { username: \"admin\", password: \"123456\", // clientId: \"Lesan\", }); mqttClient.on(\"connect\", (e) =\u003e { console.log(\"connected\", e); mqttClient.subscribe(\"monitor\", { qos: 1 }, (err) =\u003e { if (!err) { console.log(\"subscribed\"); } }); }); mqttClient.on(\"message\", (topic, message) =\u003e { console.log(topic, message.toString()); }); }, useRabbitMQ() { // this.rabbitClient.heartbeat.outgoing = 0; // this.rabbitClient.heartbeat.incoming = 0; this.rabbitClient.connect( \"KB\", \"KB\", this.onConnected, this.onFailed, \"kb_monitor\" ); }, onConnected: function () { //订阅频道 // const topic = localStorage.getItem(\"Lesan\"); console.log(\"连接成功\"); this.rabbitClient.subscribe( \"/exchange/monitor/message\", this.responseCallback, this.onFailed ); }, onFailed: function (frame) { console.log(\"MQ Failed: \" + frame); this.$message.error(\"连接失败\"); }, // 回传消息 responseCallback: function (frame) { console.log(\"MQ msg=\u003e\" + frame.body); //接收消息处理 }, // 断开相应的连接 close: function () { this.rabbitClient.disconnect(function () { console.log(\"已退出账号\"); }); }, }, }; \u003c/script\u003e \u003cstyle\u003e #app { font-family: Avenir, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px; } \u003c/style\u003e ","date":"2022-03-19","objectID":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/:4:0","tags":["消息推送",".NET"],"title":"实现简单消息推送功能","uri":"/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E5%8A%9F%E8%83%BD/"},{"categories":["学习笔记"],"content":"RabbitMQ简述 MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。RabbitMQ是一个在AMQP基础上完整的，可复用的企业消息系统。他遵循Mozilla Public License开源协议。AMQP(高级消息队列协议) 是一个异步消息传递所使用的应用层协议规范，作为线路层协议，而不是API（例如JMS），AMQP 客户端能够无视消息的来源任意发送和接受信息。AMQP的原始用途只是为金融界提供一个可以彼此协作的消息协议，而现在的目标则是为通用消息队列架构提供通用构建工具。因此，面向消息的中间件 （MOM）系统，例如发布/订阅队列，没有作为基本元素实现。AMQP当中有四个概念非常重要（一个虚拟主机持有一组交换机、队列和绑定）： virtual host，虚拟主机 exchange，交换机 queue，队列 binding，绑定 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:1:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息传递过程 上图为RabbitMQ中一些重要名词的概述，其中包括Connection、Channel、Exchange、Queue、Bind、Routing Key 上图为消息从生产到消费的整个流程，其中Exchange，与Queue都是可以设置相关属性，队列的持久化，交换器类型制定 这个过程走分三个部分，1、客户端（生产消息队列），2、RabbitMQ服务端（负责路由规则的绑定与消息的分发），3、客户端（消费消息队列中的消息） 由图可以看出，一个消息可以走一次网络却被分发到不同的消息队列中，然后被多个的客户端消费，那么这个过程就是RabbitMQ的核心机制，RabbitMQ的路由类型与消费模式 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:2:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"RabbitMQ中Exchange的类型 类型有4种，direct，fanout，topic，headers。其中headers不常用，本篇不做介绍，其他三种类型，会做详细介绍。 那么这些类型是什么意思呢？就是Exchange与队列进行绑定后，消息根据exchang的类型，按照不同的绑定规则分发消息到消息队列中，可以是一个消息被分发给多个消息队列，也可以是一个消息分发到一个消息队列。具体请看下文。 介绍之初还要说下RoutingKey，这是个什么玩意呢？他是exchange与消息队列绑定中的一个标识。有些路由类型会按照标识对应消息队列，有些路由类型忽略routingkey。具体看下文。 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Exchange类型direct 根据交换器名称与routingkey来找队列的 Note:消息从client发出，传送给交换器ChangeA，RoutingKey为routingkey.ZLH,那么不管你发送给Queue1，还是Queue2一个消息都会保存在Queue1，Queue2，Queue3，三个队列中。这就是交换器的direct类型的路由规则。只要找到路由器与routingkey绑定的队列，那么他有多少队列，他就分发给多少队列。 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:1","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Exchange类型fanout 这个类型忽略Routingkey，他为广播模式 Note:消息从客户端发出，只要queue与exchange有绑定，那么他不管你的Routingkey是什么他都会将消息分发给所有与该exchang绑定的队列中。 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:2","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Exchange类型topic 这个类型的路由规则如果你掌握啦，那是相当的好用，与灵活。他是根据RoutingKey的设置，来做匹配的，其中这里还有两个通配符为： *，代表任意的一个词。例如topic.zlh.*，他能够匹配到，topic.zlh.one ,topic.zlh.two ,topic.zlh.abc, …. #，代表任意多个词。例如topic.#，他能够匹配到，topic.zlh.one ,topic.zlh.two ,topic.zlh.abc, …. Note：这个图看上去很乱，但是他是根据匹配符做匹配的，这里我建议你自己做下消息队列的具体操作。 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:3:3","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息队列的消费与消息确认 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:4:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息队列的消费 Note:如果一个消息队列中有大量消息等待操作时，我们可以用多个客户端来处理消息，这里的分发机制是采用负载均衡算法中的轮询。第一个消息给A，下一个消息给B，下下一个消息给A，下下下一个消息给B……以此类推 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:4:1","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消息确认 保证消息的安全性，保证此消息被正确处理后才能在服务端的消息队列中删除。那么rabbitmq提供啦ack应答机制，来实现这一功能。 ack应答有两种方式：1、自动应答，2、手动应答 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:4:2","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"使用例子 ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:5:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"生产者 using RabbitMQ.Client; using System; using System.Text; namespace RabbitMQProduct { internal class Program { static void Main(string[] args) { Console.WriteLine(\"Welcome to RabbitMQ Product!\"); DirectExchangeSendMsg(); // TopicExchangeSendMsg(); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } /// \u003csummary\u003e /// 连接配置 /// \u003c/summary\u003e private static readonly ConnectionFactory rabbitMqFactory = new ConnectionFactory() { UserName = \"guest\", Password = \"guest\", Port = 5672, //VirtualHost = \"LesanVirtualHost\" }; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string ExchangeName = \"Lesan.exchange\"; //队列名称 const string QueueName = \"Lesan.queue\"; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string TopExchangeName = \"topic.Lesan.exchange\"; //队列名称 const string TopQueueName = \"topic.Lesan.queue\"; /// \u003csummary\u003e /// 单点精确路由模式 /// \u003c/summary\u003e public static void DirectExchangeSendMsg() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //设置交换器的类型 channel.ExchangeDeclare(ExchangeName, ExchangeType.Direct, durable: true, autoDelete: false, arguments: null); //声明一个队列，设置队列是否持久化，排他性，与自动删除 channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); //绑定消息队列，交换器，routingkey channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); var props = channel.CreateBasicProperties(); //队列持久化 props.Persistent = true; string vadata = Console.ReadLine(); while (vadata != \"exit\") { var msgBody = Encoding.UTF8.GetBytes(vadata); //发送信息 channel.BasicPublish(exchange: ExchangeName, routingKey: QueueName, basicProperties: props, body: msgBody); Console.WriteLine(string.Format(\"***发送时间:{0}，发送完成，输入exit退出消息发送\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"))); vadata = Console.ReadLine(); } } } } /// \u003csummary\u003e /// topic 模糊匹配模式，符号“#”匹配一个或多个词，符号“*”匹配不多不少一个词。因此“log.#”能够匹配到“log.info.oa”，但是“log.*” 只会匹配到“log.error” /// \u003c/summary\u003e public static void TopicExchangeSendMsg() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { channel.ExchangeDeclare(TopExchangeName, ExchangeType.Topic, durable: false, autoDelete: false, arguments: null); channel.QueueDeclare(TopQueueName, durable: false, autoDelete: false, exclusive: false, arguments: null); channel.QueueBind(TopQueueName, TopExchangeName, routingKey: TopQueueName); //var props = channel.CreateBasicProperties(); //props.Persistent = true; string vadata = Console.ReadLine(); while (vadata != \"exit\") { var msgBody = Encoding.UTF8.GetBytes(vadata); channel.BasicPublish(exchange: TopExchangeName, routingKey: TopQueueName, basicProperties: null, body: msgBody); Console.WriteLine(string.Format(\"***发送时间:{0}，发送完成，输入exit退出消息发送\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"))); vadata = Console.ReadLine(); } } } } } } ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:5:1","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"消费者 using RabbitMQ.Client; using RabbitMQ.Client.Events; using System; using System.Text; namespace RabbitMQConsumer { internal class Program { static void Main(string[] args) { Console.WriteLine(\"Welcome to RabbitMQ Consumer!\"); //DirectAcceptExchange(); //DirectAcceptExchangeEvent(); DirectAcceptExchangeTask(); //TopicAcceptExchange(); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } /// \u003csummary\u003e /// 连接配置 /// \u003c/summary\u003e private static readonly ConnectionFactory rabbitMqFactory = new ConnectionFactory() { UserName = \"guest\", Password = \"guest\", Port = 5672, //VirtualHost = \"LesanVirtualHost\" }; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string ExchangeName = \"Lesan.exchange\"; //队列名称 const string QueueName = \"Lesan.queue\"; /// \u003csummary\u003e /// 路由名称 /// \u003c/summary\u003e const string TopExchangeName = \"topic.Lesan.exchange\"; //队列名称 const string TopQueueName = \"topic.Lesan.queue\"; /// \u003csummary\u003e /// 基于时间轮询的，每隔一段时间获取一次 /// \u003c/summary\u003e public static void DirectAcceptExchange() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //设置交换器的类型 channel.ExchangeDeclare(ExchangeName, ExchangeType.Direct, durable: true, autoDelete: false, arguments: null); //声明一个队列，设置队列是否持久化，排他性，与自动删除 channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); //绑定消息队列，交换器，routingkey channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); while (true) { BasicGetResult msgResponse = channel.BasicGet(QueueName, true); if (msgResponse != null) { var msgBody = Encoding.UTF8.GetString(msgResponse.Body.ToArray()); Console.WriteLine(string.Format(\"***接收时间:{0}，消息内容：{1}\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"), msgBody)); } System.Threading.Thread.Sleep(TimeSpan.FromSeconds(1)); } } } } /// \u003csummary\u003e /// 基于事件的，当消息到达时触发事件，获取数据 /// \u003c/summary\u003e public static void DirectAcceptExchangeEvent() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //channel.ExchangeDeclare(ExchangeName, \"direct\", durable: true, autoDelete: false, arguments: null); channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); //channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u003e { var msgBody = Encoding.UTF8.GetString(ea.Body.ToArray()); Console.WriteLine(string.Format(\"***接收时间:{0}，消息内容：{1}\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"), msgBody)); }; channel.BasicConsume(QueueName, true, consumer: consumer); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } } } /// \u003csummary\u003e /// 基于事件的，当消息到达时触发事件，获取数据 /// \u003c/summary\u003e public static void DirectAcceptExchangeTask() { using (IConnection conn = rabbitMqFactory.CreateConnection()) { using (IModel channel = conn.CreateModel()) { //channel.ExchangeDeclare(ExchangeName, \"direct\", durable: true, autoDelete: false, arguments: null); channel.QueueDeclare(QueueName, durable: true, autoDelete: false, exclusive: false, arguments: null); channel.BasicQos(prefetchSize: 0, prefetchCount: 1, global: false);//告诉broker同一时间只处理一个消息 //channel.QueueBind(QueueName, ExchangeName, routingKey: QueueName); //定义这个队列的消费者 var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u003e { var msgBody = Encoding.UTF8.GetString(ea.Body.ToArray()); Console.WriteLine(string.Format(\"***接收时间:{0}，消息内容：{1}\", DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\"), msgBody)); int dots = msgBody.Split('.').Length - 1; System.Threading.Thread.Sleep(dots * 1000); //处理完成，告诉Broker可以服务端可以删除消息，分配新的消息过来 channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false); }; //noAck设置false,告诉broker，发送消息之后，消息暂时不要删除，等消费者处理完成再说 //false为手动应答，true为自动应答 channel.BasicConsume(QueueName, false, consumer: consumer); Console.WriteLine(\"按任意值，退出程序\"); Console.ReadKey(); } } } /// \u003csummary\u003e /// topic 模糊匹配模式，符号“#”匹配一个或多个词，符号“*”匹配不多不少一个词。因此“log.#”能够匹配到“log.info.oa”，但是“log.*” 只会匹配到“log.error” /","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:5:2","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"引用 以上笔记摘录自网络 https://www.cnblogs.com/knowledgesea/p/5296008.html https://www.cnblogs.com/personblog/p/10681741.html ","date":"2022-02-17","objectID":"/rabbitmq%E5%AD%A6%E4%B9%A0/:6:0","tags":["RabbitMQ",".NET"],"title":"RabbitMQ学习","uri":"/rabbitmq%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"本文为个人学习和实践 Nginx 的笔记 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:0:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 常用功能 Nginx 有以下几个常用功能 反向代理 这是它的主要功能之一，客户端向服务器发送请求时，会先通过 Nginx 服务器，由服务器将请求分发到相应的Web服务器。正向代理是代理客户端，而反向代理则是代理服务器，Nginx 在提供反向代理服务方面，通过使用正则表达式进行相关配置，采取不同的转发策略，配置相当灵活，而且在配置后端转发请求时，完全不用关心网络环境如何，可以指定任意的IP地址和端口号，或其他类型的连接、请求等。 负载均衡 这也是 Nginx 最常用的功能之一，负载均衡，一方面是将单一的重负载分担到多个网络节点上做并行处理，每个节点处理结束后将结果汇总返回给用户，这样可以大幅度提高网络系统的处理能力；另一方面将大量的前端并发请求或数据流量分担到多个后端网络节点分别处理，这样可以有效减少前端用户等待相应的时间。而 Nginx 负载均衡都是属于后一方面，主要是对大量前端访问或流量进行分流，已保证前端用户访问效率，并可以减少后端服务器处理压力。 Web缓存 在很多优秀的网站中，Nginx 可以作为前置缓存服务器，它被用于缓存前端请求，从而提高 Web服务器的性能。Nginx 会对用户已经访问过的内容在服务器本地建立副本，这样在一段时间内再次访问该数据，就不需要通过 Nginx 服务器向后端发出请求。减轻网络拥堵，减小数据传输延时，提高用户访问速度。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:1:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 安装 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"下载地址 Nginx 下载地址：http://nginx.org/en/download.html ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Windows 版本安装 解压下载的文件后 下面对上面文件夹进行介绍： conf 目录：存放 Nginx 的主要配置文件，很多功能实现都是通过配置该目录下的 nginx.conf 文件，后面我们会详细介绍。 docs目录：存放 Nginx 服务器的主要文档资料，包括 Nginx 服务器的 LICENSE、OpenSSL 的 LICENSE 、PCRE 的 LICENSE 以及 zlib 的 LICENSE ，还包括本版本的 Nginx服务器升级的版本变更说明，以及 README 文档。 html目录：存放了两个后缀名为 .html 的静态网页文件，这两个文件与 Nginx 服务器的运行相关。 logs目录：存放 Nginx 服务器运行的日志文件。 nginx.exe：启动 Nginx 服务器的exe文件，如果 conf 目录下的 nginx.conf 文件配置正确的话，通过该文件即可启动 Nginx 服务器。 关闭 nginx 的方法： 进入到 nginx 目录并且输入以下命令：nginx.exe -s stop ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Linux 版本安装 首先需要安装 nginx 的依赖环境： yum install gcc-c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 对于 gcc，因为安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境的话，需要安装gcc。 对于 pcre，prce(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。 对于 zlib，zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。 对于 openssl，OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。 编译及安装： 1. 首先将下载的文件放到 Linux 系统中，然后解压： tar -zxvf nginx-1.14.0.tar.gz 2. 接着进入解压之后的目录进行编译安装 ./configure --prefix=/usr/local/nginx make make install 3. 进入到/usr/local/nginx目录，再进入sbin目录，通过以下命令启动nginx: ./nginx 通过 ps -ef | grep nginx 查看nginx的进程 4. 关闭nginx： 快速关闭：cd /usr/local/nginx/sbin ./nginx -s stop 相当于直接kill掉nginx的进程id 平缓关闭：cd /usr/local/nginx/sbin ./nginx -s quit 等nginx服务处理完所有请求后再关闭连接，停止工作 5. 重启nginx 先停止再启动：./nginx -s quit ./nginx 重新加载配置文件：./nginx -s reload 6. 检测配置文件语法是否正确 指定需要检测的配置文件：nginx -t -c /usr/local/nginx/conf/nginx.conf 检测默认nginx.conf配置文件：nginx -t ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:2:3","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"nginx.conf 配置文件 根据默认配置文件，我们可以将nginx.conf配置文件分为三部分： ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"全局块 从配置文件开始到 events 块之间的内容，主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。 比如：worker_processes 1; 这是Nginx服务器并发处理服务的关键配置，worker_processes 值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"events 块 比如： events { worker_connections 1024; } events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 work process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 word process 可以同时支持的最大连接数等。 上述例子就表示每个 work process 支持的最大连接数为 1024. 这部分的配置对 Nginx 的性能影响较大，在实际中应该灵活配置。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"http 块 http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 这是Nginx服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 http 块也可以包括 http全局块、server 块： http全局块 http全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。 server块 这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。后面会详细介绍虚拟主机的概念。 每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。 而每个 server 块也分为全局 server 块，以及可以同时包含多个 locaton 块。 全局server块：最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或IP配置。 location块：一个 server 块可以配置多个 location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是IP别名）之外的字符串（例如 前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:3:3","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"反向代理 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"代理定义 Nginx 主要能够代理如下几种协议，其中用到的最多的就是做Http代理服务器。 在Java设计模式中，代理模式是这样定义的：给某个对象提供一个代理对象，并由代理对象控制原对象的引用。 代理简单来说，就是如果我们想做什么，但又不想直接去做，那么这时候就找另外一个人帮我们去做。那么这个例子里面的中介公司就是给我们做代理服务的，我们委托中介公司帮我们找房子。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"正向代理定义 弄清楚什么是代理了，那么什么又是正向代理呢？ 这里我再举一个例子：大家都知道，现在国内是访问不了 Google的，那么怎么才能访问 Google呢？我们又想，美国人不是能访问 Google吗（这不废话，Google就是美国的），如果我们电脑的对外公网 IP 地址能变成美国的 IP 地址，那不就可以访问 Google了。你很聪明，VPN 就是这样产生的。我们在访问 Google 时，先连上 VPN 服务器将我们的 IP 地址变成美国的 IP 地址，然后就可以顺利的访问了。 这里的 VPN 就是做正向代理的。正向代理服务器位于客户端和服务器之间，为了向服务器获取数据，客户端要向代理服务器发送一个请求，并指定目标服务器，代理服务器将目标服务器返回的数据转交给客户端。这里客户端是要进行一些正向代理的设置的。 PS：这里介绍一下什么是 VPN，VPN 通俗的讲就是一种中转服务，当我们电脑接入 VPN 后，我们对外 IP 地址就会变成 VPN 服务器的 公网 IP，我们请求或接受任何数据都会通过这个VPN 服务器然后传入到我们本机。这样做有什么好处呢？比如 VPN 游戏加速方面的原理，我们要玩网通区的 LOL，但是本机接入的是电信的宽带，玩网通区的会比较卡，这时候就利用 VPN 将电信网络变为网通网络，然后在玩网通区的LOL就不会卡了（注意：VPN 是不能增加带宽的，不要以为不卡了是因为网速提升了）。 可能听到这里大家还是很抽象，没关系，和下面的反向代理对比理解就简单了。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"反向代理定义 反向代理和正向代理的区别就是：正向代理代理客户端，反向代理代理服务器。 反向代理，其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。 下面我们通过两张图来对比正向代理和方向代理： 理解这两种代理的关键在于代理服务器所代理的对象是什么，正向代理代理的是客户端，我们需要在客户端进行一些代理的设置。而反向代理代理的是服务器，作为客户端的我们是无法感知到服务器的真实存在的。 总结起来还是一句话：正向代理代理客户端，反向代理代理服务器。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:3","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 反向代理 相关指令 listen 该指令用于配置网络监听。主要有如下三种配置语法结构： ① 配置监听的IP地址 listen address[:port] [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [deferred] [accept_filter=filter] [bind] [ssl]; ② 配置监听端口 listen port [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deffered] [bind] [ipv6only=on|off] [ssl]; ③ 配置 UNIX Domain Socket listen unix:path [default_server] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deffered] [bind] [ssl] 上面的配置看似比较复杂，其实使用起来是比较简单的： listen *:80 | *:8080 #监听所有80端口和8080端口 listen IP_address:port #监听指定的地址和端口号 listen IP_address #监听指定ip地址所有端口 listen port #监听该端口的所有IP连接 下面分别解释每个选项的具体含义： 1、address:IP地址，如果是 IPV6地址，需要使用中括号[] 括起来，比如[fe80::1]等。 2、port:端口号，如果只定义了IP地址，没有定义端口号，那么就使用80端口。 3、path:socket文件路径，如 var/run/nginx.sock等。 4、default_server:标识符，将此虚拟主机设置为 address:port 的默认主机。（在 nginx-0.8.21 之前使用的是 default 指令） 5、 setfib=number:Nginx-0.8.44 中使用这个变量监听 socket 关联路由表，目前只对 FreeBSD 起作用，不常用。 6、backlog=number:设置监听函数listen()最多允许多少网络连接同时处于挂起状态，在 FreeBSD 中默认为 -1,其他平台默认为511. 7、rcvbuf=size:设置监听socket接收缓存区大小。 8、sndbuf=size:设置监听socket发送缓存区大小。 9、deferred:标识符，将accept()设置为Deferred模式。 10、accept_filter=filter:设置监听端口对所有请求进行过滤，被过滤的内容不能被接收和处理，本指令只在 FreeBSD 和 NetBSD 5.0+ 平台下有效。filter 可以设置为 dataready 或 httpready 。 11、bind:标识符，使用独立的bind() 处理此address:port，一般情况下，对于端口相同而IP地址不同的多个连接，Nginx 服务器将只使用一个监听指令，并使用 bind() 处理端口相同的所有连接。 12、ssl:标识符，设置会话连接使用 SSL模式进行，此标识符和Nginx服务器提供的 HTTPS 服务有关。 server_name 该指令用于虚拟主机的配置。通常分为以下两种： 1、基于名称的虚拟主机配置 语法格式如下： server_name name ...; 一、对于name 来说，可以只有一个名称，也可以有多个名称，中间用空格隔开。而每个名字由两段或者三段组成，每段之间用“.”隔开。 server_name 123.com www.123.com 二、可以使用通配符“*”，但通配符只能用在由三段字符组成的首段或者尾端，或者由两端字符组成的尾端。 server_name *.123.com www.123.* 三、还可以使用正则表达式，用“~”作为正则表达式字符串的开始标记。 server_name ~^www\\d+\\.123\\.com$; 该表达式“~”表示匹配正则表达式，以www开头（“^”表示开头），紧跟着一个0~9之间的数字，在紧跟“.123.co”，最后跟着“m”($表示结尾) 以上匹配的顺序优先级如下： 1 ①、准确匹配 server_name 2 ②、通配符在开始时匹配 server_name 成功 3 ③、通配符在结尾时匹配 server_name 成功 4 ④、正则表达式匹配 server_name 成功 2、基于 IP 地址的虚拟主机配置 语法结构和基于域名匹配一样，而且不需要考虑通配符和正则表达式的问题。 server_name 192.168.1.1 location 该指令用于匹配 URL。 语法如下： location [ = | ~ | ~* | ^~] uri { } 1、= ：用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。 2、~：用于表示 uri 包含正则表达式，并且区分大小写。 3、~*：用于表示 uri 包含正则表达式，并且不区分大小写。 4、^~：用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配。 注意：如果 uri 包含正则表达式，则必须要有 ~ 或者 ~* 标识。 proxy_pass 该指令用于设置被代理服务器的地址。可以是主机名称、IP地址加端口号的形式。 语法结构如下： proxy_pass URL; URL 为被代理服务器的地址，可以包含传输协议、主机名称或IP地址加端口号，URI等。 proxy_pass http://www.123.com/uri; index 该指令用于设置网站的默认首页。 语法为： index filename ...; 后面的文件名称可以有多个，中间用空格隔开。 index index.html index.jsp; 通常该指令有两个作用：第一个是用户在请求访问网站时，请求地址可以不写首页名称；第二个是可以对一个请求，根据请求内容而设置不同的首页。 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:4","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"配置案例 server { listen 80; server_name localhost; charset utf-8; location / { root /home/ruoyi/projects/ruoyi-ui; try_files $uri $uri/ /index.html; index index.html index.htm; } location /prod-api/ { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8080/; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:4:5","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"负载均衡 ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:5:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"负载均衡的由来 早期的系统架构，基本上都是如下形式的： 客户端发送多个请求到服务器，服务器处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回给客户端。 这种架构模式对于早期的系统相对单一，并发请求相对较少的情况下是比较适合的，成本也低。但是随着信息数量的不断增长，访问量和数据量的飞速增长，以及系统业务的复杂度增加，这种架构会造成服务器相应客户端的请求日益缓慢，并发量特别大的时候，还容易造成服务器直接崩溃。很明显这是由于服务器性能的瓶颈造成的问题，那么如何解决这种情况呢？ 我们首先想到的可能是升级服务器的配置，比如提高CPU执行频率，加大内存等提高机器的物理性能来解决此问题，但是我们知道摩尔定律的日益失效，硬件的性能提升已经不能满足日益提升的需求了。最明显的一个例子，天猫双十一当天，某个热销商品的瞬时访问量是极其庞大的，那么类似上面的系统架构，将机器都增加到现有的顶级物理配置，都是不能够满足需求的。那么怎么办呢？ 上面的分析我们去掉了增加服务器物理配置来解决问题的办法，也就是说纵向解决问题的办法行不通了，那么横向增加服务器的数量呢？这时候集群的概念产生了，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡。 负载均衡完美的解决了单个服务器硬件性能瓶颈的问题，但是随着而来的如何实现负载均衡呢？客户端怎么知道要将请求发送到那个服务器去处理呢？ ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:5:1","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"Nginx 实现负载均衡 Nginx 服务器是介于客户端和服务器之间的中介，通过上一节的反向代理的功能，客户端发送的请求先经过 Nginx ，然后通过 Nginx 将请求根据相应的规则分发到相应的服务器。 主要配置指令为上一讲的 pass_proxy 指令以及 upstream 指令。负载均衡主要通过专门的硬件设备或者软件算法实现。通过硬件设备实现的负载均衡效果好、效率高、性能稳定，但是成本较高。而通过软件实现的负载均衡主要依赖于均衡算法的选择和程序的健壮性。均衡算法又主要分为两大类： 静态负载均衡算法：主要包括轮询算法、基于比率的加权轮询算法或者基于优先级的加权轮询算法。 动态负载均衡算法：主要包括基于任务量的最少连接优化算法、基于性能的最快响应优先算法、预测算法及动态性能分配算法等。 静态负载均衡算法在一般网络环境下也能表现的比较好，动态负载均衡算法更加适用于复杂的网络环境。 例子： 普通轮询算法 upstream OrdinaryPolling { server 127.0.0.1:8080; server 127.0.0.1:8081; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 基于比例加权轮询 upstream OrdinaryPolling { server 127.0.0.1:8080 weight=5; server 127.0.0.1:8081 weight=2; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 基于IP路由负载 我们知道一个请求在经过一个服务器处理时，服务器会保存相关的会话信息，比如session，但是该请求如果第一个服务器没处理完，通过nginx轮询到第二个服务器上，那么这个服务器是没有会话信息的。 最典型的一个例子：用户第一次进入一个系统是需要进行登录身份验证的，首先将请求跳转到Tomcat1服务器进行处理，登录信息是保存在Tomcat1 上的，这时候需要进行别的操作，那么可能会将请求轮询到第二个Tomcat2上，那么由于Tomcat2 没有保存会话信息，会以为该用户没有登录，然后继续登录一次，如果有多个服务器，每次第一次访问都要进行登录，这显然是很影响用户体验的。 这里产生的一个问题也就是集群环境下的 session 共享，如何解决这个问题？ 通常由两种方法： 1、第一种方法是选择一个中间件，将登录信息保存在一个中间件上，这个中间件可以为 Redis 这样的数据库。那么第一次登录，我们将session 信息保存在 Redis 中，跳转到第二个服务器时，我们可以先去Redis上查询是否有登录信息，如果有，就能直接进行登录之后的操作了，而不用进行重复登录。 2、第二种方法是根据客户端的IP地址划分，每次都将同一个 IP 地址发送的请求都分发到同一个 Tomcat 服务器，那么也不会存在 session 共享的问题。 而 nginx 的基于 IP 路由负载的机制就是上诉第二种形式。大概配置如下： upstream OrdinaryPolling { ip_hash; server 127.0.0.1:8080 weight=5; server 127.0.0.1:8081 weight=2; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 注意：我们在 upstream 指令块中增加了 ip_hash 指令。该指令就是告诉 nginx 服务器，同一个 IP 地址客户端发送的请求都将分发到同一个 Tomcat 服务器进行处理。 基于服务器响应时间负载分配 根据服务器处理请求的时间来进行负载，处理请求越快，也就是响应时间越短的优先分配。 upstream OrdinaryPolling { server 127.0.0.1:8080 weight=5; server 127.0.0.1:8081 weight=2; fair; } server { listen 80; server_name localhost; location / { proxy_pass http://OrdinaryPolling; index index.html index.htm index.jsp; } } 通过增加了 fair 指令。 对不同域名实现负载均衡 通过配合location 指令块我们还可以实现对不同域名实现负载均衡。 upstream wordbackend { server 127.0.0.1:8080; server 127.0.0.1:8081; } upstream pptbackend { server 127.0.0.1:8082; server 127.0.0.1:8083; } server { listen 80; server_name localhost; location /word/ { proxy_pass http://wordbackend; index index.html index.htm index.jsp; } location /ppt/ { proxy_pass http://pptbackend; index index.html index.htm index.jsp; } } ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:5:2","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["学习笔记"],"content":"引用 以上学习笔记多处摘录自网络 https://www.cnblogs.com/ysocean/p/9392912.html ","date":"2022-02-16","objectID":"/nginx%E5%AD%A6%E4%B9%A0/:6:0","tags":["Nginx"],"title":"Nginx学习","uri":"/nginx%E5%AD%A6%E4%B9%A0/"},{"categories":["算法学习"],"content":"本篇文章是学习leetcode中链表相关算法总结的链表技巧 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:0:0","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"虚拟头节点 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:1:0","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 21 题「合并两个有序链表」 ListNode *mergeTwoLists(ListNode *l1, ListNode *l2) { ListNode *head = new ListNode(-1), *p = head; while (l1 \u0026\u0026 l2) { if (l1-\u003eval \u003c l2-\u003eval) { p-\u003enext = l1; l1 = l1-\u003enext; } else { p-\u003enext = l2; l2 = l2-\u003enext; } p = p-\u003enext; } p-\u003enext = l1 ? l1 : l2; return head-\u003enext; } 这个算法的逻辑类似于「拉拉链」，l1, l2 类似于拉链两侧的锯齿，指针 p 就好像拉链的拉索，将两个有序链表合并 ListNode *head = new ListNode(-1), *p = head;中使用到了虚拟头节点，如果不使用虚拟节点，代码会复杂很多，而有了 head 节点这个占位符，可以避免处理空指针的情况，降低代码的复杂性 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:1:1","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"优先队列 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:2:0","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 23 题「合并K个升序链表」 struct cmp { bool operator()(ListNode *p1, ListNode *p2) { return p1-\u003eval \u003e p2-\u003eval; } }; ListNode *mergeKLists(vector\u003cListNode *\u003e \u0026lists) { if (lists.size() == 0) return nullptr; ListNode *head = new ListNode(-1), *tail = head; priority_queue\u003cListNode *, vector\u003cListNode *\u003e, cmp\u003e pq; for (auto i : lists) { if (i) pq.push(i); } while (!pq.empty()) { ListNode *node = pq.top(); pq.pop(); tail-\u003enext = node; tail = tail-\u003enext; if (node-\u003enext) pq.push(node-\u003enext); } return head-\u003enext; } 这里我们就要用到 优先级队列 这种数据结构，把链表节点放入一个最小堆，就可以每次获得 k 个节点中的最小节点 它的时间复杂度是多少呢？ 优先队列 pq 中的元素个数最多是 k，所以一次 poll 或者 add 方法的时间复杂度是 O(logk)；所有的链表节点都会被加入和弹出 pq，所以算法整体的时间复杂度是 O(Nlogk)，其中 k 是链表的条数，N 是这些链表的节点总数。 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:2:1","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"单链表的倒数第k个节点 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:3:0","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 19 题「删除链表的倒数第 N 个结点」 ListNode *removeNthFromEnd(ListNode *head, int n) { ListNode *dummy = new ListNode(-1); dummy-\u003enext = head; auto temp = FindFromEnd(dummy, n + 1); temp-\u003enext = temp-\u003enext-\u003enext; return dummy-\u003enext; } ListNode *FindFromEnd(ListNode *head, int n) { ListNode *first = head, *second = head; while (n--) { first = first-\u003enext; } while (first) { first = first-\u003enext; second = second-\u003enext; } return second; } 首先，我们先让一个指针 p1 指向链表的头节点 head，然后走 k 步 现在的 p1，只要再走 n - k 步，就能走到链表末尾的空指针了对吧？趁这个时候，再用一个指针 p2 指向链表头节点 head 接下来就很显然了，让 p1 和 p2 同时向前走，p1 走到链表末尾的空指针时走了 n - k 步，p2 也走了 n - k 步，也就是链表的倒数第 k 个节点 这样，只遍历了一次链表，就获得了倒数第 k 个节点 p2 不过注意我们又使用了虚拟头结点的技巧，也是为了防止出现空指针的情况，比如说链表总共有 5 个节点，题目就让你删除倒数第 5 个节点，也就是第一个节点，那按照算法逻辑，应该首先找到倒数第 6 个节点。但第一个节点前面已经没有节点了，这就会出错。 但有了我们虚拟节点 dummy 的存在，就避免了这个问题，能够对这种情况进行正确的删除。 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:3:1","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"双指针 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:0","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 876 题「链表的中间结点」 如果想一次遍历就得到中间节点，也需要耍点小聪明，使用「快慢指针」的技巧： 我们让两个指针 slow 和 fast 分别指向链表头结点 head。 每当慢指针 slow 前进一步，快指针 fast 就前进两步，这样，当 fast 走到链表末尾时，slow 就指向了链表中点。 ListNode *middleNode(ListNode *head) { ListNode *slow = head, *fast = head; while (fast \u0026\u0026 fast-\u003enext) { slow = slow-\u003enext; fast = fast-\u003enext-\u003enext; } return slow; } ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:1","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 141 题「环形链表」 判断链表是否包含环属于经典问题了，解决方案也是用快慢指针： 每当慢指针 slow 前进一步，快指针 fast 就前进两步。 如果 fast 最终遇到空指针，说明链表中没有环；如果 fast 最终和 slow 相遇，那肯定是 fast 超过了 slow 一圈，说明链表中含有环。 bool hasCycle(ListNode *head) { ListNode *slow = head, *fast = head; while (fast \u0026\u0026 fast-\u003enext) { slow = slow-\u003enext; fast = fast-\u003enext-\u003enext; if (slow == fast) return true; } return false; } 当然，这个问题还有进阶版：如果链表中含有环，如何计算这个环的起点？ 这里简单提一下解法： ListNode detectCycle(ListNode head) { ListNode fast, slow; fast = slow = head; while (fast != null \u0026\u0026 fast.next != null) { fast = fast.next.next; slow = slow.next; if (fast == slow) break; } // 上面的代码类似 hasCycle 函数 if (fast == null || fast.next == null) { // fast 遇到空指针说明没有环 return null; } // 重新指向头结点 slow = head; // 快慢指针同步前进，相交点就是环起点 while (slow != fast) { fast = fast.next; slow = slow.next; } return slow; } ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:2","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["算法学习"],"content":"力扣第 160 题「相交链表」 ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) { ListNode *A = headA, *B = headB; while (A != B) { if (A) A = A-\u003enext; else A = headB; if (B) B = B-\u003enext; else B = headA; } return A; } 如果用两个指针 p1 和 p2 分别在两条链表上前进，并不能同时走到公共节点，也就无法得到相交节点 c1。 解决这个问题的关键是，通过某些方式，让 p1 和 p2 能够同时到达相交节点 c1。 所以，我们可以让 p1 遍历完链表 A 之后开始遍历链表 B，让 p2 遍历完链表 B 之后开始遍历链表 A，这样相当于「逻辑上」两条链表接在了一起。 如果这样进行拼接，就可以让 p1 和 p2 同时进入公共部分，也就是同时到达相交节点 c1： 那你可能会问，如果说两个链表没有相交点，是否能够正确的返回 null 呢？ 这个逻辑可以覆盖这种情况的，相当于 c1 节点是 null 空指针嘛，可以正确返回 null。 这样，这道题就解决了，空间复杂度为 O(1)，时间复杂度为 O(N)。 ","date":"2022-01-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/:4:3","tags":["算法"],"title":"算法学习-链表","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0-%E9%93%BE%E8%A1%A8/"},{"categories":["个人网站"],"content":"安装Hugo 到 Hugo Releases 下载对应的操作系统版本的Hugo二进制文件（hugo或者hugo.exe） Mac下直接使用 Homebrew 安装： brew install hugo ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:1","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"生成站点 使用Hugo快速生成站点，比如希望生成到 /path/to/site 路径： $ hugo new site /path/to/site 这样就在 /path/to/site 目录里生成了初始站点，进去目录： $ cd /path/to/site 站点目录结构： ▸ archetypes/ ▸ content/ ▸ layouts/ ▸ static/ config.toml ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:2","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"创建文章 创建一个 about 页面： $ hugo new about.md about.md 自动生成到了 content/about.md ，打开 about.md 看下： +++ date = \"2015-10-25T08:36:54-07:00\" draft = true title = \"about\" +++ 正文内容 内容是 Markdown 格式的，+++ 之间的内容是 TOML 格式的，根据你的喜好，你可以换成 YAML 格式（使用 --- 标记）或者 JSON 格式。 创建第一篇文章，放到 post 目录，方便之后生成聚合页面。 $ hugo new post/first.md ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:3","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"安装皮肤 到 皮肤列表 挑选一个心仪的皮肤，比如你觉得 Hyde 皮肤不错，找到相关的 GitHub 地址，创建目录 themes，在 themes 目录里把皮肤 git clone 下来： # 创建 themes 目录 $ cd themes $ git clone https://github.com/spf13/hyde.git ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:4","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"运行Hugo 在你的站点根目录执行 Hugo 命令进行调试： $ hugo server --theme=hyde --buildDrafts 若在config.toml设置了theme和buildDrafts： $ hugo server 浏览器里打开： http://localhost:1313 ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:5","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"部署 假设你需要部署在 GitHub Pages 上，首先在GitHub上创建一个Repository，命名为：coderzh.github.io（coderzh替换为你的github用户名）。 在站点根目录执行 Hugo 命令生成最终页面： $ hugo --theme=hyde --baseUrl=\"http://coderzh.github.io/\" 或者 $ hugo （注意，以上命令并不会生成草稿页面，如果未生成任何文章，请去掉文章头部的 draft=true 再重新生成。） 如果一切顺利，所有静态页面都会生成到 public 目录，将pubilc目录里所有文件 push 到刚创建的Repository的 master 分支。 浏览器里访问：http://coderzh.github.io/ ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:6","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"其他相关 关于文章内容 它使您可以直接包含内容的元数据。Hugo支持几种不同的格式，每种格式都有自己的识别令牌。 支持的格式： TOML，以“+++”标识。 YAML，由“---”标识。 JSON，一个单独的JSON对象，由’{‘和’}‘包围，每行各自。 YAML Example --- title: \"spf13-vim 3.0 release and new website\" description: \"spf13-vim is a cross platform distribution of vim plugins and resources for Vim.\" tags: [ \".vimrc\", \"plugins\", \"spf13-vim\", \"vim\" ] lastmod: 2015-12-23 date: \"2012-04-06\" categories: - \"Development\" - \"VIM\" slug: \"spf13-vim-3-0-release-and-new-website\" --- Content of the file goes Here Required variables title The title for the content description The description for the content date The date the content will be sorted by taxonomies These will use the field name of the plural form of the index (see tags and categories above) Optional variables aliases An array of one or more aliases (e.g. old published path of a renamed content) that would be created to redirect to this content. See Aliases for details. draft If true, the content will not be rendered unless hugo is called with --buildDrafts publishdate If in the future, content will not be rendered unless hugo is called with --buildFuture type The type of the content (will be derived from the directory automatically if unset) isCJKLanguage If true, explicitly treat the content as CJKLanguage (.Summary and .WordCount can work properly in CJKLanguage) weight Used for sorting markup (Experimental) Specify \"rst\" for reStructuredText (requires rst2html) or \"md\" (default) for Markdown slug The token to appear in the tail of the URL, or url The full path to the content from the web root. If neither slug or url is present, the filename will be used. 关于配置 通常的使用情况下，一个网站并不需要一个配置文件，因为它的目录结构和模板就提供了主要的配置。 Hugo 需要在源目录查找一个 config.toml 的配置文件。如果这个文件不存在，将会查找 config.yaml，然后是 config.json 。 这个配置文件是一个整站的配置。它给 Hugo 提供了如何构建站点的方式，比如全局的参数和菜单。 配置变量 下面是 Hugo 定义好的变量列表，以及他们的默认值，你可以设置他们： --- archetypedir: \"archetype\" # hostname (and path) to the root, e.g. http://spf13.com/ baseURL: \"\" # include content marked as draft buildDrafts: false # include content with publishdate in the future buildFuture: false # enable this to make all relative URLs relative to content root. Note that this does not affect absolute URLs. relativeURLs: false canonifyURLs: false # config file (default is path/config.yaml|json|toml) config: \"config.toml\" contentdir: \"content\" dataDir: \"data\" defaultExtension: \"html\" defaultLayout: \"post\" disableLiveReload: false # Do not build RSS files disableRSS: false # Do not build Sitemap file disableSitemap: false # edit new content with this editor, if provided editor: \"\" footnoteAnchorPrefix: \"\" footnoteReturnLinkContents: \"\" # google analytics tracking id googleAnalytics: \"\" languageCode: \"\" layoutdir: \"layouts\" # Enable Logging log: false # Log File path (if set, logging enabled automatically) logFile: \"\" # \"yaml\", \"toml\", \"json\" metaDataFormat: \"toml\" newContentEditor: \"\" # Don't sync modification time of files noTimes: false paginate: 10 paginatePath: \"page\" permalinks: # Pluralize titles in lists using inflect pluralizeListTitles: true # Preserve special characters in taxonomy names (\"Gérard Depardieu\" vs \"Gerard Depardieu\") preserveTaxonomyNames: false # filesystem path to write files to publishdir: \"public\" # color-codes for highlighting derived from this style pygmentsStyle: \"monokai\" # true: use pygments-css or false: color-codes directly pygmentsUseClasses: false # default sitemap configuration map sitemap: # filesystem path to read files relative from source: \"\" staticdir: \"static\" # display memory and timing of different steps of the program stepAnalysis: false # theme to use (located in /doc/themes/THEMENAME/) theme: \"\" title: \"\" # if true, use /filename.html instead of /filename/ uglyURLs: false # Do not make the url/path to lowercase disablePathToLower: false # if true, auto-detect Chinese/Japanese/Korean Languages in the content. (.Summary and .WordCount can work properly in CJKLanguage) hasCJKLanguage false # verbose output verbose: false # verbose logging verboseLog: false ","date":"2020-10-15","objectID":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/:0:7","tags":["Blog"],"title":"Hugo个人静态网页生成","uri":"/hugo%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E7%94%9F%E6%88%90/"},{"categories":["个人网站"],"content":"GitHub Pages GitHub Pages是GitHub提供给大家的快速部署静态网页的功能，但是由于国内访问比较慢，这里提供一个相对较快的解决办法，就是用GitHub加Vercel。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:1","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["个人网站"],"content":"第一步：注册登录Vercel 我想大家应该都有GitHub账号吧，这里就不多说了。 点击Vercel官网,并使用GitHub登录。 注意⚠️：GitHub账号不要使用QQ邮箱作为主邮箱。如果已经用QQ邮箱注册了GitHub，可以到Setting -\u003e Emails里修改自己的主邮箱。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:2","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["个人网站"],"content":"第二步：导入仓库 它会让你选择一种登录Vercel的方法，支持使用GitHub，GitLab和Bitbucket登录，这里我们选GitHub，后面就是无脑Next的步骤。 顺利的话稍等片刻就会弹出部署成功的页面，还有浮夸的撒花。 部署完成之后可以点击visit进入网页看看效果。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:3","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["个人网站"],"content":"第三步：配置域名 1.点击view Domains进行绑定自己的域名或者点击Settings👉Domains👉输入自己的域名 2.输入自己的域名，然后点Add，它会弹出来一些需要做的配置，接下来需要去我们的域名提供商那里根据Vercel给出的要求进行配置。需要修改的有：Name Servers以及域名解析 最后等待等这两个改动都生效之后就可以用我们自己的域名访问刚刚建立的网站啦~ 以后想要修改网站的话，只需要将改动push到GitHub上，vercel会自动把改动同步过来，完全不用管，超省心。 在一级域名配置好之后，也可以直接在vercel中使用二级域名，无需进行额外设置。 ","date":"2020-10-14","objectID":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/:0:4","tags":["Blog"],"title":"搭建个人网站:GitHub加Vercel","uri":"/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99github%E5%8A%A0vercel/"},{"categories":["学习笔记"],"content":"一、引入依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.thymeleaf.extras\u003c/groupId\u003e \u003cartifactId\u003ethymeleaf-extras-springsecurity4\u003c/artifactId\u003e \u003cversion\u003e3.0.4.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2020-10-12","objectID":"/%E6%B5%85%E5%AD%A6springsecurity-mybatis/:0:1","tags":["SpringBoot"],"title":"浅学SpringSecurity+Mybatis","uri":"/%E6%B5%85%E5%AD%A6springsecurity-mybatis/"},{"categories":["学习笔记"],"content":"二、配置WebSecurityConfigurerAdapter 使用内存用户储存且认证 @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true) // 开启方法级安全验证 public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests()//表示下面是认证的配置 .antMatchers(\"/login\").permitAll() .antMatchers(\"/login/form\").permitAll() .antMatchers(\"/css/**\").permitAll() .antMatchers(\"/js/**\").permitAll() .anyRequest()//任何请求 .authenticated();//都需要身份认证 http.formLogin()//表单认证 .loginPage(\"/login\")//使用本人制作的登录界面 .usernameParameter(\"user\")//username更改 .loginProcessingUrl(\"/login/form\")//表单提交的api .defaultSuccessUrl(\"/\")//登录成功跳转页面 .failureUrl(\"/login/error\").permitAll();//登录错误跳转界面 http.logout().logoutSuccessUrl(\"/login\");//登出 http.csrf().disable();//防止跨站攻击 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.inMemoryAuthentication()//使用内存用户储存 //配置了一个user用户和一个admin用户 .withUser(\"user\").password(\"password\").roles(\"USER\").and() .withUser(\"admin\").password(\"password\").roles(\"USER\", \"ADMIN\"); } } ","date":"2020-10-12","objectID":"/%E6%B5%85%E5%AD%A6springsecurity-mybatis/:0:2","tags":["SpringBoot"],"title":"浅学SpringSecurity+Mybatis","uri":"/%E6%B5%85%E5%AD%A6springsecurity-mybatis/"},{"categories":["学习笔记"],"content":"三、由数据库认证登录 在MySQL中创建用户表 CREATE TABLE `admin` ( `username` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `password` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `id` int(11) NOT NULL AUTO_INCREMENT, `role` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO `admin` VALUES ('admin', '123', 1, 'admin'); entity层创建实体 @Data //使用lombok,简化get,set public class UserInfo { private Integer id; private String username; private String password; private String role; } dao层创建数据存取对象 @Mapper//mapper.xml分离 @Repository public interface UserInfoDao { UserInfo getUserInfoByUsername(String username); } 创建dao对应的mapper.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003cmapper namespace=\"cn.llssit.ls.dao.UserInfoDao\"\u003e \u003cselect id=\"getUserInfoByUsername\" resultType=\"UserInfo\"\u003e select * from admin where username = #{username} \u003c/select\u003e \u003c/mapper\u003e service层 interface public interface UserInfoSevice { UserInfo getUserInfoByUsername(String username); } impl @Service public class UserInfoServiceImpl implements UserInfoSevice { @Autowired private UserInfoDao userInfoDao; @Override public UserInfo getUserInfoByUsername(String username) { return userInfoDao.getUserInfoByUsername(username); } } controller层或者其他运用 springsecurity数据库认证 首先需要重写接口loadUserByUsername @Component public class MyUserDetailService implements UserDetailsService { @Autowired private UserInfoSevice userInfoService; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException { // 通过用户名从数据库获取用户信息 UserInfo userInfo = userInfoService.getUserInfoByUsername(s); if (userInfo == null) { throw new UsernameNotFoundException(\"用户不存在\"); } // 得到用户角色 String role = userInfo.getRole(); // 角色集合 List\u003cGrantedAuthority\u003e authorities = new ArrayList\u003c\u003e(); // 角色必须以`ROLE_`开头，数据库中没有，则在这里加 authorities.add(new SimpleGrantedAuthority(\"ROLE_\" + role)); return new User( userInfo.getUsername(), // 因为数据库是明文，所以这里需加密密码 new BCryptPasswordEncoder().encode(userInfo.getPassword()), authorities ); } } 然后创建Security的配置类WebSecurityConfig继承WebSecurityConfigurerAdapter，并重写configure(auth)方法 @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true) // 开启方法级安全验证 public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private MyUserDetailService userDatailService; @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\"/login\").permitAll() .antMatchers(\"/login/form\").permitAll() .antMatchers(\"/css/**\").permitAll() .antMatchers(\"/js/**\").permitAll() .anyRequest() .authenticated(); http.formLogin() .loginPage(\"/login\") .usernameParameter(\"user\") .loginProcessingUrl(\"/login/form\") .defaultSuccessUrl(\"/\") .failureUrl(\"/login/error\").permitAll(); http.logout().logoutSuccessUrl(\"/login\"); http.csrf().disable(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth // 从数据库读取的用户进行身份认证 .userDetailsService(userDatailService) .passwordEncoder(new BCryptPasswordEncoder()); } } 角色访问 @EnableGlobalMethodSecurity(prePostEnabled = true) // 开启方法级安全验证 修改Controller.java类，增加方法的访问权限@PreAuthorize(\"hasAnyRole('admin')\") ","date":"2020-10-12","objectID":"/%E6%B5%85%E5%AD%A6springsecurity-mybatis/:0:3","tags":["SpringBoot"],"title":"浅学SpringSecurity+Mybatis","uri":"/%E6%B5%85%E5%AD%A6springsecurity-mybatis/"},{"categories":["学习笔记"],"content":"Java集合框架 导入包 import java.util.*; ArrayList 一、定义一个ArrayList //默认创建一个ArrayList集合 List\u003cString\u003e list = new ArrayList\u003c\u003e(); //创建一个初始化长度为100的ArrayList集合 List\u003cString\u003e initlist = new ArrayList\u003c\u003e(100); //将其他类型的集合转为ArrayList List\u003cString\u003e setList = new ArrayList\u003c\u003e(new HashSet()); 二、ArrayList常用方法 add(E element) set(int index, E element) 因为ArrayList底层是由数组实现的，set实现非常简单，调用 set(4, \"4\") 通过传入的数字下标找到对应的位置，替换其中的元素，前提也需要首先判断传入的数组下标是否越界。 get(int index) remove(int index) remove(Object o) 其他方法 size() : 获取集合长度，通过定义在ArrayList中的私有变量size得到 isEmpty()：是否为空，通过定义在ArrayList中的私有变量size得到 contains(Object o)：是否包含某个元素，通过遍历底层数组elementData，通过equals或==进行判断 clear()：集合清空，通过遍历底层数组elementData，设置为null ArrayList的遍历 List\u003cString\u003e list=new ArrayList\u003cString\u003e(); list.add(\"Hello\"); list.add(\"World\"); list.add(\"HAHAHAHA\"); //第一种遍历方法使用 For-Each 遍历 List for (String str : list) { //也可以改写 for(int i=0;i\u003clist.size();i++) 这种形式 System.out.println(str); } //第二种遍历，把链表变为数组相关的内容进行遍历 String[] strArray=new String[list.size()]; list.toArray(strArray); for(int i=0;i\u003cstrArray.length;i++) //这里也可以改写为 for(String str:strArray) 这种形式 { System.out.println(strArray[i]); } //第三种遍历 使用迭代器进行相关遍历 Iterator\u003cString\u003e ite=list.iterator(); while(ite.hasNext())//判断下一个元素之后有值 { System.out.println(ite.next()); } HashMap 一、定义一个HashMap Map\u003cString, String\u003e map = new HashMap\u003c\u003e(); 二、HashMap常用方法 public V put(K key, V value) :插入键值对数据 public V get(Object key) :根据键值获取键值对值数据 public int size() :获取Map中键值对的个数 public boolean containsKey(Object key) :判断Map集合中是否包含键为key的键值对 boolean containsValue(Object value) :判断Map集合中是否包含值为value的键值对 public boolean isEmpty() :判断Map集合中是否没有任何键值对 public V remove(Object key) :根据键值删除Map中键值对 public void clear() :清空Map集合中所有的键值对 HashMap的遍历 Map\u003cString, String\u003e map = new HashMap\u003cString, String\u003e(); map.put(\"1\", \"value1\"); map.put(\"2\", \"value2\"); map.put(\"3\", \"value3\"); //第一种：普遍使用，二次取值 System.out.println(\"通过Map.keySet遍历key和value：\"); for (String key : map.keySet()) { System.out.println(\"key= \"+ key + \" and value= \" + map.get(key)); } //第二种 System.out.println(\"通过Map.entrySet使用iterator遍历key和value：\"); Iterator\u003cMap.Entry\u003cString, String\u003e\u003e it = map.entrySet().iterator(); while (it.hasNext()) { Map.Entry\u003cString, String\u003e entry = it.next(); System.out.println(\"key= \" + entry.getKey() + \" and value= \" + entry.getValue()); } //第三种：推荐，尤其是容量大时 System.out.println(\"通过Map.entrySet遍历key和value\"); for (Map.Entry\u003cString, String\u003e entry : map.entrySet()) { System.out.println(\"key= \" + entry.getKey() + \" and value= \" + entry.getValue()); } //第四种 System.out.println(\"通过Map.values()遍历所有的value，但不能遍历key\"); for (String v : map.values()) { System.out.println(\"value= \" + v); } ","date":"2020-10-12","objectID":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:1","tags":["Java"],"title":"Java学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"Java多线程 Java 给多线程编程提供了内置的支持。 一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 多线程是多任务的一种特别的形式，但多线程使用了更小的资源开销。 这里定义和线程相关的另一个术语 - 进程：一个进程包括由操作系统分配的内存空间，包含一个或多个线程。一个线程不能独立的存在，它必须是进程的一部分。一个进程一直运行，直到所有的非守护线程都结束运行后才能结束。 多线程能满足程序员编写高效率的程序来达到充分利用 CPU 的目的。 一个线程的生命周期 线程是一个动态执行的过程，它也有一个从产生到死亡的过程。 下图显示了一个线程完整的生命周期。 新建状态： 使用 new 关键字和 Thread 类或其子类建立一个线程对象后，该线程对象就处于新建状态。它保持这个状态直到程序 start() 这个线程。 就绪状态： 当线程对象调用了start()方法之后，该线程就进入就绪状态。就绪状态的线程处于就绪队列中，要等待JVM里线程调度器的调度。 运行状态： 如果就绪状态的线程获取 CPU 资源，就可以执行 run()，此时线程便处于运行状态。处于运行状态的线程最为复杂，它可以变为阻塞状态、就绪状态和死亡状态。 阻塞状态： 如果一个线程执行了sleep（睡眠）、suspend（挂起）等方法，失去所占用资源之后，该线程就从运行状态进入阻塞状态。在睡眠时间已到或获得设备资源后可以重新进入就绪状态。可以分为三种： 等待阻塞：运行状态中的线程执行 wait() 方法，使线程进入到等待阻塞状态。 同步阻塞：线程在获取 synchronized 同步锁失败(因为同步锁被其他线程占用)。 其他阻塞：通过调用线程的 sleep() 或 join() 发出了 I/O 请求时，线程就会进入到阻塞状态。当sleep() 状态超时，join() 等待线程终止或超时，或者 I/O 处理完毕，线程重新转入就绪状态。 死亡状态： 一个运行状态的线程完成任务或者其他终止条件发生时，该线程就切换到终止状态。 线程的优先级 每一个 Java 线程都有一个优先级，这样有助于操作系统确定线程的调度顺序。 Java 线程的优先级是一个整数，其取值范围是 1 （Thread.MIN_PRIORITY ） - 10 （Thread.MAX_PRIORITY ）。 默认情况下，每一个线程都会分配一个优先级 NORM_PRIORITY（5）。 具有较高优先级的线程对程序更重要，并且应该在低优先级的线程之前分配处理器资源。但是，线程优先级不能保证线程执行的顺序，而且非常依赖于平台。 Thread 方法 序号 方法描述 1 public void start()使该线程开始执行；==Java== 虚拟机调用该线程的 run 方法。 2 public void run()如果该线程是使用独立的 Runnable 运行对象构造的，则调用该 Runnable 对象的 run 方法；否则，该方法不执行任何操作并返回。 3 public final void setName(String name)改变线程名称，使之与参数 name 相同。 4 public final void setPriority(int priority) 更改线程的优先级。 5 public final void setDaemon(boolean on)将该线程标记为守护线程或用户线程。 6 public final void join(long millisec)等待该线程终止的时间最长为 millis 毫秒。 7 public void interrupt()中断线程。 8 public final boolean isAlive()测试线程是否处于活动状态。 测试线程是否处于活动状态。 上述方法是被Thread对象调用的。下面的方法是Thread类的静态方法。 序号 方法描述 1 public static void yield()暂停当前正在执行的线程对象，并执行其他线程。 2 public static void sleep(long millisec)在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），此操作受到系统计时器和调度程序精度和准确性的影响。 3 public static boolean holdsLock(Object x)当且仅当当前线程在指定的对象上保持监视器锁时，才返回 true。 4 public static Thread currentThread()返回对当前正在执行的线程对象的引用。 5 public static void dumpStack()将当前线程的堆栈跟踪打印至标准错误流。 创建一个线程 Java 提供了三种创建线程的方法： 通过实现 Runnable 接口； 通过继承 Thread 类本身； 通过 Callable 和 Future 创建线程。 通过实现Runnable 接口来创建线程 创建一个线程，最简单的方法是创建一个实现 Runnable 接口的类。 为了实现 Runnable，一个类只需要执行一个方法调用 run()，声明如下： public void run() 你可以重写该方法，重要的是理解的 run() 可以调用其他方法，使用其他类，并声明变量，就像主线程一样。 在创建一个实现 Runnable 接口的类之后，你可以在类中实例化一个线程对象。 Thread 定义了几个构造方法，下面的这个是我们经常使用的： Thread(Runnable threadOb,String threadName); 这里，threadOb 是一个实现 Runnable 接口的类的实例，并且 threadName 指定新线程的名字。 新线程创建之后，你调用它的 start() 方法它才会运行。 void start(); 下面是一个创建线程并开始让它执行的实例： class RunnableDemo implements Runnable { private Thread t; private String threadName; RunnableDemo( String name) { threadName = name; System.out.println(\"Creating \" + threadName ); } public void run() { System.out.println(\"Running \" + threadName ); try { for(int i = 4; i \u003e 0; i--) { System.out.println(\"Thread: \" + threadName + \", \" + i); // 让线程睡眠一会 Thread.sleep(50); } }catch (InterruptedException e) { System.out.println(\"Thread \" + threadName + \" interrupted.\"); } System.out.println(\"Thread \" + threadName + \" exiting.\"); } public void start () { System.out.println(\"Starting \" + threadName ); if (t == null) { t = new Thread (this, threadName); t.start (); } } } public class TestThread { public static void main(String args[]) { RunnableDemo R1 = new RunnableDemo( \"Thread-1\"); R1.start(); RunnableDemo R2 = new RunnableDemo( \"Thread-2\"); R2.start(); } } 通过继承Thread来创建线程 创建一个线程的第二种方法是创建一个新的类，该类继承 Thread 类，然后创建一个该类的实例。 继承类必须重写 run() 方法，该方法是新线程的入口点。它也必须调用 start() 方法才能执行。 该方法尽管被列为一种多线程实现方式，但是本质上也是实现了 Runnable 接口的一个实例。 class ThreadDemo extends Thread { private Thread t; private String threadName; ThreadDemo( String name) { threadName = name; System.out.println(\"Creating \" + threadName ); } public void run() { System.out.println(\"Running \" + threadName ); try { for(int i = 4; i \u003e 0; i--) { System.out.println(\"Thread: \" + threadName + \", \" + i); // 让线程睡眠一会 Thread.sleep(50); } }catch (InterruptedException e) { System.out.println(\"Thread \" + threadName + \" interrupted.\"); } System.out.println(\"Thread \" + t","date":"2020-10-12","objectID":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:2","tags":["Java"],"title":"Java学习笔记","uri":"/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"一、写前准备 在atom文本编译器中自带着markdown的编写与浏览功能。 浏览使用快捷键ctl+shift+m就可以打开markdown预览。 简书中在设置-\u003e默认编辑器-\u003emarkdown编译，就可以设置markdown。 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:1:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"二、标题 在想要设置为标题的文字前面加#来表示标题 一个#号是以及标题，两个#是二级标题，最多有六级标题 标准语法需要在#后加空格才能表示 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:2:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"三、字体 加粗 在要加粗的文字左右分别用两个*标注 斜体 在要倾斜的文字左右分别用一个*标注 斜体加粗 在要倾斜和加粗的文字左右分别用三个*标注 删除线 在要加删除线的文字左右分别用两个～标注 例如： **加粗字体** *斜体字体* ***斜体加粗字体*** ~~删除字体~~ 效果： 加粗字体，斜体字体，斜体加粗字体，删除字体 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:3:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"四、引用 在引用文字前加\u003e。引用可以嵌套，如一个\u003e、两个\u003e等等 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:4:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"五、\u0008分割线 三个或三个以上的-或者*\u0008\u0008 例： --- *** \u0008效果: ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:5:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"六、\u0008图片 使用方法： ![图片alt](图片地址 ''图片title'') 图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:6:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"七、超链接 使用方法： [超链接名](超链接地址 \"超链接title\") title可加可不加 注：Markdown本身语法不支持链接在新页面中打开，貌似简书做了处理，是可以的。别的平台可能就不行了，如果想要在新页面中打开的话可以用html语言的a标签代替。 \u003ca href=\"超链接地址\" target=\"_blank\"\u003e超链接名\u003c/a\u003e 示例 \u003ca href=\"https://www.jianshu.com/u/1f5ac0cf6a8b\" target=\"_blank\"\u003e简书\u003c/a\u003e ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:7:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"八、列表 无序列表 使用方法：无序列表用 - + * 任何一种都可以 - 列表内容 + 列表内容 * 列表内容 注意：- + * 跟内容之间都要有一个空格 有序列表 使用方法：数字加点 1.列表内容 2.列表内容 3.列表内容 注意：序号跟内容之间要有空格 列表嵌套 使用方法：上一级和下一级之间敲三个空格 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:8:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"九、表格 使用方法： | 表头 | 表头 | 表头 | | ---- | :---: | ---: | | 内容 | 内容 | 内容 | | 内容 | 内容 | 内容 | 第二行分割表头和内容。 -有一个就行 文字默认居左 -两边加：表示文字居中 -右边加：表示文字居右 注：原生的语法两边都要用 | 包起来。此处省略 效果： 表头 表头 表头 内容 内容 内容 内容 内容 内容 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:9:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十、代码 使用方法： 单行代码：代码之间分别用一个反引号包起来 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行 代码\u0008高亮：在第一行反引号后面输入代码块所使用的语言 代码高亮演示： `c #include \"stdio.h\" int main(){ printf(\"hello world\\n\"); return 0; } ` #include \"stdio.h\" int main(){ printf(\"hello world\\n\"); return 0; } ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:10:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十一、流程图 使用方法： st=\u003estart: 开始 op=\u003eoperation: My Operation cond=\u003econdition: Yes or No? e=\u003eend st-\u003eop-\u003econd cond(yes)-\u003ee cond(no)-\u003eop ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:11:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十二、数学表达式 用反引号将数学表达式封装,并在第三个号后标注math代表数学公式. E = mc^2 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:12:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"十三、待办事项 在待办的事项文本或者清单文本前加上- 、- [x]即可 - [ ] 表示未完成，- [x] 表示已完成。 注：键入字符与字符之间都要保留一个字符的空格。 效果 分析需求 研发 测试 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:13:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"结语 Markdown换行方法： 在本行最后敲两个空格即可 每行间空一行即可 Mac上反引号方法： 在英文状态下按住option键+数字1左边的键 本文章为个人学习笔记，转载了多人的博客，如有雷同请见谅。 ","date":"2020-10-12","objectID":"/markdown%E7%AC%94%E8%AE%B0/:14:0","tags":["Markdown"],"title":"Markdown笔记","uri":"/markdown%E7%AC%94%E8%AE%B0/"}]